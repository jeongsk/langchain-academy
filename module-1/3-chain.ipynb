{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b212373",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4579981",
   "metadata": {},
   "source": [
    "# 체인\n",
    "\n",
    "## 복습\n",
    "\n",
    "이전 시간에 노드, 일반 에지, 조건부 에지로 구성된 간단한 그래프를 만들었습니다.\n",
    "\n",
    "## 목표\n",
    "\n",
    "이번에는 4가지 [개념](https://python.langchain.com/v0.2/docs/concepts/)을 결합한 간단한 체인을 구축해 보겠습니다:\n",
    "\n",
    "* 그래프 상태에 [채팅 메시지](https://python.langchain.com/v0.2/docs/concepts/#messages) 사용\n",
    "* 그래프 노드에 [채팅 모델](https://python.langchain.com/v0.2/docs/concepts/#chat-models) 적용\n",
    "* 채팅 모델에 [도구를 연결](https://python.langchain.com/v0.2/docs/concepts/#tools)\n",
    "* 그래프 노드에서 [도구 호출 실행](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) \n",
    "\n",
    "![](https://i.imgur.com/ORvUyMg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc43365",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500667f",
   "metadata": {},
   "source": [
    "## Messages(메시지)\n",
    "\n",
    "챗 모델은 대화 내 다양한 역할을 포착하는 [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages)를 사용할 수 있습니다. \n",
    "\n",
    "LangChain은 `HumanMessage`, `AIMessage`, `SystemMessage`, `ToolMessage` 등 다양한 메시지 유형을 지원합니다.\n",
    "\n",
    "이들은 각각 사용자의 메시지, 채팅 모델의 메시지, 채팅 모델의 행동 지시 메시지, 도구 호출 메시지를 나타냅니다.\n",
    "\n",
    "메시지 목록을 생성해 보겠습니다. \n",
    "\n",
    "각 메시지는 다음과 같은 정보를 포함할 수 있습니다:\n",
    "\n",
    "* `content` - 메시지 내용\n",
    "* `name` - 선택적으로 메시지 작성자\n",
    "* `response_metadata` - 선택적으로 메타데이터 사전 (예: `AIMessages`의 경우 모델 제공자가 자주 채움)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c27e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "그러니까 해양 포유류를 연구하고 있다고 하셨나요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "네, 맞아요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "좋아요, 무엇을 배우고 싶으신가요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "미국에서 범고래를 관찰하기 가장 좋은 장소에 대해 알고 싶습니다.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(\"그러니까 해양 포유류를 연구하고 있다고 하셨나요?\",  name=\"Model\")]\n",
    "messages.append(HumanMessage(\"네, 맞아요.\", name=\"Lance\"))\n",
    "messages.append(AIMessage(\"좋아요, 무엇을 배우고 싶으신가요?\", name=\"Model\"))\n",
    "messages.append(HumanMessage(\"미국에서 범고래를 관찰하기 가장 좋은 장소에 대해 알고 싶습니다.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91b0cb",
   "metadata": {},
   "source": [
    "## 채팅 모델\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models)은 메시지 시퀀스를 입력으로 사용할 수 있으며, 앞서 논의한 바와 같이 다양한 메시지 유형을 지원합니다.\n",
    "\n",
    "선택할 수 있는 모델이 [많습니다](https://python.langchain.com/v0.2/docs/concepts/#chat-models)! OpenAI와 함께 작업해 보겠습니다.\n",
    "\n",
    "`OPENAI_API_KEY`가 설정되어 있는지 확인하세요. 설정되어 있지 않으면 입력하라는 메시지가 표시됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0016a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\", override=True, verbose=True)\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "        \n",
    "_set_env(\"OPENAI_API_KEY\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35808c4",
   "metadata": {},
   "source": [
    "채팅 모델을 로드하고 메시지 목록으로 호출할 수 있습니다.\n",
    "\n",
    "결과는 특정 `response_metadata`를 가진 `AIMessage`임을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e9e37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e17f60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='미국에서 범고래를 관찰하기 좋은 장소로는 다음과 같은 곳들이 있습니다:\\n\\n1. **샌환 제도(San Juan Islands), 워싱턴주**: 이 지역은 범고래를 관찰하기에 가장 유명한 장소 중 하나입니다. 특히 여름철에 많은 범고래가 이 지역을 찾습니다. 일대에서는 배를 타고 관찰할 수 있는 투어도 많이 운영되고 있습니다.\\n\\n2. **올림픽 해안 국립공원(Olympic National Park), 워싱턴주**: 이곳은 태평양을 접하고 있어 해안가에서 범고래를 볼 수 있는 기회가 있습니다. 특히 스프링 웨일링 시즌에 주목할 만합니다.\\n\\n3. **푸겟 사운드(Puget Sound), 워싱턴주**: 이 지역도 범고래를 관찰하기에 적합한 장소입니다. 이곳에서는 종종 캐하기, 회색고래 같은 다른 해양생물도 볼 수 있습니다.\\n\\n4. **몬터레이 베이(Monterey Bay), 캘리포니아**: 비록 주로 회색고래와 돌고래로 유명하지만, 가끔씩 몬터레이 베이에서도 범고래를 볼 수 있습니다. 이곳에서는 다양한 바다 생물을 관찰할 수 있는 투어가 많이 있습니다.\\n\\n5. **캘리포니아 해안**: 남부 캘리포니아의 해안을 따라, 특히 봄철과 가을철 이동 시즌 동안 범고래를 가끔씩 볼 수 있습니다.\\n\\n범고래를 관찰할 때는 지역 생태 시스템과 해양 생물에 미치는 영향을 최소화하면서 자연을 존중하는 태도를 갖는 것이 중요합니다. 즐거운 관찰 경험이 되기를 바랍니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 392, 'prompt_tokens': 79, 'total_tokens': 471, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CLNuPQWIumG8BqZw2Ukxm2T3zWzZt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--105c53ab-2eea-445b-9bfe-3f19ec692ef8-0', usage_metadata={'input_tokens': 79, 'output_tokens': 392, 'total_tokens': 471, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6597c9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 392,\n",
       "  'prompt_tokens': 79,\n",
       "  'total_tokens': 471,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-2024-08-06',\n",
       " 'system_fingerprint': 'fp_f33640a400',\n",
       " 'id': 'chatcmpl-CLNuPQWIumG8BqZw2Ukxm2T3zWzZt',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a02e1",
   "metadata": {},
   "source": [
    "## Tools(도구)\n",
    "\n",
    "도구는 모델이 외부 시스템과 상호작용해야 할 때 유용합니다.\n",
    "\n",
    "외부 시스템(예: API)은 자연어 대신 특정 입력 스키마나 페이로드를 요구하는 경우가 많습니다.\n",
    "\n",
    "예를 들어 API를 도구로 바인딩하면, 모델이 필요한 입력 스키마를 인식하도록 합니다.\n",
    "\n",
    "모델은 사용자의 자연어 입력에 따라 도구를 호출할지 선택합니다.\n",
    "\n",
    "그리고 해당 도구의 스키마를 준수하는 출력을 반환합니다. \n",
    "\n",
    "[많은 LLM 공급자가 도구 호출을 지원](https://python.langchain.com/v0.1/docs/integrations/chat/)하며, LangChain의 [도구 호출 인터페이스](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/)는 간단합니다. \n",
    " \n",
    "`ChatModel.bind_tools(function)`에 어떤 Python `function`든 전달하기만 하면 됩니다.\n",
    "\n",
    "![](https://i.imgur.com/A6umx0G.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927d5188",
   "metadata": {},
   "source": [
    "도구 호출의 간단한 예시를 살펴보겠습니다!\n",
    " \n",
    "`multiply` 함수가 우리의 도구입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8598d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiply a and b.\n",
    "    \n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4578b",
   "metadata": {},
   "source": [
    "입력값(예: `\"2에 3을 곱하면 얼마인가요?\"`)을 전달하면 도구 호출이 반환되는 것을 확인할 수 있습니다.\n",
    "\n",
    "이 도구 호출은 호출할 함수의 이름과 함께 함수의 입력 스키마에 맞는 특정 인수를 포함합니다.\n",
    "\n",
    "```json\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f125d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_cool = llm_with_tools.invoke([HumanMessage(\"2에 3을 곱하면 얼마인가요?\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f2350a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_S8ST5hiD6wgNtgqsB69eT1sa',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_cool.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433a7f8",
   "metadata": {},
   "source": [
    "## 메시지를 상태로 사용하기\n",
    "\n",
    "이러한 기반이 마련되었으므로 이제 그래프 상태에서 [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages)를 사용할 수 있습니다.\n",
    "\n",
    "`MessagesState` 상태를 단일 키 `messages`를 가진 `TypedDict`로 정의해 보겠습니다.\n",
    "\n",
    "`messages`는 위에서 정의한 대로 단순히 메시지 목록입니다(예: `HumanMessage` 등)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5892203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    message: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b9093",
   "metadata": {},
   "source": [
    "## Reducers(리듀서)\n",
    "\n",
    "이제 사소한 문제가 생겼습니다!\n",
    "\n",
    "앞서 논의한 대로, 각 노드는 상태 키 `messages`에 대한 새 값을 반환합니다.\n",
    "\n",
    "하지만 이 새 값은 이전 `messages` 값을 [덮어씁니다](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers).\n",
    " \n",
    "그래프가 실행될 때, 우리는 `messages` 상태 키에 메시지를 **추가**하고 싶습니다.\n",
    " \n",
    "이를 해결하기 위해 [리듀서 함수](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers)를 사용할 수 있습니다.\n",
    "\n",
    "리듀서를 사용하면 상태 업데이트가 수행되는 방식을 지정할 수 있습니다.\n",
    "\n",
    "리듀서 함수가 지정되지 않으면, 앞서 본 것처럼 키에 대한 업데이트가 *기존 값을 덮어씁니다*.\n",
    " \n",
    "그러나 메시지를 추가하려면 미리 정의된 `add_messages` 리듀서를 사용할 수 있습니다.\n",
    "\n",
    "이렇게 하면 모든 메시지가 기존 메시지 목록에 추가됩니다.\n",
    "\n",
    "`messages` 키에 `add_messages` 리듀서 함수를 메타데이터로 주석 처리하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c648f",
   "metadata": {},
   "source": [
    "그래프 상태에 메시지 목록을 갖는 것이 매우 흔하기 때문에, LangGraph에는 미리 구축된 [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)가 있습니다! \n",
    "\n",
    "`MessagesState`는 다음과 같이 정의됩니다:\n",
    "\n",
    "* 미리 구축된 단일 `messages` 키로 구성\n",
    "* `AnyMessage` 객체들의 리스트 형태\n",
    "* `add_messages` 리듀서를 사용\n",
    "\n",
    "위에서 보여준 것처럼 커스텀 `TypedDict`를 정의하는 것보다 덜 장황하기 때문에 일반적으로 `MessagesState`를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2adabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class CustomState(MessagesState):\n",
    "    # messages 외에 필요한 키를 추가하세요. messages는 미리 빌드되어 있습니다.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60d4393",
   "metadata": {},
   "source": [
    "좀 더 깊이 들어가서, `add_messages` 리듀서가 독립적으로 어떻게 작동하는지 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eace3dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}, id='e29e4caa-516f-414d-bdfe-0c2437637a24'),\n",
       " HumanMessage(content='해양 생물학에 관한 정보를 찾고 있습니다.', additional_kwargs={}, response_metadata={}, id='6c2ed04b-8099-432c-98d2-37e9c5855eed'),\n",
       " AIMessage(content='물론 도와드릴 수 있어요. 구체적으로 어떤 부분에 관심이 있으신가요?', additional_kwargs={}, response_metadata={}, id='da3ad4f1-4218-4e31-b61b-fa27806fc51c')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_message = [\n",
    "    AIMessage(\"안녕하세요! 무엇을 도와드릴까요?\"), \n",
    "    HumanMessage(\"해양 생물학에 관한 정보를 찾고 있습니다.\")\n",
    "]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(\"물론 도와드릴 수 있어요. 구체적으로 어떤 부분에 관심이 있으신가요?\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_message, [new_message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576a9a2",
   "metadata": {},
   "source": [
    "## 그래프\n",
    "\n",
    "이제 `MessagesState`를 그래프와 함께 사용해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a49a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "def tool_calling_llm(state: CustomState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return CustomState(messages=[response])\n",
    "\n",
    "builder = StateGraph(CustomState)\n",
    "builder.add_node(\"llm\", llm_with_tools)\n",
    "builder.set_entry_point(\"llm\")\n",
    "builder.set_finish_point(\"llm\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87c262d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tllm(llm)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> llm;\n",
      "\tllm --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99cdf7c",
   "metadata": {},
   "source": [
    "`안녕!`를 입력하면 LLM은 도구 호출 없이 응답합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcce674",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m안녕!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      4\u001b[39m     m.pretty_print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2657\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2655\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2656\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2657\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2658\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2662\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2663\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2664\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2666\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2667\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5710\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5703\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5704\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5705\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5708\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5709\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5711\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5712\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5713\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5714\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:396\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    395\u001b[39m         \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    397\u001b[39m             stop=stop,\n\u001b[32m    398\u001b[39m             callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    399\u001b[39m             tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    400\u001b[39m             metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    401\u001b[39m             run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    402\u001b[39m             run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    403\u001b[39m             **kwargs,\n\u001b[32m    404\u001b[39m         ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:381\u001b[39m, in \u001b[36mBaseChatModel._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=convert_to_messages(model_input))\n\u001b[32m    377\u001b[39m msg = (\n\u001b[32m    378\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    379\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    380\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
      "During task with name 'llm' and id '261371ed-3280-65a5-cb17-a2eb7e3f95a1'"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"messages\": [HumanMessage(\"안녕!\")]})\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1f08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
