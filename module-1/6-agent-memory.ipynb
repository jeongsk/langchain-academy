{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13cd1c3e",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/agent-memory.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239417-lesson-7-agent-with-memory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c451ffd-a18b-4412-85fa-85186824dd03",
   "metadata": {},
   "source": [
    "# 에이전트 메모리\n",
    "\n",
    "## 복습\n",
    "\n",
    "이전 시간에 다음과 같은 기능을 가진 에이전트를 구축했습니다:\n",
    "\n",
    "* `act(행동)` - 모델이 특정 도구를 호출할 수 있도록 합니다\n",
    "* `observe(관찰)` - 도구 출력을 모델로 다시 전달합니다\n",
    "* `reason(추론)` - 모델이 도구 출력에 대해 추론하여 다음 행동(예: 다른 도구 호출 또는 직접 응답)을 결정할 수 있도록 합니다\n",
    "\n",
    "![](https://i.imgur.com/eEknwcr.png)\n",
    "\n",
    "## 목표\n",
    "\n",
    "이제 에이전트에 메모리 기능을 도입하여 확장해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b4b45b-cbaa-41b1-b3ed-f6b0645be3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b0cfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\", override=True)\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eff247-a2aa-4f7a-8be1-73dfebfecc63",
   "metadata": {},
   "source": [
    "[tracing](https://docs.smith.langchain.com/concepts/tracing)을 위해 [LangSmith](https://docs.smith.langchain.com/)를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74ef2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f123b-db5d-4816-a6a3-2e4247611512",
   "metadata": {},
   "source": [
    "다음은 이전 시간에 작성했던 코드와 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46647bbe-def5-4ea7-a315-1de8d97c8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9092b40-20c4-4872-b0ed-be1b53a15ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(\n",
    "    content=\"당신은 일련의 입력값에 대해 산술 연산을 수행하는 임무를 맡은 유용한 보조자입니다.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "771123a3-91ac-4076-92c0-93bcd69cf048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830b7ae-3673-4cc6-8627-4740b7b8b217",
   "metadata": {},
   "source": [
    "## Memory(메모리)\n",
    "\n",
    "에이전트를 실행해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a71a0-1337-44d4-971d-f80c367bd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "3과 4를 더하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_fNWjnNW7D6BJMrzh5dkjlolX)\n",
      " Call ID: call_fNWjnNW7D6BJMrzh5dkjlolX\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "3과 4를 더하면 7입니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"3과 4를 더하세요.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8128c-f4a5-4dee-b20b-3245bd33f6b3",
   "metadata": {},
   "source": [
    "자, 이제 2를 곱해 보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cc1d7-e6de-4d86-8958-8cf7446f4c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "그 값을 2를 곱하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "곱하고자 하는 값을 제공해 주시면, 제가 그 값에 2를 곱할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"그 값을 2를 곱하세요.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e65f3c-e1dc-4a62-b8ab-02b33a6ff268",
   "metadata": {},
   "source": [
    "대화에서 이전 계산 결과값 7에 대한 기억을 유지하지 않습니다!\n",
    "\n",
    "이는 [상태가 일시적](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220)이기 때문입니다.\n",
    "\n",
    "물론 이는 중단이 있는 다중 대화 진행 능력을 제한합니다.\n",
    "\n",
    "이를 해결하기 위해 [지속성](https://langchain-ai.github.io/langgraph/how-tos/persistence/)을 활용할 수 있습니다!\n",
    "\n",
    "LangGraph는 체크포인터(checkpointer)를 사용해 각 단계 후 그래프 상태를 자동 저장합니다.\n",
    "\n",
    "이 내장 지속성 계층은 메모리를 제공하여 LangGraph가 마지막 상태 업데이트에서 작업을 재개할 수 있게 합니다.\n",
    "\n",
    "사용하기 가장 쉬운 체크포인터 중 하나는 그래프 상태를 위한 인메모리 키-값 저장소인 `MemorySaver`입니다.\n",
    "\n",
    "체크포인터와 함께 그래프를 컴파일하기만 하면, 그래프에 메모리가 부여됩니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "637fcd79-3896-42e4-9131-e03b123a0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "react_graph_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff8fc3bf-3999-47cb-af34-06b2b94d7192",
   "metadata": {},
   "source": [
    "메모리를 사용할 때는 `thread_id`를 지정해야 합니다.\n",
    "\n",
    "이 `thread_id`는 그래프 상태 컬렉션을 저장합니다.\n",
    "\n",
    "다음은 개념도입니다:\n",
    "\n",
    "* 체크포인터는 그래프의 각 단계에서 상태를 기록합니다\n",
    "* 이 체크포인트는 스레드에 저장됩니다\n",
    "* 향후 `thread_id`를 사용하여 해당 스레드에 접근할 수 있습니다\n",
    "\n",
    "![](https://i.imgur.com/komusXJ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722a1d6-e73c-4023-86ed-8b07d392278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "3과 4를 더하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_AkLtVAqsdrMHh52JXor03fOc)\n",
      " Call ID: call_AkLtVAqsdrMHh52JXor03fOc\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "3과 4를 더하면 7입니다.\n"
     ]
    }
   ],
   "source": [
    "# Specify a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "messages = [HumanMessage(content=\"3과 4를 더하세요.\")]\n",
    "\n",
    "# Run\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a8a16-6bf1-48e2-a889-ae04a37c7a2b",
   "metadata": {},
   "source": [
    "동일한 `thread_id`를 전달하면, 이전에 기록된 상태 체크포인트에서 진행할 수 있습니다!\n",
    "\n",
    "이 경우, 위 대화 내용이 스레드에 캡처됩니다.\n",
    "\n",
    "전달한 `HumanMessage`(`\"그 값에 2로 곱하세요.\"`)는 위 대화 끝에 추가됩니다.\n",
    "\n",
    "따라서 모델은 이제 `그 값`이 `3과 4의 합은 7입니다.`를 가리킨다는 것을 알게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38c6ef-8bfb-4c66-9214-6f474c9b8451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "3과 4를 더하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_AkLtVAqsdrMHh52JXor03fOc)\n",
      " Call ID: call_AkLtVAqsdrMHh52JXor03fOc\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "3과 4를 더하면 7입니다.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "그 값에 2로 곱하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_x8bjDpwODA21X2ZlHDAEnCwi)\n",
      " Call ID: call_x8bjDpwODA21X2ZlHDAEnCwi\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "7에 2를 곱하면 14입니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"그 값에 2로 곱하세요.\")]\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72986c-ff6f-4f81-b585-d268e2710e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
