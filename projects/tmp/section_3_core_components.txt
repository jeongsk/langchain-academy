Transformer의 핵심 구성 요소

3.1 입력 임베딩(Input Embedding)
입력 데이터를 고차원 벡터 공간으로 변환하는 과정으로, 각각의 단어를 고정된 크기의 벡터로 표현한다. 임베딩 벡터는 모델이 텍스트의 의미를 학습하는 기반이 된다.

3.2 위치 인코딩(Positional Encoding)
Transformer는 순차적 구조가 없으므로, 단어의 위치 정보를 추가하기 위해 위치 인코딩을 사용한다. 사인과 코사인 함수를 활용한 주기적인 패턴으로 위치 정보를 벡터에 더해 위치 의존성을 반영한다.

3.3 셀프 어텐션(Self-attention) 메커니즘
입력 시퀀스 내 각 단어가 다른 단어와의 상관관계를 학습한다. 쿼리, 키, 값 벡터를 이용해 단어 간의 유사도를 측정하고 중요한 정보를 강조한다.

3.4 멀티-헤드 어텐션(Multi-head Attention)
여러 개의 셀프 어텐션을 병렬로 수행하여 다양한 표현 공간에서 정보를 추출한다. 이를 통해 모델의 학습 능력과 일반화 성능을 개선한다.

3.5 포지션-와이즈 피드포워드 네트워크(Position-wise Feedforward Network)
각 위치별로 독립적으로 적용되는 완전 연결층으로, 비선형 변환을 통해 표현력을 증대시킨다.

3.6 잔차 연결(Residual Connection)과 레이어 노멀라이제이션(Layer Normalization)
딥 네트워크 학습 안정화를 위해 잔차 연결을 사용하며, 각 층의 출력을 정규화하여 학습 속도를 높인다.