{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d140c86",
   "metadata": {},
   "source": [
    "## STORM: 연구를 위한 멀티 에이전트\n",
    "\n",
    "### 개요\n",
    "\n",
    "STORM(Synthesis of Topic Outline through Retrieval and Multi-perspective Question Asking)은 Stanford 대학에서 개발한 LLM 기반의 지식 큐레이션 시스템입니다. 이 시스템은 인터넷 리서치를 통해 Wikipedia 수준의 포괄적이고 체계적인 장문의 기사를 자동으로 생성하는 것을 목표로 합니다.\n",
    "\n",
    "![](https://github.com/stanford-oval/storm/raw/main/assets/two_stages.jpg)\n",
    "\n",
    "### 핵심 아키텍처\n",
    "\n",
    "STORM은 두 단계의 파이프라인으로 구성됩니다:\n",
    "\n",
    "1. **사전 작성 단계(Pre-writing Stage)**\n",
    "   - 인터넷 기반 리서치를 수행하여 참고 자료 수집\n",
    "   - 다양한 관점(perspective) 발견\n",
    "   - 주제에 대한 개요(outline) 생성\n",
    "\n",
    "2. **작성 단계(Writing Stage)**\n",
    "   - 생성된 개요와 수집된 참고 자료를 활용\n",
    "   - 인용(citation)이 포함된 전체 기사 작성\n",
    "\n",
    "### 멀티 에이전트 접근법\n",
    "\n",
    "STORM의 핵심은 **관점 기반 질문 생성(Perspective-Guided Question Asking)** 과 **시뮬레이션된 대화(Simulated Conversation)** 전략입니다:\n",
    "\n",
    "- **다양한 관점 발견**: 유사한 주제의 기존 기사들을 조사하여 다양한 시각을 발견하고, 이를 질문 생성 과정에 활용\n",
    "- **역할 기반 대화 시뮬레이션**: Wikipedia 작성자와 주제 전문가 간의 대화를 시뮬레이션\n",
    "  - 작성자 에이전트: 다양한 관점에서 질문 제기\n",
    "  - 전문가 에이전트: 인터넷 소스에 기반한 답변 제공\n",
    "  - 이를 통해 이해도를 업데이트하고 후속 질문 생성\n",
    "\n",
    "### Co-STORM: 협업 확장\n",
    "\n",
    "Co-STORM은 STORM을 협업 기능으로 확장한 버전으로, 다음과 같은 멀티 에이전트 구성을 포함합니다:\n",
    "\n",
    "\n",
    "- **LLM 전문가 에이전트**: 외부 소스에 기반한 답변 생성 및 후속 질문 제기\n",
    "- **중재자 에이전트(Moderator)**: 발견된 정보에서 영감을 받은 사고를 자극하는 질문 생성\n",
    "- **동적 마인드맵**: 정보를 계층적으로 정리하여 인간과 시스템 간의 공유 개념 공간 생성\n",
    "\n",
    "![](https://github.com/stanford-oval/storm/raw/main/assets/co-storm-workflow.jpg)\n",
    "\n",
    "### 주요 특징\n",
    "\n",
    "- **포괄적 커버리지**: 다양한 관점에서 주제를 탐색하여 Wikipedia 수준의 광범위한 내용 생성\n",
    "- **구조화된 정보**: 자동으로 생성된 개요를 통해 체계적으로 정보 조직\n",
    "- **신뢰할 수 있는 출처**: 인터넷 소스에 기반하여 모든 정보에 인용 포함\n",
    "- **평가 검증**: FreshWiki 데이터셋을 통한 평가에서 기존 방법 대비 조직성 25%, 커버리지 10% 향상\n",
    "\n",
    "STORM은 복잡한 연구 작업을 자동화하고, 다양한 관점에서 정보를 종합하며, 신뢰할 수 있는 장문의 리포트를 생성하는 멀티 에이전트 시스템의 우수한 사례입니다.\n",
    "\n",
    "---\n",
    "\n",
    "- 참고 자료: https://wikidocs.net/270693\n",
    "- 관련 논문: https://arxiv.org/abs/2402.14207\n",
    "- GitHub 저장소: https://github.com/stanford-oval/storm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb325a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "112e4070",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84dd060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\", override=True)\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\"\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c360a",
   "metadata": {},
   "source": [
    "## 분석가 생성: Human-In-The-Loop\n",
    "\n",
    "분석가 생성이 필요한 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e07bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    \"\"\"분석가 속성과 메타데이터를 정의\"\"\"\n",
    "\n",
    "    affiliation: Annotated[str, Field(description=\"분석가의 주요 소속 기관\")]\n",
    "    name: Annotated[str, Field(description=\"분석가 이름\")]\n",
    "    role: Annotated[str, Field(description=\"주제 맥락에서의 분석가의 역할\")]\n",
    "    description: Annotated[\n",
    "        str, Field(description=\"분석가의 관심사, 우려 사항 및 동기 설명\")\n",
    "    ]\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return (\n",
    "            f\"이름: {self.name}\\n\"\n",
    "            \"역할: {self.role}\\n\"\n",
    "            \"소속 기관: {self.affiliation}\\n\"\n",
    "            \"설명: {self.description}\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    \"\"\"분석가들의 집합\"\"\"\n",
    "\n",
    "    analysts: Annotated[\n",
    "        list[Analyst],\n",
    "        Field(description=\"분석가들의 역할 및 소속 기관을 포함한 종합 목록\"),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6778d7",
   "metadata": {},
   "source": [
    "### 분석가 생성 상태 및 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61f39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 정의\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: Annotated[str, \"연구 주제\"]\n",
    "    max_analysts: Annotated[int, \"생성할 분석가의 최대 수\"]\n",
    "    human_analyst_feedback: Annotated[str, \"휴먼 피드백\"]\n",
    "    analysts: Annotated[list[Analyst], \"분석가 목록\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46502385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석가 생성 프롬프트\n",
    "analyst_instructions = \"\"\"AI 애널리스트 페르소나 세트를 생성하는 임무를 맡았습니다.\n",
    "\n",
    "다음 지침을 주의 깊게 따르십시오:\n",
    "\n",
    "1. 먼저 연구 주제를 검토하십시오:\n",
    "\n",
    "{topic}\n",
    "\n",
    "2. 애널리스트 생성 가이드로 제공된 선택적 편집 피드백을 검토하십시오:\n",
    "\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3. 위 문서 및/또는 피드백을 바탕으로 가장 흥미로운 테마를 결정하십시오.\n",
    "\n",
    "4. 상위 {max_analysts}개 테마를 선정하십시오.\n",
    "\n",
    "5. 각 테마에 한 명의 애널리스트를 배정하십시오.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcfdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "# 분석가 생성 노드\n",
    "def create_analysts(state: GenerateAnalystsState):\n",
    "    \"\"\"분석가 페르소나를 생성합니다.\"\"\"\n",
    "\n",
    "    topic = state[\"topic\"]\n",
    "    max_analysts = state[\"max_analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "\n",
    "    llm_with_structured = llm.with_structured_output(Perspectives)\n",
    "\n",
    "    system_message = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        human_analyst_feedback=human_analyst_feedback,\n",
    "        max_analysts=max_analysts,\n",
    "    )\n",
    "\n",
    "    response = llm_with_structured.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=\"Generate the set of analysts.\")]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"analysts\": response.analysts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47c51fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysts': [Analyst(affiliation='KAIST 인공지능연구소', name='김지훈', role='멀티 에이전트 시스템 이론 연구원', description='멀티 에이전트 간 협력과 경쟁 모델을 연구하며, 분산 인공지능과 협업 알고리즘의 이론적 기반을 탐구하는 전문가.'),\n",
       "  Analyst(affiliation='서울대학교 컴퓨터공학과', name='이수민', role='멀티 에이전트 강화학습 연구원', description='멀티 에이전트 환경에서의 강화 학습 알고리즘 개발 및 응용에 집중하며, 자율 에이전트 간 상호작용 최적화 연구를 수행.'),\n",
       "  Analyst(affiliation='네이버 AI 연구소', name='박현우', role='멀티 에이전트 기반 실시간 시스템 개발자', description='실시간 멀티 에이전트 시스템 설계 및 구현 전문가로, 분산 시스템과 에이전트 커뮤니케이션 프로토콜 개발 경험 다수 보유.')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_analysts({\"topic\": \"멀티 에이전트\", \"max_analysts\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b276ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 피드백 노드\n",
    "def human_feedback(state: GenerateAnalystsState):\n",
    "    \"\"\"사용자 피드백을 받기 위한 중단점 노드\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b976f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: GenerateAnalystsState):\n",
    "    \"\"\"워크플로우의 다음 노드를 결정합니다.\"\"\"\n",
    "\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "    return \"___end___\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation-introduction-to-langgraph (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
