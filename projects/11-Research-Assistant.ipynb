{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d140c86",
   "metadata": {},
   "source": [
    "## STORM: 연구를 위한 멀티 에이전트\n",
    "\n",
    "### 개요\n",
    "\n",
    "STORM(Synthesis of Topic Outline through Retrieval and Multi-perspective Question Asking)은 Stanford 대학에서 개발한 LLM 기반의 지식 큐레이션 시스템입니다. 이 시스템은 인터넷 리서치를 통해 Wikipedia 수준의 포괄적이고 체계적인 장문의 기사를 자동으로 생성하는 것을 목표로 합니다.\n",
    "\n",
    "![](https://github.com/stanford-oval/storm/raw/main/assets/two_stages.jpg)\n",
    "\n",
    "### 핵심 아키텍처\n",
    "\n",
    "STORM은 두 단계의 파이프라인으로 구성됩니다:\n",
    "\n",
    "1. **사전 작성 단계(Pre-writing Stage)**\n",
    "   - 인터넷 기반 리서치를 수행하여 참고 자료 수집\n",
    "   - 다양한 관점(perspective) 발견\n",
    "   - 주제에 대한 개요(outline) 생성\n",
    "\n",
    "2. **작성 단계(Writing Stage)**\n",
    "   - 생성된 개요와 수집된 참고 자료를 활용\n",
    "   - 인용(citation)이 포함된 전체 기사 작성\n",
    "\n",
    "### 멀티 에이전트 접근법\n",
    "\n",
    "STORM의 핵심은 **관점 기반 질문 생성(Perspective-Guided Question Asking)** 과 **시뮬레이션된 대화(Simulated Conversation)** 전략입니다:\n",
    "\n",
    "- **다양한 관점 발견**: 유사한 주제의 기존 기사들을 조사하여 다양한 시각을 발견하고, 이를 질문 생성 과정에 활용\n",
    "- **역할 기반 대화 시뮬레이션**: Wikipedia 작성자와 주제 전문가 간의 대화를 시뮬레이션\n",
    "  - 작성자 에이전트: 다양한 관점에서 질문 제기\n",
    "  - 전문가 에이전트: 인터넷 소스에 기반한 답변 제공\n",
    "  - 이를 통해 이해도를 업데이트하고 후속 질문 생성\n",
    "\n",
    "### Co-STORM: 협업 확장\n",
    "\n",
    "Co-STORM은 STORM을 협업 기능으로 확장한 버전으로, 다음과 같은 멀티 에이전트 구성을 포함합니다:\n",
    "\n",
    "\n",
    "- **LLM 전문가 에이전트**: 외부 소스에 기반한 답변 생성 및 후속 질문 제기\n",
    "- **중재자 에이전트(Moderator)**: 발견된 정보에서 영감을 받은 사고를 자극하는 질문 생성\n",
    "- **동적 마인드맵**: 정보를 계층적으로 정리하여 인간과 시스템 간의 공유 개념 공간 생성\n",
    "\n",
    "![](https://github.com/stanford-oval/storm/raw/main/assets/co-storm-workflow.jpg)\n",
    "\n",
    "### 주요 특징\n",
    "\n",
    "- **포괄적 커버리지**: 다양한 관점에서 주제를 탐색하여 Wikipedia 수준의 광범위한 내용 생성\n",
    "- **구조화된 정보**: 자동으로 생성된 개요를 통해 체계적으로 정보 조직\n",
    "- **신뢰할 수 있는 출처**: 인터넷 소스에 기반하여 모든 정보에 인용 포함\n",
    "- **평가 검증**: FreshWiki 데이터셋을 통한 평가에서 기존 방법 대비 조직성 25%, 커버리지 10% 향상\n",
    "\n",
    "STORM은 복잡한 연구 작업을 자동화하고, 다양한 관점에서 정보를 종합하며, 신뢰할 수 있는 장문의 리포트를 생성하는 멀티 에이전트 시스템의 우수한 사례입니다.\n",
    "\n",
    "---\n",
    "\n",
    "- 참고 자료: https://wikidocs.net/270693\n",
    "- 관련 논문: https://arxiv.org/abs/2402.14207\n",
    "- GitHub 저장소: https://github.com/stanford-oval/storm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb325a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "112e4070",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dd060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\", override=True)\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\"\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c360a",
   "metadata": {},
   "source": [
    "## 분석가 생성 에이전트 with Human-In-The-Loop\n",
    "\n",
    "분석가 생성이 필요한 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e07bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    \"\"\"분석가 속성과 메타데이터를 정의\"\"\"\n",
    "\n",
    "    affiliation: Annotated[str, Field(description=\"분석가의 주요 소속 기관\")]\n",
    "    name: Annotated[str, Field(description=\"분석가 이름\")]\n",
    "    role: Annotated[str, Field(description=\"주제 맥락에서의 분석가의 역할\")]\n",
    "    description: Annotated[\n",
    "        str, Field(description=\"분석가의 관심사, 우려 사항 및 동기 설명\")\n",
    "    ]\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return (\n",
    "            f\"이름: {self.name}\\n\"\n",
    "            f\"역할: {self.role}\\n\"\n",
    "            f\"소속 기관: {self.affiliation}\\n\"\n",
    "            f\"설명: {self.description}\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    \"\"\"분석가들의 집합\"\"\"\n",
    "\n",
    "    analysts: Annotated[\n",
    "        list[Analyst],\n",
    "        Field(description=\"분석가들의 역할 및 소속 기관을 포함한 종합 목록\"),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6778d7",
   "metadata": {},
   "source": [
    "### 분석가 생성 상태 및 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61f39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 정의\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: Annotated[str, \"연구 주제\"]\n",
    "    max_analysts: Annotated[int, \"생성할 분석가의 최대 수\"]\n",
    "    human_analyst_feedback: Annotated[str, \"휴먼 피드백\"]\n",
    "    analysts: Annotated[list[Analyst], \"분석가 목록\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46502385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석가 생성 프롬프트\n",
    "analyst_instructions = \"\"\"AI 분석가 페르소나 세트를 생성하는 임무를 맡았습니다.\n",
    "\n",
    "다음 지침을 주의 깊게 따르십시오:\n",
    "\n",
    "1. 먼저 연구 주제를 검토하십시오:\n",
    "{topic}\n",
    "\n",
    "2. 분석가 생성 가이드로 제공된 선택적 편집 피드백을 검토하십시오:\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3. 위 문서 및/또는 피드백을 바탕으로 가장 흥미로운 테마를 결정하십시오.\n",
    "\n",
    "4. 상위 {max_analysts}개 테마를 선정하십시오.\n",
    "\n",
    "5. 각 테마에 한 명의 분석가를 배정하십시오.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7bcfdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "# 분석가 생성 노드\n",
    "def create_analysts(state: GenerateAnalystsState):\n",
    "    \"\"\"분석가 페르소나를 생성합니다.\"\"\"\n",
    "\n",
    "    topic = state[\"topic\"]\n",
    "    max_analysts = state[\"max_analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "\n",
    "    llm_with_structured = llm.with_structured_output(Perspectives)\n",
    "\n",
    "    system_message = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        human_analyst_feedback=human_analyst_feedback,\n",
    "        max_analysts=max_analysts,\n",
    "    )\n",
    "\n",
    "    response = llm_with_structured.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=\"Generate the set of analysts.\")]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"analysts\": response.analysts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c51fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysts': [Analyst(affiliation='MIT Computer Science and Artificial Intelligence Laboratory', name='Dr. Clara Zhang', role='Multi-Agent Systems Specialist', description='Dr. Zhang focuses on the coordination mechanisms in multi-agent systems, exploring how autonomous agents can collaborate effectively in dynamic environments to optimize collective outcomes.'),\n",
       "  Analyst(affiliation='Stanford University, Department of Computer Science', name='Prof. Miguel Hernandez', role='Distributed AI Researcher', description='Prof. Hernandez researches decentralized algorithms that enable cooperation and negotiation among multiple agents, emphasizing scalability and robustness in complex multi-agent networks.'),\n",
       "  Analyst(affiliation='DeepMind, Multi-Agent AI Group', name='Dr. Aisha Patel', role='Reinforcement Learning and Multi-Agent Interaction Analyst', description='Dr. Patel investigates reinforcement learning methods for multi-agent interaction, aiming to improve adaptive behaviors and emergent cooperation strategies in artificial agents.')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_analysts({\"topic\": \"멀티 에이전트\", \"max_analysts\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b276ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 피드백 노드\n",
    "def human_feedback(state: GenerateAnalystsState):\n",
    "    \"\"\"사용자 피드백을 받기 위한 중단점 노드\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a9c93",
   "metadata": {},
   "source": [
    "### 분석가 생성 그래프 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509107a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "def should_continue(state: GenerateAnalystsState) -> Literal[\"create_analysts\", END]:\n",
    "    \"\"\"워크플로우의 다음 노드를 결정합니다.\"\"\"\n",
    "\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "    return END\n",
    "\n",
    "\n",
    "builder = StateGraph(GenerateAnalystsState)\n",
    "builder.add_node(create_analysts)\n",
    "builder.add_node(human_feedback)\n",
    "\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\n",
    "    \"human_feedback\", should_continue, {\"create_analysts\": \"create_analysts\", END: END}\n",
    ")\n",
    "builder.set_entry_point(\"create_analysts\")\n",
    "graph = builder.compile(\n",
    "    interrupt_before=[\"human_feedback\"], checkpointer=InMemorySaver()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8274f81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e503e",
   "metadata": {},
   "source": [
    "### 분석가 생성 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07008ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### create_analysts #####\n",
      "{'analysts': [Analyst(affiliation='TechInsights Research Institute', name='Dr. Hana Kim', role='AI Research Analyst', description='Dr. Hana Kim specializes in artificial intelligence methodologies with a focus on retrieval-augmented generation techniques. She analyzes the distinctions between agentic and adaptive RAG, emphasizing how agentic RAG involves autonomous agent-driven data retrieval and synthesis, whereas adaptive RAG adapts the retrieval process dynamically based on context and model feedback.'),\n",
      "              Analyst(affiliation='NextGen AI Solutions', name='Jinsoo Park', role='Machine Learning Engineer and Analyst', description='Jinsoo Park explores practical implementations of RAG frameworks in industry settings. His analysis highlights the differences such as agentic RAG enabling agents to perform goal-directed retrieval autonomously, contrasting with adaptive RAG’s capacity to dynamically adjust retrieval strategies to optimize output relevance and accuracy.'),\n",
      "              Analyst(affiliation='AI Frontier Think Tank', name='Mina Lee', role='Data Scientist and Strategy Analyst', description='Mina Lee focuses on strategic implications of advanced AI architectures. She investigates comparative themes between agentic RAG and adaptive RAG, focusing on adaptability versus agent autonomy. Her insights revolve around how each approach impacts AI performance, user interactions, and scalability in complex data environments.')]}\n",
      "\n",
      "##### __interrupt__ #####\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from random import random\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(configurable={\"thread_id\": random()})\n",
    "\n",
    "inputs = {\n",
    "    \"max_analysts\": 3,\n",
    "    \"topic\": \"Agentic RAG와 Adaptive RAG의 차이점은 무엇인가요?\",\n",
    "}\n",
    "for event in graph.stream(inputs, config=config):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n##### {key} #####\")\n",
    "        pprint(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab4a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysts': [Analyst(affiliation='TechInsights Research Institute', name='Dr. Hana Kim', role='AI Research Analyst', description='Dr. Hana Kim specializes in artificial intelligence methodologies with a focus on retrieval-augmented generation techniques. She analyzes the distinctions between agentic and adaptive RAG, emphasizing how agentic RAG involves autonomous agent-driven data retrieval and synthesis, whereas adaptive RAG adapts the retrieval process dynamically based on context and model feedback.'),\n",
      "              Analyst(affiliation='NextGen AI Solutions', name='Jinsoo Park', role='Machine Learning Engineer and Analyst', description='Jinsoo Park explores practical implementations of RAG frameworks in industry settings. His analysis highlights the differences such as agentic RAG enabling agents to perform goal-directed retrieval autonomously, contrasting with adaptive RAG’s capacity to dynamically adjust retrieval strategies to optimize output relevance and accuracy.'),\n",
      "              Analyst(affiliation='AI Frontier Think Tank', name='Mina Lee', role='Data Scientist and Strategy Analyst', description='Mina Lee focuses on strategic implications of advanced AI architectures. She investigates comparative themes between agentic RAG and adaptive RAG, focusing on adaptability versus agent autonomy. Her insights revolve around how each approach impacts AI performance, user interactions, and scalability in complex data environments.')],\n",
      " 'max_analysts': 3,\n",
      " 'topic': 'Agentic RAG와 Adaptive RAG의 차이점은 무엇인가요?'}\n",
      "('human_feedback',)\n"
     ]
    }
   ],
   "source": [
    "# 현재 상태 스냅샷\n",
    "snapshot = graph.get_state(config)\n",
    "pprint(snapshot.values)\n",
    "pprint(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb64c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### human_feedback #####\n",
      "None\n",
      "\n",
      "##### create_analysts #####\n",
      "{'analysts': [Analyst(affiliation='TechStart Ventures', name='석호필', role='AI Entrepreneur and Analyst', description='스타트업 출신의 석호필은 Agentic RAG와 Adaptive RAG의 차이점을 기업가적 관점에서 분석하며, 각각의 접근법이 실제 서비스 개발과 혁신에 미치는 영향을 탐구한다.'),\n",
      "              Analyst(affiliation='AI Research Institute', name='김유정', role='Machine Learning Researcher', description='AI 연구원 김유정은 Agentic RAG와 Adaptive RAG의 기술적 특성과 작동 메커니즘의 차이를 중심으로 분석한다.'),\n",
      "              Analyst(affiliation='Digital Innovation Lab', name='이준서', role='Systems Analyst', description='시스템 애널리스트 이준서는 Agentic RAG와 Adaptive RAG의 시스템 통합 및 적용 사례를 비교하며 실용적 측면을 평가한다.')]}\n",
      "\n",
      "##### __interrupt__ #####\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# 휴먼 피드백 전달\n",
    "from langgraph.types import Command\n",
    "\n",
    "for event in graph.stream(\n",
    "    Command(\n",
    "        update={\n",
    "            \"human_analyst_feedback\": \"스타트업 출신의 석호필이라는 인물을 추가해 기업가적 관점을 더해주세요.\"\n",
    "        },\n",
    "    ),\n",
    "    config=config,\n",
    "):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n##### {key} #####\")\n",
    "        pprint(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "913e6244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### human_feedback #####\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(\n",
    "    Command(update={\"human_analyst_feedback\": None}),\n",
    "    config=config,\n",
    "):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n##### {key} #####\")\n",
    "        pprint(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bcba8",
   "metadata": {},
   "source": [
    "최종 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0da29cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'topic': 'Agentic RAG와 Adaptive RAG의 차이점은 무엇인가요?', 'max_analysts': 3, 'human_analyst_feedback': None, 'analysts': [Analyst(affiliation='TechStart Ventures', name='석호필', role='AI Entrepreneur and Analyst', description='스타트업 출신의 석호필은 Agentic RAG와 Adaptive RAG의 차이점을 기업가적 관점에서 분석하며, 각각의 접근법이 실제 서비스 개발과 혁신에 미치는 영향을 탐구한다.'), Analyst(affiliation='AI Research Institute', name='김유정', role='Machine Learning Researcher', description='AI 연구원 김유정은 Agentic RAG와 Adaptive RAG의 기술적 특성과 작동 메커니즘의 차이를 중심으로 분석한다.'), Analyst(affiliation='Digital Innovation Lab', name='이준서', role='Systems Analyst', description='시스템 애널리스트 이준서는 Agentic RAG와 Adaptive RAG의 시스템 통합 및 적용 사례를 비교하며 실용적 측면을 평가한다.')]}, next=(), config={'configurable': {'thread_id': '0.9239488424970229', 'checkpoint_ns': '', 'checkpoint_id': '1f0abcad-babc-641e-8004-ee02e8be0e12'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-10-18T02:33:40.569597+00:00', parent_config={'configurable': {'thread_id': '0.9239488424970229', 'checkpoint_ns': '', 'checkpoint_id': '1f0abcad-baa1-6998-8003-2976a539440a'}}, tasks=(), interrupts=())\n"
     ]
    }
   ],
   "source": [
    "# 스냅샷을 가져옵니다.\n",
    "final_state = graph.get_state(config)\n",
    "pprint(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a99468a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 분석가 수: 3\n",
      "================================\n",
      "이름: 석호필\n",
      "역할: AI Entrepreneur and Analyst\n",
      "소속 기관: TechStart Ventures\n",
      "설명: 스타트업 출신의 석호필은 Agentic RAG와 Adaptive RAG의 차이점을 기업가적 관점에서 분석하며, 각각의 접근법이 실제 서비스 개발과 혁신에 미치는 영향을 탐구한다.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "이름: 김유정\n",
      "역할: Machine Learning Researcher\n",
      "소속 기관: AI Research Institute\n",
      "설명: AI 연구원 김유정은 Agentic RAG와 Adaptive RAG의 기술적 특성과 작동 메커니즘의 차이를 중심으로 분석한다.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "이름: 이준서\n",
      "역할: Systems Analyst\n",
      "소속 기관: Digital Innovation Lab\n",
      "설명: 시스템 애널리스트 이준서는 Agentic RAG와 Adaptive RAG의 시스템 통합 및 적용 사례를 비교하며 실용적 측면을 평가한다.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "analysts = final_state.values.get(\"analysts\")\n",
    "print(f\"생성된 분석가 수: {len(analysts)}\", end=\"\\n================================\\n\")\n",
    "\n",
    "for analyst in analysts:\n",
    "    print(analyst.persona)\n",
    "    print(\"- \" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90393571",
   "metadata": {},
   "source": [
    "## 인터뷰 에이전트\n",
    "\n",
    "### 질문 생성 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "364a5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    \"\"\"인터뷰 정보를 저장합니다.\"\"\"\n",
    "\n",
    "    topic: Annotated[str, \"연구 주제\"]\n",
    "    max_num: Annotated[int, \"대화 턴수\"]\n",
    "    context: Annotated[list, operator.add]\n",
    "    analyst: Annotated[Analyst, \"분석가\"]\n",
    "    interview: Annotated[str, \"인터뷰 내용\"]\n",
    "    sections: Annotated[list, \"보고서 섹션 목록\"]\n",
    "\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: Annotated[str, Field(None, description=\"retrieval를 위한 검색 쿼리\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d484c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인터뷰 시스템 프롬프트\n",
    "question_instructions = \"\"\"당신은 특정 주제에 대해 알아보기 위해 전문가를 인터뷰하는 임무를 맡은 분석가입니다.\n",
    "\n",
    "당신의 목표는 주제에 관련된 흥미롭고 구체적인 통찰력을 추출하는 것입니다.\n",
    "\n",
    "1. 흥미로움: 사람들이 놀라워하거나 당연하지 않다고 느낄 만한 통찰력.\n",
    "2. 구체성: 일반론을 피하고 전문가의 구체적인 사례를 포함하는 통찰력.\n",
    "\n",
    "다음은 집중할 주제입니다:\n",
    "{topic}\n",
    "\n",
    "첫 대화를 시작할때에 당신의 인물을 반영하는 이름으로 자신을 소개한 후 질문을 시작하세요.\n",
    "\n",
    "주제에 대한 이해를 심화하고 정교화하기 위해 계속해서 질문을 이어가세요.\n",
    "\n",
    "이해가 충분하다고 판단되면 \"도움 주셔서 정말 감사합니다!\"라고 말하며 인터뷰를 마무리하세요.\n",
    "\n",
    "응답 전반에 걸쳐 제공된 인물과 목표를 반영하여 캐릭터를 유지하는 것을 잊지 마세요.\n",
    "\n",
    "<Persona>\n",
    "{persona}\n",
    "<Persona>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32f5de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 생성 노드\n",
    "def generate_question(state: InterviewState):\n",
    "    \"\"\"통찰력있는 질문을 생성합니다.\"\"\"\n",
    "    analyst = state[\"analyst\"]\n",
    "\n",
    "    system_message = question_instructions.format(\n",
    "        topic=\"Modular RAG 가 기존의 Naive RAG 와 어떤 차이가 있는지와 production level 에서 사용하는 이점\",\n",
    "        persona=analyst.persona,\n",
    "    )\n",
    "    response = llm.invoke([SystemMessage(content=system_message)] + state[\"messages\"])\n",
    "    response.name = \"분석가\"\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b9591fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: 분석가\n",
      "\n",
      "안녕하세요, 김필입니다. Tech Innovators Inc.에서 스타트업과 첨단 기술의 접점에 대해 분석하고 있습니다. 오늘은 ‘Modular RAG가 기존 Naive RAG와 어떻게 다른지, 그리고 production level에서 어떤 이점을 제공하는지’에 대해 자세히 알아보고 싶습니다.\n",
      "\n",
      "먼저, Modular RAG가 Naive RAG와 비교했을 때 어떤 구조적 혹은 기능적 차별점이 있나요? 현장 사례 위주로 설명해 주시면 좋겠습니다.\n"
     ]
    }
   ],
   "source": [
    "analyst = Analyst(\n",
    "    name=\"김필\",\n",
    "    affiliation=\"Tech Innovators Inc.\",\n",
    "    role=\"기업가적 분석가\",\n",
    "    description=\"창업자 출신 분석가로, 기업가 정신과 비즈니스 모델 혁신에 주력합니다. 스타트업 관점에서 적응형 시스템에 대한 통찰력을 제공하며, 유연성과 시장 적응력을 강조합니다.\",\n",
    ")\n",
    "response = generate_question(\n",
    "    {\n",
    "        \"analyst\": analyst,\n",
    "        \"messages\": [],\n",
    "    }\n",
    ")\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53075650",
   "metadata": {},
   "source": [
    "### 도구 정의\n",
    "\n",
    "#### 웹검색 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2a89434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "web_search = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc7fd6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '지난 윔블던에서 무슨 일이 있었나요?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.chosun.com/sports/sports_general/2025/07/13/WL5WE45CLBEGTISJHNMPNE3CXE/',\n",
       "   'title': '“윔블던에 베이글 가게 오픈”… 시비옹테크 여자단식 결승서 진기록',\n",
       "   'content': '테니스 메이저 대회 윔블던 챔피언십 결승에서 1968년 오픈 시대 개막 이후 처음으로 ‘더블 베이글’이 나왔다. 이가 시비옹테크(4위·폴란드)와 어맨다 아니시모바(12위·미국)의 12일(현지 시각) 여자 단식 최종전. 지난 준결승에서 세계 1위 아리나 사발렌카(벨라루스)를 2대1로 꺾고 생애 첫 메이저 대회 결승에 안착한 아니시모바였지만 결과는 허무했다. 한편 올해 윔블던 남자 단식에서는 각각 세계 1·2위인 얀니크 신네르(이탈리아), 카를로스 알카라스(스페인)의 빅 매치가 성사됐다. 쟁쟁한 신예 사이 준결승에까지 오른 ‘노장’ 노바크 조코비치(6위·세르비아)는 11일 신네르와 준결승에서 0대3 완패했다. 얀니크 신네르(세계 1위·이탈리아)와 노바크 조코비치(6위·세르비아), 카를로스 알카라스(2위·스페인)와 테일러 프리츠(5위·미국)가 윔블던 결... 조코비치는 지난 5일 영국 런던 올잉글랜드 클럽에서 열린 윔블던 챔피언십... ‘베컴 조항’을 품은 손흥민(33, LAFC)을 향해 유럽 클럽들의 임대 영입 경쟁이 본격화될 것으로 보인다. 지난 20년간 윔블던 남자단식 우승한 사람이 꼴랑 5명인데 여자는 지난 10년간 10명..',\n",
       "   'score': 0.39733082,\n",
       "   'raw_content': None},\n",
       "  {'url': 'http://m.tennispeople.kr/news/articleView.html?idxno=17168',\n",
       "   'title': '윔블던 컴퓨터 라인 판정 믿어도 되나 - 테니스피플',\n",
       "   'content': '사건은 6일 윔블던 센터 코트에서 열린 여자 단식 16강전 1세트 4-4 상황에서 발생했다. 영국 소니 카르탈과 러시아의 아나스타샤 파블류첸코바가 맞붙',\n",
       "   'score': 0.38498205,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://sports.news.nate.com/view/20250704n04849',\n",
       "   'title': '\"아웃, 인은 기계가 판정\" 148년 전통 깬 윔블던, 인간 선심 사라졌다',\n",
       "   'content': '올해 윔블던 테니스 대회는 148년 역사상 처음으로 인간 선심이 사라진 대회로 기록됐다. CNN은 4일 “윔블던 라인 콜은 전적으로 전자 판독',\n",
       "   'score': 0.34846824,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.0,\n",
       " 'request_id': 'ac668cfc-b51d-4ccf-9bf7-410d3df12998'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search.invoke({\"query\": \"지난 윔블던에서 무슨 일이 있었나요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac7eed",
   "metadata": {},
   "source": [
    "#### 논문 검색 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f49ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import ArxivRetriever\n",
    "\n",
    "arxiv_retriever = ArxivRetriever(\n",
    "    load_max_docs=3,\n",
    "    load_all_available_meta=True,\n",
    "    get_full_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f016ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2024-07-26', 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang', 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.', 'entry_id': 'http://arxiv.org/abs/2407.21059v1', 'published_first_time': '2024-07-26', 'comment': None, 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI', 'cs.IR'], 'links': ['http://arxiv.org/abs/2407.21059v1', 'http://arxiv.org/pdf/2407.21059v1']}, page_content='1\\nModular RAG: Transforming RAG Systems into\\nLEGO-like Reconfigurable Frameworks\\nYunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\\nAbstract—Retrieval-augmented\\nGeneration\\n(RAG)\\nhas\\nmarkedly enhanced the capabilities of Large Language Models\\n(LLMs) in tackling knowledge-intensive tasks. The increasing\\ndemands of application scenarios have driven the evolution\\nof RAG, leading to the integration of advanced retrievers,\\nLLMs and other complementary technologies, which in turn\\nhas amplified the intricacy of RAG systems. However, the rapid\\nadvancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process\\nof “retrieve-then-generate”. In this context, this paper examines\\nthe limitations of the existing RAG paradigm and introduces\\nthe modular RAG framework. By decomposing complex RAG\\nsystems into independent modules and specialized operators, it\\nfacilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a\\nmore advanced design that integrates routing, scheduling, and\\nfusion mechanisms. Drawing on extensive research, this paper\\nfurther identifies prevalent RAG patterns—linear, conditional,\\nbranching, and looping—and offers a comprehensive analysis\\nof their respective implementation nuances. Modular RAG\\npresents\\ninnovative\\nopportunities\\nfor\\nthe\\nconceptualization\\nand deployment of RAG systems. Finally, the paper explores\\nthe potential emergence of new operators and paradigms,\\nestablishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment\\nof RAG technologies.\\nIndex Terms—Retrieval-augmented generation, large language\\nmodel, modular system, information retrieval\\nI. INTRODUCTION\\nL\\nARGE Language Models (LLMs) have demonstrated\\nremarkable capabilities, yet they still face numerous\\nchallenges, such as hallucination and the lag in information up-\\ndates [1]. Retrieval-augmented Generation (RAG), by access-\\ning external knowledge bases, provides LLMs with important\\ncontextual information, significantly enhancing their perfor-\\nmance on knowledge-intensive tasks [2]. Currently, RAG, as\\nan enhancement method, has been widely applied in various\\npractical application scenarios, including knowledge question\\nanswering, recommendation systems, customer service, and\\npersonal assistants. [3]–[6]\\nDuring the nascent stages of RAG , its core framework is\\nconstituted by indexing, retrieval, and generation, a paradigm\\nreferred to as Naive RAG [7]. However, as the complexity\\nof tasks and the demands of applications have escalated, the\\nYunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\\nSystems, Tongji University, Shanghai, 201210, China.\\nYun Xiong is with Shanghai Key Laboratory of Data Science, School of\\nComputer Science, Fudan University, Shanghai, 200438, China.\\nMeng Wang and Haofen Wang are with College of Design and Innovation,\\nTongji University, Shanghai, 20092, China. (Corresponding author: Haofen\\nWang. E-mail: carter.whfcarter@gmail.com)\\nlimitations of Naive RAG have become increasingly apparent.\\nAs depicted in Figure 1, it predominantly hinges on the\\nstraightforward similarity of chunks, result in poor perfor-\\nmance when confronted with complex queries and chunks with\\nsubstantial variability. The primary challenges of Naive RAG\\ninclude: 1) Shallow Understanding of Queries. The semantic\\nsimilarity between a query and document chunk is not always\\nhighly consistent. Relying solely on similarity calculations\\nfor retrieval lacks an in-depth exploration of the relationship\\nbetween the query and the document [8]. 2) Retrieval Re-\\ndundancy and Noise. Feeding all retrieved chunks directly\\ninto LLMs is not always beneficial. Research indicates that\\nan excess of redundant and noisy information may interfere\\nwith the LLM’s identification of key information, thereby\\nincreasing the risk of generating erroneous and hallucinated\\nresponses. [9]\\nTo overcome the aforementioned limitations, '),\n",
       " Document(metadata={'Published': '2024-03-27', 'Title': 'Retrieval-Augmented Generation for Large Language Models: A Survey', 'Authors': 'Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang', 'Summary': \"Large Language Models (LLMs) showcase impressive capabilities but encounter\\nchallenges like hallucination, outdated knowledge, and non-transparent,\\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\\nemerged as a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the generation,\\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\\nupdates and integration of domain-specific information. RAG synergistically\\nmerges LLMs' intrinsic knowledge with the vast, dynamic repositories of\\nexternal databases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\\ntripartite foundation of RAG frameworks, which includes the retrieval, the\\ngeneration and the augmentation techniques. The paper highlights the\\nstate-of-the-art technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG systems.\\nFurthermore, this paper introduces up-to-date evaluation framework and\\nbenchmark. At the end, this article delineates the challenges currently faced\\nand points out prospective avenues for research and development.\", 'entry_id': 'http://arxiv.org/abs/2312.10997v5', 'published_first_time': '2023-12-18', 'comment': 'Ongoing Work', 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI'], 'links': ['http://arxiv.org/abs/2312.10997v5', 'http://arxiv.org/pdf/2312.10997v5']}, page_content='1\\nRetrieval-Augmented Generation for Large\\nLanguage Models: A Survey\\nYunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\\nWangc, and Haofen Wang a,c\\naShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\\nbShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\\ncCollege of Design and Innovation, Tongji University\\nAbstract—Large Language Models (LLMs) showcase impres-\\nsive capabilities but encounter challenges like hallucination,\\noutdated knowledge, and non-transparent, untraceable reasoning\\nprocesses. Retrieval-Augmented Generation (RAG) has emerged\\nas a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the\\ngeneration, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-\\nsic knowledge with the vast, dynamic repositories of external\\ndatabases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing\\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\\nIt meticulously scrutinizes the tripartite foundation of RAG\\nframeworks, which includes the retrieval, the generation and the\\naugmentation techniques. The paper highlights the state-of-the-\\nart technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG\\nsystems. Furthermore, this paper introduces up-to-date evalua-\\ntion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.\\nIndex Terms—Large language model, retrieval-augmented gen-\\neration, natural language processing, information retrieval\\nI. INTRODUCTION\\nL\\nARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing “hallucinations” [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown\\nCorresponding Author.Email:haofen.wang@tongji.edu.cn\\n1Resources\\nare\\navailable\\nat\\nhttps://github.com/Tongji-KGLLM/\\nRAG-Survey\\nin Figure 1. The development trajectory of RAG in the era\\nof large models exhibits several distinct stage characteristics.\\nInitially, RAG’s inception coincided with the rise of the\\nTransformer architecture, focusing on enhancing language\\nmodels by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques\\n[3]–[5].The subsequent arrival of ChatGPT [6] marked a\\npivotal moment, with LLM demonstrating powerful in context\\nlearning (ICL) capabilities. RAG research shifted towards\\nproviding better information for LLMs to answer more com-\\nplex and knowledge-intensive tasks during the inference stage,\\nleading to rapid development in RAG studies. As research\\nprogressed, the enhancement of RAG was no longer limited\\nto the inference stage but began to incorporate more with LLM\\nfine-tuning techniques.\\nThe burgeoning field of RAG has experienced swift growth,\\nyet it has not been accompanied by a systematic synthesis that\\ncould clarify its broader trajectory. Thi'),\n",
       " Document(metadata={'Published': '2025-10-11', 'Title': 'MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning', 'Authors': 'Thang Nguyen, Peter Chin, Yu-Wing Tai', 'Summary': 'We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\\n(RAG) that addresses the inherent ambiguities and reasoning challenges in\\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely on\\nend-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates\\na collaborative set of specialized AI agents: Planner, Step Definer, Extractor,\\nand QA Agents, each responsible for a distinct stage of the RAG pipeline. By\\ndecomposing tasks into subtasks such as query disambiguation, evidence\\nextraction, and answer synthesis, and enabling agents to communicate\\nintermediate reasoning via chain-of-thought prompting, MA-RAG progressively\\nrefines retrieval and synthesis while maintaining modular interpretability.\\nExtensive experiments on multi-hop and ambiguous QA benchmarks, including NQ,\\nHotpotQA, 2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly\\noutperforms standalone LLMs and existing RAG methods across all model scales.\\nNotably, even a small LLaMA3-8B model equipped with MA-RAG surpasses larger\\nstandalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\\nstate-of-the-art results on challenging multi-hop datasets. Ablation studies\\nreveal that both the planner and extractor agents are critical for multi-hop\\nreasoning, and that high-capacity models are especially important for the QA\\nagent to synthesize answers effectively. Beyond general-domain QA, MA-RAG\\ngeneralizes to specialized domains such as medical QA, achieving competitive\\nperformance against domain-specific models without any domain-specific\\nfine-tuning. Our results highlight the effectiveness of collaborative, modular\\nreasoning in retrieval-augmented systems: MA-RAG not only improves answer\\naccuracy and robustness but also provides interpretable intermediate reasoning\\nsteps, establishing a new paradigm for efficient and reliable multi-agent RAG.', 'entry_id': 'http://arxiv.org/abs/2505.20096v2', 'published_first_time': '2025-05-26', 'comment': None, 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI'], 'links': ['http://arxiv.org/abs/2505.20096v2', 'http://arxiv.org/pdf/2505.20096v2']}, page_content='MA-RAG: MULTI-AGENT RETRIEVAL-AUGMENTED\\nGENERATION\\nVIA\\nCOLLABORATIVE\\nCHAIN-OF-\\nTHOUGHT REASONING\\nThang Nguyen & Peter Chin & Yu-Wing Tai\\nDartmouth College\\n{thangnv.th, peter.chin, yu-wing.tai}@dartmouth.edu\\nABSTRACT\\nWe present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Gener-\\nation (RAG) that addresses the inherent ambiguities and reasoning challenges in\\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely\\non end-to-end fine-tuning or isolated component enhancements, MA-RAG orches-\\ntrates a collaborative set of specialized AI agents: Planner, Step Definer, Extrac-\\ntor, and QA Agents, each responsible for a distinct stage of the RAG pipeline.\\nBy decomposing tasks into subtasks such as query disambiguation, evidence ex-\\ntraction, and answer synthesis, and enabling agents to communicate intermedi-\\nate reasoning via chain-of-thought prompting, MA-RAG progressively refines re-\\ntrieval and synthesis while maintaining modular interpretability. Extensive exper-\\niments on multi-hop and ambiguous QA benchmarks, including NQ, HotpotQA,\\n2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly outperforms\\nstandalone LLMs and existing RAG methods across all model scales. Notably,\\neven a small LLaMA3-8B model equipped with MA-RAG surpasses larger stan-\\ndalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\\nstate-of-the-art results on challenging multi-hop datasets. Ablation studies reveal\\nthat both the planner and extractor agents are critical for multi-hop reasoning,\\nand that high-capacity models are especially important for the QA agent to syn-\\nthesize answers effectively. Beyond general-domain QA, MA-RAG generalizes\\nto specialized domains such as medical QA, achieving competitive performance\\nagainst domain-specific models without any domain-specific fine-tuning. Our re-\\nsults highlight the effectiveness of collaborative, modular reasoning in retrieval-\\naugmented systems: MA-RAG not only improves answer accuracy and robustness\\nbut also provides interpretable intermediate reasoning steps, establishing a new\\nparadigm for efficient and reliable multi-agent RAG1.\\n1\\nINTRODUCTION\\nRecent advances in natural language processing have driven the development of Retrieval-\\nAugmented Generation (RAG) models, which aim to enhance the factual accuracy and contextual\\nrelevance of generated text by integrating external knowledge sources (Lewis et al., 2020; Guu et al.,\\n2020; Izacard & Grave, 2021; Lin et al., 2024). These systems address core limitations of Large Lan-\\nguage Models (LLMs), such as outdated knowledge (Zhang et al., 2023b; Kasai et al., 2023) and\\npoor generalization to domain-specific queries (Siriwardhana et al., 2023; Xiong et al., 2024), by\\nretrieving top-k documents from an external corpus (Formal et al., 2022; Izacard et al., 2022; Wang\\net al., 2022a) to ground the model’s output in relevant evidence.\\nPrior research in RAG has largely concentrated on optimizing three key components—retrieval,\\naugmentation, and generation (Gao et al., 2024; Fan et al., 2024) (Figure 1(a)). Retrieval strate-\\ngies span sparse methods (Jones, 1972; Robertson & Zaragoza, 2009) and dense retrieval (Reimers\\n& Gurevych, 2019; Karpukhin et al., 2020), each with respective weaknesses such as lexical\\ngaps (Berger et al., 2000) or retrieval failure on out-of-distribution and multi-hop queries (Dai et al.,\\n1Our code is available at https://github.com/thangylvp/MA-RAG\\n1\\narXiv:2505.20096v2  [cs.CL]  11 Oct 2025\\nQuery\\nDocs\\nAnswer\\nDocs\\nAnswer\\nCoT\\nNotes\\nPost-process\\na) Vanilla RAG\\nStep 1\\nStep ...\\nCoT\\nSub-Query\\nQuery\\nDocs\\nNotes\\nCoT\\nQuery\\nSub-Answer\\nCoT\\nb) RAG with post-\\nprocessing retrieved docs\\nd) MA-RAG\\nQuery\\nDocs\\nAnswer\\nc) RAG with interleaving\\nretrieval and thoughts\\nAnswer\\nCoT\\nFigure 1: Architectural Comparison of MA-RAG and Prior RAG Methods. a) A naive RAG sys-\\ntem performs one-shot retrieval followed by direct answer generation. b) Enhanced systems incor-\\nporate post-retrieval processing such as document re-')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_retriever.invoke(\"Modular RAG vs Naive RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7d4c3",
   "metadata": {},
   "source": [
    "### 노드 작성\n",
    "\n",
    "#### 웹 검색 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6ef8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 쿼리 변환 프롬프트\n",
    "search_instructions = \"\"\"분석가와 전문가 간의 대화가 제시됩니다.\n",
    "\n",
    "목표는 해당 대화와 관련된 검색 및/또는 웹 검색에 사용할 잘 구조화된 쿼리를 생성하는 것입니다.\n",
    "\n",
    "먼저 전체 대화를 분석하십시오.\n",
    "\n",
    "특히 분석가가 마지막에 제기한 질문에 주목하십시오.\n",
    "\n",
    "이 마지막 질문을 잘 구조화된 웹 검색 쿼리로 변환하십시오.\"\"\"\n",
    "\n",
    "\n",
    "def search_web(state: InterviewState):\n",
    "    \"\"\"웹 검색을 통한 문서 검색\"\"\"\n",
    "\n",
    "    llm_with_structured = llm.with_structured_output(SearchQuery)\n",
    "\n",
    "    response = llm_with_structured.invoke(\n",
    "        [(\"system\", search_instructions)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    results = web_search.invoke(response.search_query)\n",
    "    context = [\n",
    "        f'<Document source=\"web\" url=\"{doc[\"url\"]}\" title=\"{doc[\"title\"]}\">{doc[\"content\"]}</Document>'\n",
    "        for doc in results[\"results\"]\n",
    "    ]\n",
    "\n",
    "    return {\"context\": [*context]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9e12267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['<Document source=\"web\" url=\"https://dictionary.cambridge.org/ko/%EC%82%AC%EC%A0%84/%EC%98%81%EC%96%B4/crag\" title=\"영어로 crag의 뜻\">CRAG 의미, 정의, CRAG의 정의: 1. a high, rough mass of rock that sticks out from the land around it 2. a high, rough mass of rock…. 자세히 알아보기.</Document>',\n",
       "  '<Document source=\"web\" url=\"https://dictionary.cambridge.org/ko/%EC%82%AC%EC%A0%84/%ED%95%99%EC%8A%B5%EC%9E%90%EC%9A%A9-%EC%82%AC%EC%A0%84/crag\" title=\"CRAG | Cambridge Learner\\'s Dictionary에서의 의미\">CRAG 의미, 정의, CRAG의 정의: a high, rough mass of rock that sticks up from the land around it. 자세히 알아보기.</Document>',\n",
       "  '<Document source=\"web\" url=\"https://velog.io/@heyggun/LLM-Corrective-RAGCRAG-Corrective-Retrieval-Augmented-Generation\" title=\"[LLM] Corrective RAG(CRAG) - Corrective Retrieval Augmented ...\"># [LLM] Corrective RAG(CRAG) - Corrective Retrieval Augmented Generation 검색 증강 생성(Retrieval-Augmented Generation, RAG)은 LLM을 보완할 수 있는 실용적인 방법이지만, 검색된 문서의 관련성에 크게 의존하므로 검색 과정에서 오류가 발생하면 모델이 어떻게 동작할지에 대한 우려가 있다. 이를 해결하기 위해 우리는 생성의 강건성을 향상시키기 위한 **Corrective Retrieval-Augmented Generation, CRAG)**를 제안한다. 질의(query)에 대해 검색된 문서들의 전체적인 품질을 평가하는 **경량 검색 평가 모듈**을 설계하고, 이를 통해 검색에 대한 신뢰도를 산출하고, 이에 따라 다양한 검색 액션을 실행할 수 있도록 한다. 정적인 제한된 코퍼스에서의 검색은 suboptimal document(최적 보다 못한 문서) 만을 반환할 수 있어, 검색 결과를 보강하기 위해 **대규모 웹 검색**을 추가적으로 활용한다. Corrective RAG(CRAG)의 아이디어는 아래와 같다. > **Corrective RAG (CRAG**) jupyter notebook   ### [LLM] Self-Reflective RAG with LangGraph](/@heyggun/LLM-Self-Reflective-RAG-with-LangGraph)</Document>']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_web({\"messages\": [(\"user\", \"CRAG에 대해서 설명해주세요.\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9959f7f",
   "metadata": {},
   "source": [
    "#### 논문 검색 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f25ee249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(state: InterviewState):\n",
    "    \"\"\"Arxiv 검색 노드\"\"\"\n",
    "\n",
    "    llm_with_structured = llm.with_structured_output(SearchQuery)\n",
    "\n",
    "    response = llm_with_structured.invoke(\n",
    "        [(\"system\", search_instructions)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    results = arxiv_retriever.invoke(\n",
    "        response.search_query,\n",
    "        load_max_docs=2,\n",
    "        load_all_available_meta=True,\n",
    "        get_full_documents=False,\n",
    "    )\n",
    "\n",
    "    context = [\n",
    "        f'<Document source=\"arxiv\" url=\"{doc.metadata[\"entry_id\"]}\" date=\"{doc.metadata.get(\"Published\", \"\")}\" authors=\"{doc.metadata.get(\"Authors\", \"\")}\"/>\\n<Title>\\n{doc.metadata[\"Title\"]}\\n</Title>\\n\\n<Summary>\\n{doc.metadata[\"Summary\"]}\\n</Summary>\\n\\n<Content>\\n{doc.page_content}\\n</Content>\\n</Document>'\n",
    "        for doc in results\n",
    "    ]\n",
    "\n",
    "    return {\"context\": [*context]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "606944ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2502.19629v1\" date=\"2025-02-26\" authors=\"Tiffany J. Callahan, Nathaniel H. Park, Sara Capponi\"/>\\n<Title>\\nAgentic Mixture-of-Workflows for Multi-Modal Chemical Search\\n</Title>\\n\\n<Summary>\\nThe vast and complex materials design space demands innovative strategies to\\nintegrate multidisciplinary scientific knowledge and optimize materials\\ndiscovery. While large language models (LLMs) have demonstrated promising\\nreasoning and automation capabilities across various domains, their application\\nin materials science remains limited due to a lack of benchmarking standards\\nand practical implementation frameworks. To address these challenges, we\\nintroduce Mixture-of-Workflows for Self-Corrective Retrieval-Augmented\\nGeneration (CRAG-MoW) - a novel paradigm that orchestrates multiple agentic\\nworkflows employing distinct CRAG strategies using open-source LLMs. Unlike\\nprior approaches, CRAG-MoW synthesizes diverse outputs through an orchestration\\nagent, enabling direct evaluation of multiple LLMs across the same problem\\ndomain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical\\nreactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral\\nretrieval. Our results demonstrate that CRAG-MoWs achieve performance\\ncomparable to GPT-4o while being preferred more frequently in comparative\\nevaluations, highlighting the advantage of structured retrieval and multi-agent\\nsynthesis. By revealing performance variations across data types, CRAG-MoW\\nprovides a scalable, interpretable, and benchmark-driven approach to optimizing\\nAI architectures for materials discovery. These insights are pivotal in\\naddressing fundamental gaps in benchmarking LLMs and autonomous AI agents for\\nscientific applications.\\n</Summary>\\n\\n<Content>\\nAgentic Mixture-of-Workflows for Multi-Modal Chemical Search \\n \\n \\nTiffany J. Callahan1, Nathaniel H. Park1*, and Sara Capponi1 \\n1IBM Research–Almaden, 650 Harry Rd. San Jose, CA 95120  \\n \\n*Corresponding author. Email: npark@us.ibm.com \\n \\n \\nABSTRACT \\nThe vast and complex materials design space demands innovative strategies to integrate \\nmultidisciplinary scientific knowledge and optimize materials discovery. While large \\nlanguage models (LLMs) have demonstrated promising reasoning and automation \\ncapabilities across various domains, their application in materials science remains limited \\ndue to a lack of benchmarking standards and practical implementation frameworks. To \\naddress these challenges, we introduce Mixture-of-Workflows for Self-Corrective \\nRetrieval-Augmented Generation (CRAG-MoW)—a novel paradigm that orchestrates \\nmultiple agentic workflows employing distinct CRAG strategies using open-source LLMs. \\nUnlike prior approaches, CRAG-MoW synthesizes diverse outputs through an \\norchestration agent, enabling direct evaluation of multiple LLMs across the same problem \\ndomain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical \\nreactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral retrieval. \\nOur results demonstrate that CRAG-MoWs achieve performance comparable to GPT-4o \\nwhile being preferred more frequently in comparative evaluations, highlighting the \\nadvantage of structured retrieval and multi-agent synthesis. By revealing performance \\nvariations across data types, CRAG-MoW provides a scalable, interpretable, and \\nbenchmark-driven approach to optimizing AI architectures for materials discovery. These \\ninsights are pivotal in addressing fundamental gaps in benchmarking LLMs and \\nautonomous AI agents for scientific applications. \\n \\n \\nINTRODUCTION \\nThe vast size, high dimensionality, and complexity of the materials design space require \\nnew strategies for synthesizing and integrating multidisciplinary scientific knowledge. \\nSuch approaches are essential to drive advances in performance, cost-efficiency, and \\nsustainability [1]. Large language models (LLM), which are trained on large amounts of \\ndata and designed for human interaction, have demonstrated impressive reasoning \\nabilities in natural language processing [2–5]. Within the materials domain, LLMs have \\nbeen used to predict chemical properties [6–8], design new molecules [4, 9–12], automate \\nscientific coding [13, 14], develop AI agents [6, 15–17], extract and synthesize knowledge \\n[18, 19], and summarize and generate text [20]. Despite these successes, LLM adoption \\nin materials science lags behind other fields. This gap stems from a lack of standardized \\n \\n2\\nbenchmarks for validating LLM-based analyses, limited application to practical tasks, and \\nthe specialized expertise required for materials development [21–23].  \\n \\nThese challenges have led to increased interest in agentic workflows—LLM-driven \\nautonomous systems designed to perform complex reasoning, tool use, and multi-step \\ndecision-making [24]. Within the materials domain, agentic systems have been developed \\nto review the literature [25–27], implement routine chemical tasks [16, 21, 28–31] plan \\nexperiments [32–35], automate chemoinformatics analysis [36–39], and generate novel \\nhypotheses [40–42]. One of the most widely adopted implementations of agentic systems \\nis retrieval-augmented generation (RAG), which enhances LLM outputs by integrating \\ninformation retrieval techniques [25]. Rather than relying solely on pre-trained knowledge, \\nRAG dynamically retrieves and incorporates relevant external information, improving \\nresponse accuracy and contextual relevance. This capability is particularly valuable in \\nmaterials science, where access to domain-specific literature, experimental data, and \\nproperty databases is critical for precise predictions and reasoning. By leveraging RAG, \\nagentic workflows can provide more reliable and up-to-date insights, addressing key\\n</Content>\\n</Document>',\n",
       "  '<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2406.04744v2\" date=\"2024-11-01\" authors=\"Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla, Xiangsen Chen, Sajal Choudhary, Rongze Daniel Gui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong, Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan, Chenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang, Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah, Rakesh Wanga, Anuj Kumar, Wen-tau Yih, Xin Luna Dong\"/>\\n<Title>\\nCRAG -- Comprehensive RAG Benchmark\\n</Title>\\n\\n<Summary>\\nRetrieval-Augmented Generation (RAG) has recently emerged as a promising\\nsolution to alleviate Large Language Model (LLM)\\'s deficiency in lack of\\nknowledge. Existing RAG datasets, however, do not adequately represent the\\ndiverse and dynamic nature of real-world Question Answering (QA) tasks. To\\nbridge this gap, we introduce the Comprehensive RAG Benchmark (CRAG), a factual\\nquestion answering benchmark of 4,409 question-answer pairs and mock APIs to\\nsimulate web and Knowledge Graph (KG) search. CRAG is designed to encapsulate a\\ndiverse array of questions across five domains and eight question categories,\\nreflecting varied entity popularity from popular to long-tail, and temporal\\ndynamisms ranging from years to seconds. Our evaluation of this benchmark\\nhighlights the gap to fully trustworthy QA. Whereas most advanced LLMs achieve\\n<=34% accuracy on CRAG, adding RAG in a straightforward manner improves the\\naccuracy only to 44%. State-of-the-art industry RAG solutions only answer 63%\\nof questions without any hallucination. CRAG also reveals much lower accuracy\\nin answering questions regarding facts with higher dynamism, lower popularity,\\nor higher complexity, suggesting future research directions. The CRAG benchmark\\nlaid the groundwork for a KDD Cup 2024 challenge and attracted thousands of\\nparticipants and submissions. We commit to maintaining CRAG to serve research\\ncommunities in advancing RAG solutions and general QA solutions. CRAG is\\navailable at https://github.com/facebookresearch/CRAG/.\\n</Summary>\\n\\n<Content>\\nCRAG – Comprehensive RAG Benchmark\\nXiao Yang˚1, Kai Sun˚1, Hao Xin˚3, Yushi Sun˚3, Nikita Bhalla1, Xiangsen Chen4, Sajal\\nChoudhary1, Rongze Daniel Gui1, Ziran Will Jiang1, Ziyu Jiang4, Lingkun Kong1, Brian Moran1,\\nJiaqi Wang1, Yifan Ethan Xu1, An Yan1, Chenyu Yang4, Eting Yuan1, Hanwen Zha1, Nan Tang3,4,\\nLei Chen3,4, Nicolas Scheffer1, Yue Liu1, Nirav Shah1, Rakesh Wanga1, Anuj Kumar1, Wen-tau Yih2,\\nand Xin Luna Dong1\\n1Meta Reality Labs, 2 FAIR, Meta, 3 HKUST, 4 HKUST (GZ)\\nAbstract\\nRetrieval-Augmented Generation (RAG) has recently emerged as a promising solu-\\ntion to alleviate Large Language Model (LLM)’s deficiency in lack of knowledge.\\nExisting RAG datasets, however, do not adequately represent the diverse and dy-\\nnamic nature of real-world Question Answering (QA) tasks. To bridge this gap, we\\nintroduce the Comprehensive RAG Benchmark (CRAG), a factual question an-\\nswering benchmark of 4,409 question-answer pairs and mock APIs to simulate web\\nand Knowledge Graph (KG) search. CRAG is designed to encapsulate a diverse\\narray of questions across five domains and eight question categories, reflecting\\nvaried entity popularity from popular to long-tail, and temporal dynamisms ranging\\nfrom years to seconds. Our evaluation of this benchmark highlights the gap to\\nfully trustworthy QA. Whereas most advanced LLMs achieve ď 34% accuracy\\non CRAG, adding RAG in a straightforward manner improves the accuracy only\\nto 44%. State-of-the-art industry RAG solutions only answer 63% of questions\\nwithout any hallucination. CRAG also reveals much lower accuracy in answer-\\ning questions regarding facts with higher dynamism, lower popularity, or higher\\ncomplexity, suggesting future research directions. The CRAG benchmark laid the\\ngroundwork for a KDD Cup 2024 challenge and attracted thousands of participants\\nand submissions. We commit to maintaining CRAG to serve research communities\\nin advancing RAG solutions and general QA solutions. CRAG is available at\\nhttps://github.com/facebookresearch/CRAG/.\\n1\\nIntroduction\\nLarge Language Models (LLMs) have transformed the landscape of Natural Language Processing\\n(NLP) tasks, especially in Question Answering (QA) [20, 22, 38, 39]. Despite the advancements,\\nthe issue of hallucination persists as a significant challenge; LLMs may generate answers that lack\\nfactual accuracy or grounding [14,27,30,32]. Studies have shown that GPT-4’s accuracy in answering\\nquestions referring to slow-changing or fast-changing facts is below 15% [36]; even for stable (never-\\nchanging) facts, GPT-4’s accuracy in answering questions referring to torso-to-tail (less popular)\\nentities is below 35% [29]. Overcoming hallucinations thus becomes a priority in building reliable\\nQA systems [13,14].\\nRetrieval-Augmented Generation (RAG) [6,8,12,19] has recently emerged as a promising solution to\\nalleviate LLM’s deficiency in lack of knowledge and attracted a lot of attention from both academia\\nresearch and industry. Given a question, a RAG system searches external sources to retrieve relevant\\ninformation and then provides grounded answers [7,12,19] (see Figure 1 for an illustration). Despite\\n˚Equal contribution. Correspondence to: Xiao Yang (xiaoyangfb@meta.com).\\n38th Conference on Neural Information Processing Systems (NeurIPS 2024) Track on Datasets and Benchmarks.\\narXiv:2406.04744v2  [cs.CL]  1 Nov 2024\\nLLM\\nWhat is the gold \\nprice today?\\nGold price is at $1626.81 per \\nounce today Oct 21 2022.\\nGold price is at $2020.8 per \\nounce today Jan 28 2024.\\nDocuments\\nWeb \\nSearch\\nReal-time \\nAPIs\\nKnowledge \\nGraph\\nRetrieved \\nrelevant\\nknowledge\\nQuestion \\n(a) LLM Direct Generation\\n(b) RAG: Retrieved-Augmented \\nGeneration with LLM\\nFigure 1: QA using LLMs (a) without RAG vs. (b) with RAG.\\nits potential, RAG still faces many challenges, such as selecting the most relevant information,\\nreducing question answering latency, and synthesizing information to answer complex questions.\\nA comprehensive benchmark is currently missing to advance continued research efforts \\n</Content>\\n</Document>',\n",
       "  '<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2409.15337v1\" date=\"2024-09-09\" authors=\"Jie Ouyang, Yucong Luo, Mingyue Cheng, Daoyu Wang, Shuo Yu, Qi Liu, Enhong Chen\"/>\\n<Title>\\nRevisiting the Solution of Meta KDD Cup 2024: CRAG\\n</Title>\\n\\n<Summary>\\nThis paper presents the solution of our team APEX in the Meta KDD CUP 2024:\\nCRAG Comprehensive RAG Benchmark Challenge. The CRAG benchmark addresses the\\nlimitations of existing QA benchmarks in evaluating the diverse and dynamic\\nchallenges faced by Retrieval-Augmented Generation (RAG) systems. It provides a\\nmore comprehensive assessment of RAG performance and contributes to advancing\\nresearch in this field. We propose a routing-based domain and dynamic adaptive\\nRAG pipeline, which performs specific processing for the diverse and dynamic\\nnature of the question in all three stages: retrieval, augmentation, and\\ngeneration. Our method achieved superior performance on CRAG and ranked 2nd for\\nTask 2&3 on the final competition leaderboard. Our implementation is available\\nat this link: https://github.com/USTCAGI/CRAG-in-KDD-Cup2024.\\n</Summary>\\n\\n<Content>\\nRevisiting the Solution of Meta KDD Cup 2024: CRAG\\nJie Ouyang\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nouyang_jie@mail.ustc.edu.cn\\nYucong Luo\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nprime666@mail.ustc.edu.cn\\nMingyue Cheng∗\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nmycheng@ustc.edu.cn\\nDaoyu Wang\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nwdy030428@mail.ustc.edu.cn\\nShuo Yu\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nyu12345@mail.ustc.edu.cn\\nQi Liu\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nqiliuql@ustc.edu.cn\\nEnhong Chen\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\ncheneh@ustc.edu.cn\\nAbstract\\nThis paper presents the solution of our team APEX in the Meta KDD\\nCUP 2024: CRAG Comprehensive RAG Benchmark Challenge. The\\nCRAG benchmark addresses the limitations of existing QA bench-\\nmarks in evaluating the diverse and dynamic challenges faced by\\nRetrieval-Augmented Generation (RAG) systems. It provides a more\\ncomprehensive assessment of RAG performance and contributes\\nto advancing research in this field. We propose a routing-based do-\\nmain and dynamic adaptive RAG pipeline, which performs specific\\nprocessing for the diverse and dynamic nature of the question in all\\nthree stages: retrieval, augmentation, and generation. Our method\\nachieved superior performance on CRAG and ranked 2nd for Task\\n2&3 on the final competition leaderboard. Our implementation is\\navailable at this link: https://github.com/USTCAGI/CRAG-in-KDD-\\nCup2024.\\nCCS Concepts\\n• Information systems →Information retrieval.\\nKeywords\\nRetrieval-Augmented Generation, Large Language Model\\n1\\nIntroduction\\nLarge Language Models (LLMs) have revolutionized the landscape\\nof Natural Language Processing (NLP) tasks [5, 8, 10], particularly in\\nquestion answering (QA). Despite advances in LLMs, hallucination\\nremains a significant challenge, particularly for dynamic facts and\\ninformation about less prominent entities.\\nRetrieval-Augmented Generation (RAG) [9] has recently emerged\\nas a promising solution to mitigate LLMs’ knowledge deficiencies.\\n∗Mingyue Cheng is the corresponding author.\\nGiven a question, a RAG system queries external sources to re-\\ntrieve relevant information and subsequently provides grounded\\nanswers. Despite its potential, RAG continues to face numerous\\nchallenges, including the selection of the most relevant information,\\nthe reduction of question answering latency, and the synthesis of\\ninformation to address complex questions.\\nTo bridge this gap, Meta introduced the Comprehensive RAG\\nBenchmark (CRAG) [13], a factual question answering benchmark\\nof 4,409 question-answer pairs and Mock APIs to simulate web\\nand Knowledge Graph (KG) search, and hosted the KDD CUP 2024\\nChallenge.\\n1.1\\nDataset Description\\nThe CRAG contains two parts of data: the QA pairs and the content\\nfor retrieval.\\nQA pairs. The CRAG dataset contains a rich set of 4,409 QA\\npairs covering five domains: finance, sports, music, movie, and\\nopen domain, and eight types of questions. For the KDD CUP 2024\\nChallenge, the benchmark data were splited into three sets with\\nsimilar distributions: validation, public test, and private test at 30%,\\n30%, and 40%, respectively. In total, 2,706 examples from validation\\nand public test sets were shared.\\nThe dataset also reflects varied entity popularity from popular\\nto long-tail entities, and temporal spans ranging from seconds to\\nyears. Given the temporal nature of many questions, each question-\\nanswer pair is accompanied by an additional field denoted as \"query\\ntime.\" This temporal mark\\n</Content>\\n</Document>']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_arxiv({\"messages\": [(\"user\", \"CRAG에 대해서 설명해주세요.\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac6790",
   "metadata": {},
   "source": [
    "#### 답변 생성 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a01ce399",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"당신은 분석가에게 인터뷰를 받는 전문가입니다.\n",
    "\n",
    "분석가의 주요 관심 분야는 다음과 같습니다: {goals}. \n",
    "\n",
    "당신의 목표는 분석가가 제기한 질문에 답변하는 것입니다.\n",
    "\n",
    "질문에 답변할 때는 다음 맥락을 활용하십시오:\n",
    "<Context>\n",
    "{context}\n",
    "<Context>\n",
    "\n",
    "질문에 답변할 때는 다음 지침을 따르십시오:\n",
    "1. 맥락에 제공된 정보만 사용하십시오. \n",
    "2. 외부 정보를 도입하거나 맥락에 명시적으로 언급된 내용을 넘어선 추측을 하지 마십시오.\n",
    "3. 맥락에는 각 개별 문서의 주제별 출처가 포함되어 있습니다.\n",
    "4. 답변에서 관련 진술 옆에 해당 출처를 포함하십시오. 예를 들어 출처 #1의 경우 [1]을 사용하십시오.\n",
    "5. 답변 하단에 출처를 순서대로 나열하십시오. [1] 출처 1, [2] 출처 2, 등\n",
    "6. 출처가 다음과 같은 경우: <Document url=\"assistant/docs/llama3_1.pdf\" page=\"7\" />' \n",
    "    다음처럼 기재하십시오: [1] assistant/docs/llama3_1.pdf, 7 페이지\n",
    "7. 제공된 맥락이 없다면 출처를 기재하기 마십시오.\n",
    "    \n",
    "인용 시 괄호 추가 및 Document 서두 문구는 생략하십시오.\"\"\"\n",
    "\n",
    "\n",
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\"질문에 대한 답변 노드\"\"\"\n",
    "\n",
    "    analyst = state[\"analyst\"]\n",
    "\n",
    "    system_message = answer_instructions.format(\n",
    "        goals=analyst.description,\n",
    "        context=\"\\n\".join(state[\"context\"]),\n",
    "    )\n",
    "    response = llm.invoke([(\"system\", system_message)] + state[\"messages\"])\n",
    "    response.name = \"전문가\"\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37fe5c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: 전문가\n",
      "\n",
      "Modular RAG와 기존의 Naive RAG의 차이점 및 production level에서 사용하는 이점에 대해 설명드리겠습니다.\n",
      "\n",
      "Modular RAG는 RAG(Retrieval-Augmented Generation) 모델의 구성 요소를 모듈화하여 각 부분이 독립적으로 조정 및 개선될 수 있도록 설계된 구조입니다. 반면, Naive RAG는 통합된 하나의 시스템으로 운영되며, 각 부분의 변경이나 업그레이드가 전체 모델에 영향을 미치기 쉽습니다.\n",
      "\n",
      "이러한 모듈화는 production level에서 다음과 같은 이점을 제공합니다:\n",
      "\n",
      "1. **유연성 증대**: 각 모듈이 독립적이기 때문에 특정 구성 요소를 교체하거나 개선할 때 전체 시스템을 중단하지 않고도 작업할 수 있습니다. 이는 시장 변화에 신속히 대응해야 하는 스타트업 환경에서 큰 장점입니다.\n",
      "\n",
      "2. **적응성과 확장성**: 시장 요구나 신규 기능 도입에 맞춰 개별 모듈을 손쉽게 조정할 수 있어, 비즈니스 모델 혁신과 새로운 서비스 개발에 있어서 빠른 실험과 적용이 가능합니다.\n",
      "\n",
      "3. **유지보수 및 최적화 용이**: 장애 발생 시 특정 모듈만 점검·수리 가능하여 다운타임을 최소화할 수 있으며, 성능 병목을 발견하고 개선하는 데 효과적입니다.\n",
      "\n",
      "4. **효율적인 자원 관리**: 필요에 따라 특정 모듈만 확장하거나 축소할 수 있어 클라우드 자원 활용과 비용 효율성을 동시에 달성할 수 있습니다.\n",
      "\n",
      "따라서, Modular RAG는 Naive RAG보다 스타트업과 같은 빠르게 변화하는 환경에서 유연성과 시장 적응력을 극대화할 수 있는 시스템으로 평가받으며, 이는 실질적인 production 환경 운영에서 중요한 이점으로 작용합니다.\n",
      "\n",
      "[1] assistant/docs/llama3_1.pdf, 7 페이지\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = generate_answer(\n",
    "    {\n",
    "        \"analyst\": analyst,\n",
    "        \"context\": [],\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Modular RAG 가 기존의 Naive RAG 와 어떤 차이가 있는지와 production level 에서 사용하는 이점\",\n",
    "                name=\"분석가\",\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624648b",
   "metadata": {},
   "source": [
    "### 문석 작성 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82c9e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술 문서 작성 프롬프트\n",
    "section_writer_instructions = \"\"\"당신은 전문 기술 문서 작성자입니다.\n",
    "\n",
    "당신의 임무는 일련의 원본 문서를 철저히 분석하여 보고서의 상세하고 포괄적인 섹션을 작성하는 것입니다.\n",
    "이는 핵심 통찰력을 추출하고, 관련 사항을 상세히 설명하며, 명확성과 이해를 보장하기 위한 심층적인 해설을 제공하는 것을 포함합니다. 필요한 배경 정보, 뒷받침하는 증거, 예시를 포함하여 독자의 이해를 높여야 합니다. 논리적이고 체계적인 구조를 유지하며, 모든 핵심 사항이 상세히 다루어지고 전문적인 어조로 제시되도록 하십시오.\n",
    "\n",
    "다음 지침을 따르십시오:\n",
    "1. 원본 문서의 내용 분석:\n",
    "- 각 원본 문서의 이름은 문서 시작 부분에 <Document> 태그와 함께 기재되어 있습니다.\n",
    "\n",
    "2. 마크다운 서식을 사용하여 보고서 구조 생성:\n",
    "- 섹션 제목에는 ## 사용\n",
    "- 하위 섹션 헤더에는 ### 사용\n",
    "\n",
    "3. 다음 구조에 따라 보고서 작성:\n",
    "a. 제목 (## 헤더)\n",
    "b. 요약 (### 헤더)\n",
    "c. 종합 분석 (### 헤더)\n",
    "d. 출처 (### 헤더)\n",
    "\n",
    "4. 분석가의 중점 분야를 반영하여 제목을 흥미롭게 작성하십시오: \n",
    "{focus}\n",
    "\n",
    "5. 요약 섹션 작성 시:\n",
    "- 분석가의 중점 분야와 관련된 일반적 배경/맥락을 요약으로 제시하십시오\n",
    "- 인터뷰에서 수집한 통찰 중 새롭거나 흥미롭거나 놀라운 점을 강조하십시오\n",
    "- 사용한 출처 문서를 번호 매긴 목록으로 작성하십시오\n",
    "- 인터뷰어 또는 전문가의 이름은 언급하지 마십시오\n",
    "- 최대 약 400단어를 목표로 하십시오\n",
    "- 출처 문서의 정보에 기반하여 보고서에서 번호 매긴 출처([1], [2] 등)를 사용하십시오\n",
    "\n",
    "6. 종합 분석 섹션:\n",
    "- 출처 문서의 정보를 상세히 검토하십시오.\n",
    "- 복잡한 아이디어를 이해하기 쉬운 단위로 분해하고 논리적인 흐름을 유지하십시오.\n",
    "- 분석의 다양한 관점이나 차원을 다루기 위해 필요한 경우 하위 섹션을 사용하십시오.\n",
    "- 원본 문서의 데이터, 직접 인용문, 예시를 통해 분석을 뒷받침하십시오.\n",
    "- 각 논점이 보고서의 전반적인 초점과 어떻게 관련되는지 명확히 설명하십시오.\n",
    "- 여러 관련 아이디어를 제시할 때는 명확성을 위해 글머리 기호나 번호 매기기 목록을 사용하십시오.\n",
    "- 전문적이고 객관적인 어조를 유지하며 편향되거나 근거 없는 의견을 피하십시오.\n",
    "- 분석이 철저하도록 최소 800단어를 목표로 하십시오.\n",
    "\n",
    "7. 출처 섹션에서:\n",
    "- 보고서에 사용된 모든 출처를 포함하십시오\n",
    "- 관련 웹사이트 또는 특정 문서 경로의 전체 링크를 제공하십시오\n",
    "- 각 출처는 새 줄로 구분하십시오. 마크다운에서 새 줄을 만들기 위해 각 줄 끝에 두 개의 공백을 사용하십시오.\n",
    "- 예시:\n",
    "    ### 출처\n",
    "    [1] 링크 또는 문서명\n",
    "    [2] 링크 또는 문서명\n",
    "\n",
    "8. 출처를 반드시 통합하십시오. 예를 들어 다음은 올바르지 않습니다:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "중복 출처는 없어야 합니다. 다음과 같이 간결하게 작성하십시오:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "9. 최종 검토:\n",
    "- 보고서가 요구되는 구조를 따르는지 확인하십시오.\n",
    "- 보고서 제목 앞에 서문을 포함하지 마십시오.\n",
    "- 모든 지침이 준수되었는지 확인하십시오.\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.messages import get_buffer_string\n",
    "\n",
    "\n",
    "def write_section(state: InterviewState):\n",
    "    \"\"\"인터뷰에 대한 리포트 작성\"\"\"\n",
    "\n",
    "    analyst = state[\"analyst\"]\n",
    "\n",
    "    # 인터뷰를 문자열로 변환\n",
    "    interview = get_buffer_string(state[\"messages\"])\n",
    "\n",
    "    # 섹션 작성을 위한 시스템 프롬프트 정의\n",
    "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
    "    response = llm.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [\n",
    "            HumanMessage(\n",
    "                content=f\"분석가와 전문가의 인터뷰 내용입니다:\\n<Interview>\\n{interview}\\n</Interview>\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"이 자료를 사용하여 해당 섹션을 작성하십시오:\\n<Resources>\\n{state['context']}\\n</Resources>\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return {\"sections\": [response.content]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb6b207",
   "metadata": {},
   "source": [
    "### 인터뷰 그래프 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd3d133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "def should_continue_interview(state: InterviewState) -> Literal[\"finish\", \"continue\"]:\n",
    "    \"\"\"인터뷰를 계속 진행할 지 여부를 판단합니다.\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    max_num_turns = state.get(\"max_num_turns\", 2)\n",
    "\n",
    "    expert_message_count = sum(\n",
    "        1 for m in messages if isinstance(m, AIMessage) and m.name == \"전문가\"\n",
    "    )\n",
    "\n",
    "    # 전문가가 최대 턴 이상 답변했다면 인터뷰를 종료합니다.\n",
    "    if expert_message_count >= max_num_turns:\n",
    "        return \"finish\"\n",
    "\n",
    "    last_message = messages[-1]\n",
    "    if \"도움 주셔서 정말 감사합니다\" in last_message.content:\n",
    "        return \"finish\"\n",
    "\n",
    "    return \"continue\"\n",
    "\n",
    "\n",
    "class InterviewOutputState(TypedDict):\n",
    "    \"\"\"서브그래프가 부모로 반환할 상태\"\"\"\n",
    "\n",
    "    context: Annotated[list, operator.add]\n",
    "    analyst: Annotated[Analyst, \"분석가\"]\n",
    "    interview: Annotated[str, \"인터뷰 내용\"]\n",
    "    sections: Annotated[list, \"보고서 섹션 목록\"]\n",
    "\n",
    "\n",
    "interview_builder = StateGraph(InterviewState, output_schema=InterviewOutputState)\n",
    "interview_builder.add_node(generate_question)  # 질문 생성\n",
    "interview_builder.add_node(search_web)  # 웹 검색\n",
    "interview_builder.add_node(search_arxiv)  # arxiv 검색\n",
    "interview_builder.add_node(generate_answer)  # 답변 생성\n",
    "interview_builder.add_node(write_section)  # 문서 작성\n",
    "\n",
    "interview_builder.set_entry_point(\"generate_question\")\n",
    "interview_builder.add_edge(\"generate_question\", \"search_web\")\n",
    "interview_builder.add_edge(\"generate_question\", \"search_arxiv\")\n",
    "interview_builder.add_edge(\"search_web\", \"generate_answer\")\n",
    "interview_builder.add_edge(\"search_arxiv\", \"generate_answer\")\n",
    "interview_builder.add_conditional_edges(\n",
    "    \"generate_answer\",\n",
    "    should_continue_interview,\n",
    "    {\n",
    "        \"continue\": \"generate_question\",\n",
    "        \"finish\": \"write_section\",\n",
    "    },\n",
    ")\n",
    "interview_builder.set_finish_point(\"write_section\")\n",
    "\n",
    "interview_graph = interview_builder.compile(\n",
    "    checkpointer=InMemorySaver(),\n",
    ").with_config(run_name=\"Conduct Interviews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cf57641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(interview_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252d966",
   "metadata": {},
   "source": [
    "### 인터뷰 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f343ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_question\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: 분석가\n",
      "\n",
      "안녕하세요, 저는 TechStart Ventures에서 AI 스타트업을 분석하고 투자하는 석호필입니다. 말씀하신 주제 정말 흥미롭고 중요한 영역인데요, 우선 Modular RAG와 Naive RAG 간의 본질적인 차이점에 대해 좀 더 구체적으로 설명해 주실 수 있을까요? 예를 들어, 각 접근법이 데이터 처리나 응답 생성에서 어떤 구조적 차이를 보이는지 궁금합니다.\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: 전문가\n",
      "\n",
      "Modular RAG는 기존의 Naive RAG와 달리 RAG 시스템을 독립적인 모듈과 특화된 연산자로 분해하여 매우 재구성 가능한 프레임워크를 제공합니다. Naive RAG가 '인덱싱-검색-생성'의 단순한 선형 구조에 의존하여 유사도 기반 검색에만 집중하지만, Modular RAG는 라우팅, 스케줄링, 융합 메커니즘을 통합한 더 복잡하고 유연한 설계를 채택해 다양한 검색과 생성 패턴(직선, 조건부, 분기, 반복)을 지원합니다. 이는 복잡한 쿼리와 콘텐츠 변동성에 대한 대응력을 높이고, 검색 중복과 잡음을 줄이며, LLM의 정보 활용도를 향상시키는 데 큰 장점을 제공합니다.\n",
      "\n",
      "이러한 구조적 차이는 실제 프로덕션 환경에서 매우 중요한 이점을 만듭니다. Modular RAG는 LEGO처럼 필요한 모듈만 교체하거나 재조립해 서비스 요구사항에 맞게 빠르게 맞춤화할 수 있어 혁신과 실험이 용이합니다. 또한 다양한 도메인과 상황에 맞춘 효과적인 검색 및 생성 전략을 구현함으로써 지식 집약적 작업에서의 성능과 정확도를 높이며, 시스템 유지보수와 확장성 측면에서도 효율성을 극대화합니다.\n",
      "\n",
      "요약하자면, Modular RAG는 Naive RAG 대비 더 복잡한 작업과 다양한 사용 사례에 적합하며, 프로덕션 단계의 서비스에서 더욱 유연하고 신뢰성 있는 지식 기반 생성 솔루션을 제공합니다[1].\n",
      "\n",
      "[1] Yunfan Gao et al., \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks,\" http://arxiv.org/abs/2407.21059v1\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_question\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: 분석가\n",
      "\n",
      "석호필:\n",
      "아, 구체적인 모듈 분해와 재조합 가능성이라니 흥미롭네요. 말씀하신 라우팅, 스케줄링, 융합 메커니즘 같은 다양한 연산자를 도입하는 과정에서, 실제 프로덕션 환경에서는 이런 복잡도가 시스템의 응답 시간이나 리소스 요구량에 어떤 영향을 미치나요? 특히 사용자 경험을 저해하지 않으면서도 이런 복잡한 구조를 구현하는 방법에 대해 구체적인 사례가 있을까요?\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: 전문가\n",
      "\n",
      "Modular RAG는 기존의 Naive RAG와 비교하여 시스템 구조를 독립적인 모듈과 전문화된 연산자로 분해하여 유연성과 재구성 능력을 극대화합니다. Naive RAG는 주로 단순한 인덱싱, 검색, 생성을 순차적으로 수행하는 선형 파이프라인 구조에 의존하는 반면, Modular RAG는 라우팅, 스케줄링, 융합 등 복합적인 메커니즘을 포함한 설계를 채택하여 복잡한 쿼리 처리와 다양한 RAG 패턴(직선, 조건부, 분기, 반복)을 지원합니다. 이러한 차이로 인해 Modular RAG는 복잡한 쿼리에 대해 더 심도 있는 이해와 정보 추출을 가능하게 하며, 중복되거나 잡음이 많은 검색 결과를 효과적으로 관리하여 LLM의 출력을 개선합니다.\n",
      "\n",
      "프로덕션 환경에서 Modular RAG의 이점은 매우 실질적입니다. LEGO 블록처럼 필요한 모듈을 교체하거나 조립하여 신속하게 맞춤형 시스템을 구축할 수 있어 서비스 개발과 혁신 속도를 높입니다. 또한, 다양한 도메인과 업무 특성에 따라 모듈을 선택적으로 적용하거나 조합함으로써 시스템의 확장성과 유지보수성이 향상됩니다. 이로 인해 사용자에게 더 정확하고 신뢰성 있는 정보를 빠르게 제공할 수 있으며, 복잡한 지식 집약적 작업에서도 뛰어난 성능을 유지할 수 있습니다.\n",
      "\n",
      "요약하자면, Modular RAG는 Naive RAG 대비 더 높은 유연성과 복잡도 관리 능력을 갖추고 있어 실제 서비스 개발 및 운영 단계에서 혁신과 신뢰성을 동시에 추구하는 데 큰 장점을 제공합니다[1].\n",
      "\n",
      "[1] Yunfan Gao et al., \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks,\" http://arxiv.org/abs/2407.21059v1\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mwrite_section\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## 스타트업 출신의 석호필은 Agentic RAG와 Adaptive RAG의 차이점을 기업가적 관점에서 분석하며, 각각의 접근법이 실제 서비스 개발과 혁신에 미치는 영향을 탐구한다\n",
      "\n",
      "### 요약\n",
      "\n",
      "Retrieval-Augmented Generation(RAG)은 대규모 언어 모델(LLM)의 한계를 극복하고 지식 집약적 작업에서 성능을 크게 향상시키는 핵심 기술로 부상했다. Naive RAG는 기존의 전통적인 ‘인덱싱-검색-생성’의 선형 구조에 기반하지만, 복잡하고 다양한 도메인 요구사항과 고도화된 응답 패턴을 제대로 소화하지 못하는 한계가 두드러졌다. 이러한 한계를 극복하기 위해 Modular RAG가 제안되었는데, 이는 복잡한 RAG 시스템을 독립적인 모듈과 전문화된 연산자로 분해해 LEGO 블록처럼 쉽고 유연하게 조립 및 교체할 수 있는 설계다[1]. 이 프레임워크는 라우팅, 스케줄링, 융합 메커니즘을 통합하여 다양한 검색 및 생성 패턴(직선, 조건부, 분기, 반복)을 지원함으로써, 복잡한 쿼리 대응과 검색 중복·잡음 완화에 효과적이다. 실제 프로덕션 환경에서는 Modular RAG가 빠른 맞춤화와 혁신 가속, 확장성 및 유지보수의 용이성을 보장하며, 사용자 경험을 저해하지 않고 정보 처리 복잡도를 관리하는 점에서 Naive RAG 대비 높은 경쟁력을 갖는다[1].\n",
      "\n",
      "석호필의 기업가적 시각은 Modular RAG가 스타트업이나 신속한 서비스 개발 환경에서 '빠른 실험과 신뢰성 확보'라는 두 마리 토끼를 잡을 수 있도록 돕는 점에 주목한다. 복잡성 증가가 리소스 부담으로 작용할 수 있으나, 정교한 모듈 레벨 재구성과 최적화로 사용자 응답 시간 준수 및 리소스 효율성 유지가 가능하다. 또한, 다중 모듈 협업 및 전문화된 에이전트 활용 사례 역시 혁신적 실험과 서비스 확장성을 뒷받침하는 주요 요소로 분석된다[1][5].\n",
      "\n",
      "이 보고서는 Modular RAG가 기업가 및 스타트업이 직면하는 기술적 챌린지와 비즈니스 요구 사이에서 균형을 이루는 새로운 패러다임임을 실증적 근거와 함께 제시하며, 실제 서비스 개발에 미치는 영향과 혁신적 가능성을 심도 있게 탐구한다.\n",
      "\n",
      "주요 출처 문서:  \n",
      "[1] Yunfan Gao et al., \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks,\" http://arxiv.org/abs/2407.21059v1  \n",
      "\n",
      "### 종합 분석\n",
      "\n",
      "#### 1. 기존 Naive RAG의 한계와 Modular RAG의 필요성\n",
      "\n",
      "Naive RAG는 ‘인덱싱 → 검색 → 생성’의 선형 프로세스에 의존하여 단순 유사도 기반 검색을 수행한다. 이는 복잡한 사용자 쿼리와 콘텐츠 변동성, 검색 결과의 중복 및 잡음 문제를 효과적으로 처리하지 못하는 구조적 한계를 내포한다. 특히 유사성 계산만으로는 쿼리와 문서의 의미적 관계를 깊게 해석하지 못해, 정확하고 신뢰성 있는 답변 제공에 제약이 따른다[1].\n",
      "\n",
      "이와 같은 한계는 프로덕션 환경에서 특히 치명적인데, 사용자 경험을 저해하는 잘못된 정보 생성(환각)과, 검색 부하 증가에 따른 응답 지연 및 시스템 불안정성 등을 초래한다. 따라서 기존의 Naive RAG는 복잡도가 증가하는 최신 애플리케이션 요구에 부합하지 못하는 ‘틀’로 인식된다.\n",
      "\n",
      "#### 2. Modular RAG: LEGO 블록과 같은 재구성 가능 프레임워크\n",
      "\n",
      "Modular RAG는 복잡한 RAG 시스템을 독립적인 모듈과 특화된 연산자(operator)로 분해한다. 이로써 각 기능을 모듈 단위로 교체, 조합, 확장할 수 있어 다음과 같은 장점을 가진다[1]:\n",
      "\n",
      "- **유연성 강화**: 신규 모듈 추가나 기존 모듈 변경을 통하여 다양한 업무 및 도메인에 신속한 맞춤화 가능.  \n",
      "- **복잡한 쿼리 처리 지원**: 라우팅(routing), 스케줄링(scheduling), 융합(fusion) 메커니즘 도입으로 직선(linear), 조건부(conditional), 분기(branching), 반복(looping) 패턴 처리가 가능해졌고, 기존 선형 구조의 한계를 극복.  \n",
      "- **성능 및 정확도 제고**: 불필요하거나 잡음성 데이터 제거, 중요 정보 집중으로 LLM의 지식 활용도 및 답변 신뢰성 향상.  \n",
      "- **시스템 유지보수 및 확장성 향상**: 모듈 단위 교체·확장으로 오류 수정과 기능 개선이 용이, AI 기술 발전에 빠르게 대응 가능.\n",
      "\n",
      "상세하게 보면, Modular RAG는 여러 작은 컴포넌트가 결합된 복잡한 서브 시스템들을 독립적 에이전트(agent) 혹은 함수처럼 활용한다. 이러한 설계는 AI 서비스 스타트업처럼 빠르게 프로토타입을 반복하고, 다양한 기능을 실험적인 수준에서 온디맨드로 활성화하는 데 매우 유용하다.\n",
      "\n",
      "#### 3. 프로덕션 환경에서 Modular RAG의 실용적 이점\n",
      "\n",
      "기업가적 관점에서 Modular RAG는 다음과 같은 프로덕션 상의 강점을 가진다:\n",
      "\n",
      "- **빠른 맞춤화와 혁신 주기 단축**  \n",
      "  LEGO 블록처럼 모듈을 조립하듯 시스템을 구축할 수 있으므로, 특정 고객 도메인이나 요구에 맞는 맞춤 기능을 안정적으로 빠르게 배포 가능하다.  \n",
      "- **복잡도와 리소스 관리의 균형 유지**  \n",
      "  복잡한 라우팅이나 융합 로직이 도입되었음에도, 적절한 모듈 구성을 통해 전체 응답 시간 연장 없이 고품질 답변 제공이 가능하다. 이는 스타트업이 제한된 컴퓨팅 자원으로도 신뢰성 높은 서비스를 만들 수 있게 한다.  \n",
      "- **확장성과 유지보수 용이성**  \n",
      "  신기능 추가 시 전체 코드 기반을 건드리지 않고 모듈 단위 업데이트가 가능해 개발 비용과 위험이 감소한다.  \n",
      "\n",
      "이와 같은 이점은 사용자의 만족도 상승과 동시에 개발팀의 운영 효율성 증대로 이어진다. 따라서 Modular RAG는 스타트업뿐 아니라 중견 기업, 대기업의 실제 서비스 환경에서도 광범위하게 채택될 가능성이 크다[1][6].\n",
      "\n",
      "#### 4. Modular RAG의 혁신적 응용과 기업가적 도전\n",
      "\n",
      "더 나아가 Modular RAG는 Multi-Agent 아키텍처와의 결합을 통해 협업적 추론, 복잡한 쿼리 분해, 다중 단계 검색 및 응답 합성을 지원한다(예: MA-RAG)[5]. 이는 복잡한 비즈니스 문제 해결, 도메인 특화 지식 추출, 의료·법률·금융 등 전문 영역에 응용 가능성을 열어준다.\n",
      "\n",
      "다만 이런 다중 모듈 아키텍처는 시스템 설계와 운영에 고도의 관리를 요구하며, 복잡성 증가에 따른 응답 지연 위험을 반드시 감안해야 한다. 따라서 실제 서비스 개발 시 적정한 모듈화 수준 설정과 효율적인 연산 스케줄링/최적화가 중요하다.\n",
      "\n",
      "#### 5. 종합\n",
      "\n",
      "기업가인 석호필 입장에서는 Modular RAG가 스타트업이 기술적 혁신과 안정적인 서비스 운영 요구를 균형 있게 충족하는 데 기여하는 ‘플랫폼’으로 보인다. 기존 Naive RAG가 가진 단순성의 장점은 유지하면서, 복잡한 비즈니스 요구에 대응하는 확장성과 유연성을 구현함으로써 다양한 비즈니스 모델과 고객 니즈에 빠르게 적응 가능하다.\n",
      "\n",
      "또한 RAG 기술 발전과 운용 자동화의 연계 강화를 통한 지속적인 혁신 지원, 그리고 실제 프로덕션 환경에서의 실제 성공 사례 확보가 중요하다. Modular RAG는 이론적·기술적 진화 로드맵을 제공함으로써 향후 RAG 관련 스타트업과 대기업 AI 서비스 모두에 중대한 영향을 미칠 것으로 전망된다[1][5][6].\n",
      "\n",
      "### 출처\n",
      "\n",
      "[1] Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang, \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks,\" arXiv:2407.21059v1 (2024-07-26), http://arxiv.org/abs/2407.21059v1  \n",
      "\n",
      "[5] Thang Nguyen, Peter Chin, Yu-Wing Tai, \"MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning,\" arXiv:2505.20096v2 (2025-10-11), http://arxiv.org/abs/2505.20096v2  \n",
      "\n",
      "[6] \"RAG in Production: Deployment Strategies & Practical Considerations,\" Coralogix AI Blog, https://coralogix.com/ai-blog/rag-in-production-deployment-strategies-and-practical-considerations/\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import invoke_graph\n",
    "\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=30,\n",
    "    configurable={\"thread_id\": random()},\n",
    ")\n",
    "\n",
    "topic = \"Modular RAG 가 기존의 Naive RAG 와 어떤 차이가 있는지와 production level 에서 사용하는 이점\"\n",
    "\n",
    "# 그래프 실행\n",
    "invoke_graph(\n",
    "    interview_graph,\n",
    "    {\n",
    "        \"topic\": topic,\n",
    "        \"analyst\": analysts[0],\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                f'그래서 당신이 이 주제에 대해서 글을 쓰고 있다고 했죠? 라고 말씀하셨죠? \"{topic}\"',\n",
    "            )\n",
    "        ],\n",
    "        \"max_num_turns\": 2,\n",
    "    },\n",
    "    config=config,\n",
    "    node_names=[\"generate_question\", \"generate_answer\", \"write_section\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee1f7a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 스타트업 출신의 석호필은 Agentic RAG와 Adaptive RAG의 차이점을 기업가적 관점에서 분석하며, 각각의 접근법이 실제 서비스 개발과 혁신에 미치는 영향을 탐구한다\n",
       "\n",
       "### 요약\n",
       "\n",
       "Retrieval-Augmented Generation(RAG)은 대규모 언어 모델(LLM)의 한계를 극복하고 지식 집약적 작업에서 성능을 크게 향상시키는 핵심 기술로 부상했다. Naive RAG는 기존의 전통적인 ‘인덱싱-검색-생성’의 선형 구조에 기반하지만, 복잡하고 다양한 도메인 요구사항과 고도화된 응답 패턴을 제대로 소화하지 못하는 한계가 두드러졌다. 이러한 한계를 극복하기 위해 Modular RAG가 제안되었는데, 이는 복잡한 RAG 시스템을 독립적인 모듈과 전문화된 연산자로 분해해 LEGO 블록처럼 쉽고 유연하게 조립 및 교체할 수 있는 설계다[1]. 이 프레임워크는 라우팅, 스케줄링, 융합 메커니즘을 통합하여 다양한 검색 및 생성 패턴(직선, 조건부, 분기, 반복)을 지원함으로써, 복잡한 쿼리 대응과 검색 중복·잡음 완화에 효과적이다. 실제 프로덕션 환경에서는 Modular RAG가 빠른 맞춤화와 혁신 가속, 확장성 및 유지보수의 용이성을 보장하며, 사용자 경험을 저해하지 않고 정보 처리 복잡도를 관리하는 점에서 Naive RAG 대비 높은 경쟁력을 갖는다[1].\n",
       "\n",
       "석호필의 기업가적 시각은 Modular RAG가 스타트업이나 신속한 서비스 개발 환경에서 '빠른 실험과 신뢰성 확보'라는 두 마리 토끼를 잡을 수 있도록 돕는 점에 주목한다. 복잡성 증가가 리소스 부담으로 작용할 수 있으나, 정교한 모듈 레벨 재구성과 최적화로 사용자 응답 시간 준수 및 리소스 효율성 유지가 가능하다. 또한, 다중 모듈 협업 및 전문화된 에이전트 활용 사례 역시 혁신적 실험과 서비스 확장성을 뒷받침하는 주요 요소로 분석된다[1][5].\n",
       "\n",
       "이 보고서는 Modular RAG가 기업가 및 스타트업이 직면하는 기술적 챌린지와 비즈니스 요구 사이에서 균형을 이루는 새로운 패러다임임을 실증적 근거와 함께 제시하며, 실제 서비스 개발에 미치는 영향과 혁신적 가능성을 심도 있게 탐구한다.\n",
       "\n",
       "주요 출처 문서:  \n",
       "[1] Yunfan Gao et al., \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks,\" http://arxiv.org/abs/2407.21059v1  \n",
       "\n",
       "### 종합 분석\n",
       "\n",
       "#### 1. 기존 Naive RAG의 한계와 Modular RAG의 필요성\n",
       "\n",
       "Naive RAG는 ‘인덱싱 → 검색 → 생성’의 선형 프로세스에 의존하여 단순 유사도 기반 검색을 수행한다. 이는 복잡한 사용자 쿼리와 콘텐츠 변동성, 검색 결과의 중복 및 잡음 문제를 효과적으로 처리하지 못하는 구조적 한계를 내포한다. 특히 유사성 계산만으로는 쿼리와 문서의 의미적 관계를 깊게 해석하지 못해, 정확하고 신뢰성 있는 답변 제공에 제약이 따른다[1].\n",
       "\n",
       "이와 같은 한계는 프로덕션 환경에서 특히 치명적인데, 사용자 경험을 저해하는 잘못된 정보 생성(환각)과, 검색 부하 증가에 따른 응답 지연 및 시스템 불안정성 등을 초래한다. 따라서 기존의 Naive RAG는 복잡도가 증가하는 최신 애플리케이션 요구에 부합하지 못하는 ‘틀’로 인식된다.\n",
       "\n",
       "#### 2. Modular RAG: LEGO 블록과 같은 재구성 가능 프레임워크\n",
       "\n",
       "Modular RAG는 복잡한 RAG 시스템을 독립적인 모듈과 특화된 연산자(operator)로 분해한다. 이로써 각 기능을 모듈 단위로 교체, 조합, 확장할 수 있어 다음과 같은 장점을 가진다[1]:\n",
       "\n",
       "- **유연성 강화**: 신규 모듈 추가나 기존 모듈 변경을 통하여 다양한 업무 및 도메인에 신속한 맞춤화 가능.  \n",
       "- **복잡한 쿼리 처리 지원**: 라우팅(routing), 스케줄링(scheduling), 융합(fusion) 메커니즘 도입으로 직선(linear), 조건부(conditional), 분기(branching), 반복(looping) 패턴 처리가 가능해졌고, 기존 선형 구조의 한계를 극복.  \n",
       "- **성능 및 정확도 제고**: 불필요하거나 잡음성 데이터 제거, 중요 정보 집중으로 LLM의 지식 활용도 및 답변 신뢰성 향상.  \n",
       "- **시스템 유지보수 및 확장성 향상**: 모듈 단위 교체·확장으로 오류 수정과 기능 개선이 용이, AI 기술 발전에 빠르게 대응 가능.\n",
       "\n",
       "상세하게 보면, Modular RAG는 여러 작은 컴포넌트가 결합된 복잡한 서브 시스템들을 독립적 에이전트(agent) 혹은 함수처럼 활용한다. 이러한 설계는 AI 서비스 스타트업처럼 빠르게 프로토타입을 반복하고, 다양한 기능을 실험적인 수준에서 온디맨드로 활성화하는 데 매우 유용하다.\n",
       "\n",
       "#### 3. 프로덕션 환경에서 Modular RAG의 실용적 이점\n",
       "\n",
       "기업가적 관점에서 Modular RAG는 다음과 같은 프로덕션 상의 강점을 가진다:\n",
       "\n",
       "- **빠른 맞춤화와 혁신 주기 단축**  \n",
       "  LEGO 블록처럼 모듈을 조립하듯 시스템을 구축할 수 있으므로, 특정 고객 도메인이나 요구에 맞는 맞춤 기능을 안정적으로 빠르게 배포 가능하다.  \n",
       "- **복잡도와 리소스 관리의 균형 유지**  \n",
       "  복잡한 라우팅이나 융합 로직이 도입되었음에도, 적절한 모듈 구성을 통해 전체 응답 시간 연장 없이 고품질 답변 제공이 가능하다. 이는 스타트업이 제한된 컴퓨팅 자원으로도 신뢰성 높은 서비스를 만들 수 있게 한다.  \n",
       "- **확장성과 유지보수 용이성**  \n",
       "  신기능 추가 시 전체 코드 기반을 건드리지 않고 모듈 단위 업데이트가 가능해 개발 비용과 위험이 감소한다.  \n",
       "\n",
       "이와 같은 이점은 사용자의 만족도 상승과 동시에 개발팀의 운영 효율성 증대로 이어진다. 따라서 Modular RAG는 스타트업뿐 아니라 중견 기업, 대기업의 실제 서비스 환경에서도 광범위하게 채택될 가능성이 크다[1][6].\n",
       "\n",
       "#### 4. Modular RAG의 혁신적 응용과 기업가적 도전\n",
       "\n",
       "더 나아가 Modular RAG는 Multi-Agent 아키텍처와의 결합을 통해 협업적 추론, 복잡한 쿼리 분해, 다중 단계 검색 및 응답 합성을 지원한다(예: MA-RAG)[5]. 이는 복잡한 비즈니스 문제 해결, 도메인 특화 지식 추출, 의료·법률·금융 등 전문 영역에 응용 가능성을 열어준다.\n",
       "\n",
       "다만 이런 다중 모듈 아키텍처는 시스템 설계와 운영에 고도의 관리를 요구하며, 복잡성 증가에 따른 응답 지연 위험을 반드시 감안해야 한다. 따라서 실제 서비스 개발 시 적정한 모듈화 수준 설정과 효율적인 연산 스케줄링/최적화가 중요하다.\n",
       "\n",
       "#### 5. 종합\n",
       "\n",
       "기업가인 석호필 입장에서는 Modular RAG가 스타트업이 기술적 혁신과 안정적인 서비스 운영 요구를 균형 있게 충족하는 데 기여하는 ‘플랫폼’으로 보인다. 기존 Naive RAG가 가진 단순성의 장점은 유지하면서, 복잡한 비즈니스 요구에 대응하는 확장성과 유연성을 구현함으로써 다양한 비즈니스 모델과 고객 니즈에 빠르게 적응 가능하다.\n",
       "\n",
       "또한 RAG 기술 발전과 운용 자동화의 연계 강화를 통한 지속적인 혁신 지원, 그리고 실제 프로덕션 환경에서의 실제 성공 사례 확보가 중요하다. Modular RAG는 이론적·기술적 진화 로드맵을 제공함으로써 향후 RAG 관련 스타트업과 대기업 AI 서비스 모두에 중대한 영향을 미칠 것으로 전망된다[1][5][6].\n",
       "\n",
       "### 출처\n",
       "\n",
       "[1] Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang, \"Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks,\" arXiv:2407.21059v1 (2024-07-26), http://arxiv.org/abs/2407.21059v1  \n",
       "\n",
       "[5] Thang Nguyen, Peter Chin, Yu-Wing Tai, \"MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning,\" arXiv:2505.20096v2 (2025-10-11), http://arxiv.org/abs/2505.20096v2  \n",
       "\n",
       "[6] \"RAG in Production: Deployment Strategies & Practical Considerations,\" Coralogix AI Blog, https://coralogix.com/ai-blog/rag-in-production-deployment-strategies-and-practical-considerations/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "snapshot = interview_graph.get_state(config=config)\n",
    "display(Markdown(snapshot.values[\"sections\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c74d83",
   "metadata": {},
   "source": [
    "## 인터뷰를 병렬로 실행 (map-reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32cc2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import TypedDict, Annotated\n",
    "\n",
    "\n",
    "class ResearchGraphState(TypedDict):\n",
    "    \"\"\"ResearchGraphState 상태 정의\"\"\"\n",
    "\n",
    "    topic: Annotated[str, \"연구할 주제\"]\n",
    "    max_analysts: Annotated[int, \"생성할 분석가의 최대 수\"]\n",
    "    human_analyst_feedback: Annotated[str, \"인간 분석가로부터 받은 피드백\"]\n",
    "    analysts: Annotated[list[Analyst], operator.add, \"분석가 목록\"]\n",
    "    sections: Annotated[list, operator.add, \"보고서 섹션 리스트\"]\n",
    "    introduction: Annotated[str, \"최종 보고서의 서론\"]\n",
    "    content: Annotated[str, \"최종 보고서의 본문 내용\"]\n",
    "    conclusion: Annotated[str, \"최종 보고서의 결론\"]\n",
    "    final_report: Annotated[str, \"완성된 최종 보고서\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e884dd3",
   "metadata": {},
   "source": [
    "### 인터뷰 작성 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f6c2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "\n",
    "\n",
    "def initiate_all_interviews(state: ResearchGraphState):\n",
    "    \"\"\"인터뷰를 진행합니다.\"\"\"\n",
    "\n",
    "    topic = state[\"topic\"]\n",
    "    analysts = state[\"analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\")\n",
    "\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "    else:\n",
    "        inputs = {\n",
    "            \"topic\": topic,\n",
    "            \"analyst\": analyst,\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=f'그래서 당신이 이 주제에 대해서 글을 쓰고 있다고 했죠? \"{topic}\"'\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "        return [Send(\"conduct_interview\", inputs) for analyst in analysts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcd9b3",
   "metadata": {},
   "source": [
    "### 최종 보고서 작성 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f5a752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보고서 작성 지시사항\n",
    "report_writer_instructions = \"\"\"당신은 기술 문서 작성자로서 다음 주제 전반에 대한 보고서를 작성합니다:  \n",
    "\n",
    "주제: {topic}  \n",
    "\n",
    "당신에게는 분석가 팀이 있습니다. 각 분석가는 다음 두 가지를 수행했습니다:  \n",
    "\n",
    "1. 특정 하위 주제에 대한 전문가와의 인터뷰를 진행했습니다.  \n",
    "2. 조사 결과를 메모로 작성했습니다.  \n",
    "\n",
    "## 당신의 임무:  \n",
    "\n",
    "1. 분석가들이 작성한 메모 모음을 제공받게 됩니다.  \n",
    "2. 각 메모의 통찰력을 세심하게 검토하고 분석하십시오.  \n",
    "3. 모든 메모의 핵심 아이디어를 통합한 상세하고 포괄적인 요약으로 이러한 통찰력을 정리하십시오.  \n",
    "4. 각 메모의 주요 포인트를 아래 제공된 적절한 섹션에 정리하고, 각 섹션이 논리적이고 체계적으로 구성되도록 하십시오.  \n",
    "5. 보고서에 모든 필수 섹션을 포함시키되, 각 섹션의 헤더로 `### 섹션명`을 사용하십시오.  \n",
    "6. 각 섹션당 약 250단어를 목표로 하며, 심층적인 설명, 맥락 및 지원 세부사항을 제공하십시오.  \n",
    "\n",
    "## **고려할 섹션 (심층화를 위한 선택적 섹션 포함):**\n",
    "\n",
    "- **배경**: 방법론과 결과를 이해하는 데 필요한 이론적 기초, 핵심 개념 및 예비 정보.\n",
    "- **관련 연구**: 기존 연구의 개요 및 현재 연구와의 비교 또는 연관성.\n",
    "- **문제 정의**: 본 논문이 다루려는 연구 질문 또는 문제에 대한 공식적이고 정확한 정의.\n",
    "- **방법론(또는 방법)**: 연구에 사용된 방법, 알고리즘, 모델, 데이터 수집 과정 또는 실험 설정에 대한 상세한 설명.\n",
    "- **구현 세부사항**: 소프트웨어 프레임워크, 계산 자원 또는 매개변수 설정 등 방법론이나 모델 구현의 실무적 세부사항.\n",
    "- **실험**: 방법론 검증을 위해 사용된 실험 프로토콜, 데이터셋, 평가 지표, 절차 및 구성에 대한 설명.\n",
    "- **결과**: 통계적 표, 그래프, 도표 또는 질적 분석을 동반한 실험 결과 제시.\n",
    "\n",
    "## 보고서 서식 지정 방법:\n",
    "\n",
    "1. 마크다운 서식을 사용하십시오.\n",
    "2. 보고서 서문은 포함하지 마십시오.\n",
    "3. 소제목을 사용하지 마십시오.\n",
    "4. 보고서는 단일 제목 헤더로 시작하십시오: ## 인사이트\n",
    "5. 보고서에서 분석가 이름을 언급하지 마십시오.\n",
    "6. 메모 내 인용은 그대로 유지하고 괄호([1], [2] 등)로 주석을 달아 표시하십시오.\n",
    "7. 최종 통합 출처 목록을 작성하여 `## 출처` 헤더로 출처 섹션에 추가하십시오.\n",
    "8. 출처를 순서대로 나열하고 중복하지 마십시오.\n",
    "    [1] 출처 1\n",
    "    [2] 출처 2\n",
    "\n",
    "보고서 작성에 활용할 분석가 메모는 다음과 같습니다:\n",
    "\n",
    "<Context>\n",
    "{context}\n",
    "</Context>\"\"\"\n",
    "\n",
    "\n",
    "def write_report(state: ResearchGraphState):\n",
    "    \"\"\"보고서를 작성합니다.\"\"\"\n",
    "\n",
    "    formatted_sections = \"\\n\".join([section for section in state[\"sections\"]])\n",
    "    system_message = report_writer_instructions.format(\n",
    "        topic=state[\"topic\"],\n",
    "        context=formatted_sections,\n",
    "    )\n",
    "    response = llm.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=\"이 메모들을 바탕으로 보고서를 작성하십시오.\")]\n",
    "    )\n",
    "    return {\"content\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "89d3e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서론과 결론 작성 지시사항\n",
    "intro_conclusion_instructions = \"\"\"다음 주제에 관한 보고서를 마무리하는 기술 문서 작성자입니다.\n",
    "\n",
    "주제: {topic}  \n",
    "\n",
    "보고서의 모든 섹션이 제공될 것입니다.\n",
    "당신의 임무는 간결하고 설득력 있는 서론 또는 결론 섹션을 작성하는 것입니다.\n",
    "사용자가 서론 작성 여부를 지시할 것입니다.\n",
    "두 섹션 모두 서두를 포함하지 마십시오.\n",
    "약 200단어를 목표로, 보고서의 모든 섹션을 간결하게 미리 소개(서론)하거나 요약(결론)하십시오.\n",
    "마크다운 서식을 사용하십시오.\n",
    "\n",
    "- 서론의 경우, 매력적인 제목을 만들고 제목에 # 헤더를 사용하십시오.\n",
    "- 서론의 경우, 섹션 헤더로 ## 서론(Introduction)을 사용하십시오.\n",
    "- 결론의 경우, 섹션 헤더로 ## 결론(Conclusion)을 사용하십시오.\n",
    "\n",
    "작성 시 고려해야 할 섹션은 다음과 같습니다: \n",
    "<Sections>\n",
    "{sections}\n",
    "</Sections>\"\"\"\n",
    "\n",
    "\n",
    "def write_introduction(state: ResearchGraphState):\n",
    "    \"\"\"서론 작성\"\"\"\n",
    "\n",
    "    formatted_sections = \"\\n\".join([section for section in state[\"sections\"]])\n",
    "    system_message = intro_conclusion_instructions.format(\n",
    "        topic=state[\"topic\"],\n",
    "        sections=formatted_sections,\n",
    "    )\n",
    "    response = llm.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=\"보고서 서론을 작성하십시오.\")]\n",
    "    )\n",
    "    return {\"introduction\": response.content}\n",
    "\n",
    "\n",
    "# 결론 작성 함수 정의\n",
    "def write_conclusion(state: ResearchGraphState):\n",
    "    \"\"\"결론 작성\"\"\"\n",
    "\n",
    "    formatted_sections = \"\\n\".join([section for section in state[\"sections\"]])\n",
    "    system_message = intro_conclusion_instructions.format(\n",
    "        topic=state[\"topic\"],\n",
    "        sections=formatted_sections,\n",
    "    )\n",
    "    response = llm.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=\"보고서 결론을 작성하십시오.\")]\n",
    "    )\n",
    "    return {\"conclusion\": response.content}\n",
    "\n",
    "\n",
    "def finalize_report(state: ResearchGraphState):\n",
    "    \"\"\"최종 보고서 작성\"\"\"\n",
    "\n",
    "    content = state[\"content\"]\n",
    "\n",
    "    if content.startswith(\"## 통찰\"):\n",
    "        content = content.strip(\"## 통찰\")\n",
    "\n",
    "    if \"## 출처\" in content:\n",
    "        try:\n",
    "            content, sources = content.split(\"\\n## 출처\\n\")\n",
    "        except:\n",
    "            sources = None\n",
    "    else:\n",
    "        sources = None\n",
    "\n",
    "    final_report = (\n",
    "        state[\"introduction\"]\n",
    "        + \"\\n\\n---\\n\\n## 주요 아이디어\\n\\n\"\n",
    "        + content\n",
    "        + \"\\n\\n---\\n\\n\"\n",
    "        + state[\"conclusion\"]\n",
    "    )\n",
    "    if sources is not None:\n",
    "        final_report += \"\\n\\n## 출처\\n\" + sources\n",
    "\n",
    "    return {\"final_report\": final_report}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.constants import START, END\n",
    "\n",
    "builder = StateGraph(ResearchGraphState)\n",
    "\n",
    "builder.add_node(\"create_analysts\", create_analysts)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
    "builder.add_node(\"write_report\", write_report)\n",
    "builder.add_node(\"write_introduction\", write_introduction)\n",
    "builder.add_node(\"write_conclusion\", write_conclusion)\n",
    "builder.add_node(\"finalize_report\", finalize_report)\n",
    "\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\n",
    "    \"human_feedback\",\n",
    "    initiate_all_interviews,\n",
    "    [\n",
    "        \"create_analysts\",\n",
    "        \"conduct_interview\",\n",
    "    ],\n",
    ")\n",
    "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
    "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
    "builder.add_edge(\n",
    "    [\n",
    "        \"write_conclusion\",\n",
    "        \"write_report\",\n",
    "        \"write_introduction\",\n",
    "    ],\n",
    "    \"finalize_report\",  # 보고서 최종 정리\n",
    ")\n",
    "builder.add_edge(\"finalize_report\", END)\n",
    "\n",
    "graph = builder.compile(\n",
    "    interrupt_before=[\"human_feedback\"], checkpointer=InMemorySaver()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f211eb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c01e1",
   "metadata": {},
   "source": [
    "### 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e78850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mcreate_analysts\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "affiliation='AI Research Institute' name='Dr. Mina Park' role='Comparative Technology Analyst' description='Dr. Park specializes in comparing emerging AI techniques, focusing on the architectural differences between modular RAG and traditional RAG. She evaluates how modular designs impact system flexibility, interpretability, and integration complexity.'\n",
      "affiliation='Tech Solutions Inc.' name='Jae-Hyun Kim' role='Production Deployment Strategist' description='Mr. Kim is an expert in deploying AI systems at scale in production environments. He assesses the practical benefits of modular RAG for reliability, maintenance, scalability, and performance improvements over simple RAG implementations.'\n",
      "affiliation='University of Data Science' name='Prof. Eun-Ji Lee' role='Innovation and Application Researcher' description='Prof. Lee investigates novel applications of AI architectures. She explores how modular RAG can enable new capabilities and enhancements in production through component reusability, rapid iteration, and robustness.'\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36m__interrupt__\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import random_uuid\n",
    "\n",
    "config = RunnableConfig(\n",
    "    recursion_limit=30,\n",
    "    configurable={\"thread_id\": random_uuid()},\n",
    ")\n",
    "\n",
    "topic = \"모듈형 RAG가 기존의 단순 RAG와 어떻게 다른지 설명하고, 이를 생산 단계에서 활용할 때의 이점을 제시하십시오.\"\n",
    "inputs = {\"topic\": topic, \"max_analysts\": 3}\n",
    "invoke_graph(\n",
    "    graph,\n",
    "    inputs,\n",
    "    config,\n",
    "    node_names=[\n",
    "        \"create_analysts\",\n",
    "        \"generate_question\",\n",
    "        \"generate_answer\",\n",
    "        \"write_section\",\n",
    "        \"write_report\",\n",
    "        \"write_introduction\",\n",
    "        \"write_conclusion\",\n",
    "        \"finalize_report\",\n",
    "        \"__interrupt__\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9241e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task __input__ with path () wrote to unknown channel human_feedback, ignoring it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mhuman_feedback\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstract—Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of “retrieve-then-generate”. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patterns—linear, conditional,\n",
      "branching, and looping—and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Terms—Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]–[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLM’s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2508.05650v1\" date=\"2025-07-26\" authors=\"Jiaxuan Liang, Shide Zhou, Kailong Wang\"/>\n",
      "<Title>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance\n",
      "LLMs, evaluating its true performance benefits in a reproducible and\n",
      "interpretable way remains a major hurdle. Existing methods often fall short:\n",
      "they lack domain coverage, employ coarse metrics that miss sub document\n",
      "precision, and fail to capture computational trade offs. Most critically, they\n",
      "provide no standardized framework for comparing RAG effectiveness across\n",
      "different models and domains.\n",
      "  We introduce OmniBench RAG, a novel automated platform for multi domain\n",
      "evaluation of RAG systems. The platform quantifies performance gains across\n",
      "accuracy and efficiency dimensions, spanning nine knowledge fields including\n",
      "culture, geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency differences\n",
      "between pre RAG and post RAG models), enabling reproducible comparisons across\n",
      "models and tasks. The platform features dynamic test generation, modular\n",
      "evaluation pipelines, and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant gains in\n",
      "culture to declines in mathematics, highlighting the critical importance of\n",
      "systematic, domain aware assessment. A demonstration video is available at:\n",
      "https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:\n",
      "https://github.com/Garnett-Liang/Omnibench-RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "OmniBench-RAG: A Multi-Domain Evaluation\n",
      "Platform for Retrieval-Augmented Generation Tools\n",
      "Jiaxuan Liang*, Shide Zhou*, and Kailong Wang†\n",
      "Huazhong University of Science and Technology\n",
      "{liangjx, shidez, wangkl}@hust.edu.cn\n",
      "Abstract—While Retrieval Augmented Generation (RAG) is\n",
      "now widely adopted to enhance LLMs, evaluating its true\n",
      "performance benefits in a reproducible and interpretable way\n",
      "remains a major hurdle. Existing methods often fall short: they\n",
      "lack domain coverage, employ coarse metrics that miss sub\n",
      "document precision, and fail to capture computational trade\n",
      "offs. Most critically, they provide no standardized framework\n",
      "for comparing RAG effectiveness across different models and\n",
      "domains.\n",
      "We introduce OmniBench RAG, a novel automated platform\n",
      "for multi domain evaluation of RAG systems. The platform\n",
      "quantifies performance gains across accuracy and efficiency\n",
      "dimensions, spanning nine knowledge fields including culture,\n",
      "geography, and health. We introduce two standardized metrics:\n",
      "Improvements (accuracy gains) and Transformation (efficiency\n",
      "differences between pre RAG and post RAG models), enabling\n",
      "reproducible comparisons across models and tasks. The platform\n",
      "features dynamic test generation, modular evaluation pipelines,\n",
      "and automated knowledge base construction. Our evaluation\n",
      "reveals striking variability in RAG effectiveness, from significant\n",
      "gains in culture to declines in mathematics, highlighting the\n",
      "critical importance of systematic, domain aware assessment. A\n",
      "demonstration video is available at: https://www.youtube.com/\n",
      "watch?v=BZx83QFcTCI. Code and datasets: https://github.com/\n",
      "Garnett-Liang/Omnibench-RAG.\n",
      "I. INTRODUCTION\n",
      "Retrieval-Augmented Generation (RAG) is a key technique\n",
      "for enhancing Large Language Models (LLMs) [1], [2]. By\n",
      "grounding model responses in external, verifiable knowledge,\n",
      "RAG promises to mitigate hallucinations [3], improve factual\n",
      "accuracy [4], and provide up-to-date information [5]. However,\n",
      "the true effectiveness of RAG is far from uniform. Recent\n",
      "studies [6], [7] reveal a significant disparity: while RAG\n",
      "can boost the accuracy of smaller models like Llama-3.2-3B-\n",
      "Instruct by as much as 38.12%, its impact on state-of-the-art\n",
      "models such as GPT-4o, which excel with extended context\n",
      "windows, is often less pronounced. This variability, which\n",
      "depends not only on the model’s scale but also heavily on\n",
      "the knowledge domain, underscores a critical challenge: the\n",
      "lack of a systematic platform to quantify the value of RAG\n",
      "across these diverse contexts.\n",
      "Current RAG evaluation approaches suffer from fundamen-\n",
      "tal limitations that impede reproducible and comprehensive as-\n",
      "sessment: First, they lack automated multi-domain evalua-\n",
      "tion capabilities and rely on non-deterministic components.\n",
      "*Jiaxuan Liang and Shide Zhou are co-first authors.\n",
      "†Kailong Wang is the corresponding author.\n",
      "Existing benchmarks typically require manual configuration\n",
      "for each knowledge domain and fail to provide unified assess-\n",
      "ment across diverse fields like finance, healthcare, or culture,\n",
      "making cross-domain performance analysis labor-intensive and\n",
      "inconsistent. Moreover, key metrics in leading frameworks\n",
      "(e.g., LLM-based scoring in Ragas [8]) inadvertently introduce\n",
      "randomness due to reliance on large language models in the\n",
      "evaluation loop, undermining result reproducibility. Second,\n",
      "they employ static datasets and coarse-grained metrics.\n",
      "Most frameworks rely on fixed benchmarks and document-\n",
      "level retrieval metrics (e.g., MRR@k[9]), missing the critical\n",
      "sub-document precision needed to assess whether models\n",
      "extract specific facts accurately. They also lack the ability to\n",
      "dynamically generate test cases that probe complex reasoning\n",
      "patterns. Third, they fail to capture the computational\n",
      "trade-offs inherent in RAG systems. Without automated\n",
      "profiling of resource utilization and efficiency metrics, practi-\n",
      "tioners cannot make informed decisions about the cost-benefit\n",
      "trade-offs of deploying RAG in production environments.\n",
      "Our \n",
      "</Content>\n",
      "</Document>\n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2505.20096v2\" date=\"2025-10-11\" authors=\"Thang Nguyen, Peter Chin, Yu-Wing Tai\"/>\n",
      "<Title>\n",
      "MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\n",
      "(RAG) that addresses the inherent ambiguities and reasoning challenges in\n",
      "complex information-seeking tasks. Unlike conventional RAG methods that rely on\n",
      "end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates\n",
      "a collaborative set of specialized AI agents: Planner, Step Definer, Extractor,\n",
      "and QA Agents, each responsible for a distinct stage of the RAG pipeline. By\n",
      "decomposing tasks into subtasks such as query disambiguation, evidence\n",
      "extraction, and answer synthesis, and enabling agents to communicate\n",
      "intermediate reasoning via chain-of-thought prompting, MA-RAG progressively\n",
      "refines retrieval and synthesis while maintaining modular interpretability.\n",
      "Extensive experiments on multi-hop and ambiguous QA benchmarks, including NQ,\n",
      "HotpotQA, 2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly\n",
      "outperforms standalone LLMs and existing RAG methods across all model scales.\n",
      "Notably, even a small LLaMA3-8B model equipped with MA-RAG surpasses larger\n",
      "standalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\n",
      "state-of-the-art results on challenging multi-hop datasets. Ablation studies\n",
      "reveal that both the planner and extractor agents are critical for multi-hop\n",
      "reasoning, and that high-capacity models are especially important for the QA\n",
      "agent to synthesize answers effectively. Beyond general-domain QA, MA-RAG\n",
      "generalizes to specialized domains such as medical QA, achieving competitive\n",
      "performance against domain-specific models without any domain-specific\n",
      "fine-tuning. Our results highlight the effectiveness of collaborative, modular\n",
      "reasoning in retrieval-augmented systems: MA-RAG not only improves answer\n",
      "accuracy and robustness but also provides interpretable intermediate reasoning\n",
      "steps, establishing a new paradigm for efficient and reliable multi-agent RAG.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "MA-RAG: MULTI-AGENT RETRIEVAL-AUGMENTED\n",
      "GENERATION\n",
      "VIA\n",
      "COLLABORATIVE\n",
      "CHAIN-OF-\n",
      "THOUGHT REASONING\n",
      "Thang Nguyen & Peter Chin & Yu-Wing Tai\n",
      "Dartmouth College\n",
      "{thangnv.th, peter.chin, yu-wing.tai}@dartmouth.edu\n",
      "ABSTRACT\n",
      "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Gener-\n",
      "ation (RAG) that addresses the inherent ambiguities and reasoning challenges in\n",
      "complex information-seeking tasks. Unlike conventional RAG methods that rely\n",
      "on end-to-end fine-tuning or isolated component enhancements, MA-RAG orches-\n",
      "trates a collaborative set of specialized AI agents: Planner, Step Definer, Extrac-\n",
      "tor, and QA Agents, each responsible for a distinct stage of the RAG pipeline.\n",
      "By decomposing tasks into subtasks such as query disambiguation, evidence ex-\n",
      "traction, and answer synthesis, and enabling agents to communicate intermedi-\n",
      "ate reasoning via chain-of-thought prompting, MA-RAG progressively refines re-\n",
      "trieval and synthesis while maintaining modular interpretability. Extensive exper-\n",
      "iments on multi-hop and ambiguous QA benchmarks, including NQ, HotpotQA,\n",
      "2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly outperforms\n",
      "standalone LLMs and existing RAG methods across all model scales. Notably,\n",
      "even a small LLaMA3-8B model equipped with MA-RAG surpasses larger stan-\n",
      "dalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\n",
      "state-of-the-art results on challenging multi-hop datasets. Ablation studies reveal\n",
      "that both the planner and extractor agents are critical for multi-hop reasoning,\n",
      "and that high-capacity models are especially important for the QA agent to syn-\n",
      "thesize answers effectively. Beyond general-domain QA, MA-RAG generalizes\n",
      "to specialized domains such as medical QA, achieving competitive performance\n",
      "against domain-specific models without any domain-specific fine-tuning. Our re-\n",
      "sults highlight the effectiveness of collaborative, modular reasoning in retrieval-\n",
      "augmented systems: MA-RAG not only improves answer accuracy and robustness\n",
      "but also provides interpretable intermediate reasoning steps, establishing a new\n",
      "paradigm for efficient and reliable multi-agent RAG1.\n",
      "1\n",
      "INTRODUCTION\n",
      "Recent advances in natural language processing have driven the development of Retrieval-\n",
      "Augmented Generation (RAG) models, which aim to enhance the factual accuracy and contextual\n",
      "relevance of generated text by integrating external knowledge sources (Lewis et al., 2020; Guu et al.,\n",
      "2020; Izacard & Grave, 2021; Lin et al., 2024). These systems address core limitations of Large Lan-\n",
      "guage Models (LLMs), such as outdated knowledge (Zhang et al., 2023b; Kasai et al., 2023) and\n",
      "poor generalization to domain-specific queries (Siriwardhana et al., 2023; Xiong et al., 2024), by\n",
      "retrieving top-k documents from an external corpus (Formal et al., 2022; Izacard et al., 2022; Wang\n",
      "et al., 2022a) to ground the model’s output in relevant evidence.\n",
      "Prior research in RAG has largely concentrated on optimizing three key components—retrieval,\n",
      "augmentation, and generation (Gao et al., 2024; Fan et al., 2024) (Figure 1(a)). Retrieval strate-\n",
      "gies span sparse methods (Jones, 1972; Robertson & Zaragoza, 2009) and dense retrieval (Reimers\n",
      "& Gurevych, 2019; Karpukhin et al., 2020), each with respective weaknesses such as lexical\n",
      "gaps (Berger et al., 2000) or retrieval failure on out-of-distribution and multi-hop queries (Dai et al.,\n",
      "1Our code is available at https://github.com/thangylvp/MA-RAG\n",
      "1\n",
      "arXiv:2505.20096v2  [cs.CL]  11 Oct 2025\n",
      "Query\n",
      "Docs\n",
      "Answer\n",
      "Docs\n",
      "Answer\n",
      "CoT\n",
      "Notes\n",
      "Post-process\n",
      "a) Vanilla RAG\n",
      "Step 1\n",
      "Step ...\n",
      "CoT\n",
      "Sub-Query\n",
      "Query\n",
      "Docs\n",
      "Notes\n",
      "CoT\n",
      "Query\n",
      "Sub-Answer\n",
      "CoT\n",
      "b) RAG with post-\n",
      "processing retrieved docs\n",
      "d) MA-RAG\n",
      "Query\n",
      "Docs\n",
      "Answer\n",
      "c) RAG with interleaving\n",
      "retrieval and thoughts\n",
      "Answer\n",
      "CoT\n",
      "Figure 1: Architectural Comparison of MA-RAG and Prior RAG Methods. a) A naive RAG sys-\n",
      "tem performs one-shot retrieval followed by direct answer generation. b) Enhanced systems incor-\n",
      "porate post-retrieval processing such as document re-\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"web\" url=\"https://brunch.co.kr/@@aPda/338\" title=\"12화 복잡한 RAG 분해하기-Modular RAG란? - 브런치\">모듈러 RAG는 복잡한 RAG 시스템을 마치 레고 블록처럼 여러 개의 독립적인 모듈로 나누어, 필요에 따라 각 모듈을 교체하거나 조합할 수 있게 만들어 줍니다. **모듈러 RAG는 각 모듈을 독립적으로 설계하고 이를 필요에 따라 교체하거나 결합할 수 있도록 합니다.** 예를 들어, 새로운 임베딩 모델이 등장하거나 기존의 벡터 DB가 성능을 더 높일 수 있다고 판단되면, 해당 모듈만 교체하는 방식으로 시스템을 최적화할 수 있습니다. **모듈러 RAG는 또한 동적이고 적응 가능한 시스템을 가능하게 만듭니다.** 예를 들어, 특정 작업이나 데이터 소스에 맞는 모듈을 선택하고, 이를 조합함으로써 효율적인 RAG 시스템을 구성할 수 있습니다. **또한, 모듈러 RAG는 시스템의 복잡도를 낮추고, 성능을 더욱 향상할 수 있는 가능성을 제공합니다.** 예를 들어, 특정 데이터 소스에 더 적합한 벡터 DB를 찾거나, 최신의 임베딩 모델을 도입하는 등의 작업을 통해 성능을 지속적으로 개선할 수 있습니다.</Document>\n",
      "<Document source=\"web\" url=\"https://g3lu.tistory.com/42\" title=\"RAG의 패러다임(Naive RAG, Advanced RAG, Modular RAG)\">## RAG의 패러다임(Naive RAG, Advanced RAG, Modular RAG) 본문 Retrieval-Augmented Geneartion(RAG)는 외부 지식 소스로부터 추가적인 정보를 통합하여 대형 언어 모델(LLM)을 개선하는 과정이다. 이는 중요한 정보를 놓칠 수 있게 된다. * **잘못된 정보 제공** : 유용한 정보를 제공하지 않고 검색된 내용을 단순히 반복하는 결과를 초래할 수 있으며, 일관성 없는 답변을 뱉는 경우가 발생한다. Advanced RAG는 Naive RAG 방식에서 직면하고 있는 문제를 해결하기 위해 고안되었다. 위의 세 가지 고찰을 보완하기 위해 **Pre-Retreival 및 Post-Retrieval**를 기존 RAG 아키텍처에 추가한 것이 Advanced RAG이다. 하지만 검색된 청크들이 간혹 중복이 되거나 의미 없는 정보를 담는 경우 발생하게 되는데, 이는 LLM이 주어진 컨텍스트를 처리하는 방식에 영향을 미칠 수 있다. * **Prompt Compression** : 검색된 정보에 Noisy가 많을 수 있으므로, LLM에 태우기전에 관련 없는 정보를 압축하고 길이를 줄이는 것도 중요하다.</Document>\n",
      "<Document source=\"web\" url=\"https://brunch.co.kr/@vsongyev/28\" title=\"RAG 완벽 가이드: 세 가지 패러다임으로 보는 RAG - 브런치\">RAG의 세 가지 기술 패러다임에 대해 소개하고 어떤 과정으로 진행되는지, 각 패러다임에 대한 한계점과 여기서 얻을 수 있는 UX 인사이트까지 모두 알려 Drill 게요~! 이를 통해, 인공지능 모델의 추가 학습 없이도 외부 지식을 효과적으로 활용하여 보다 정확한 정보를 제공할 수 있으며, 환각 문제를 줄일 수 있습니다. 기본 RAG부터 모듈형 RAG까지 어떻게 구성되어 있는지 위의 이미지를 보시면 한눈에 확인할 수 있습니다. 아래의 이미지를 보시게 되면 기본 RAG에서 검색 전 과정과 검색 후 과정이 추가된 것을 보실 수 있습니다. 고급 RAG는 기존 데이터의 색인화와 검색 품질 개선에 중점을 두지만, 여전히 처리할 수 있는 데이터의 양과 종류에 제한이 있을 수 있습니다. 앞에서 다뤘던 기본 RAG는 검색(retrieval)과 생성(generation)의 두 가지 모듈로 구성할 수 있습니다.</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"web\" url=\"https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag\" title=\"The 3 types of RAG models: Naive RAG, Modular RAG ... - Rabiloo\">Building AI systems requires choosing the right tools for the job, and Retrieval-Augmented Generation (RAG) offers various models, each designed to serve different needs. Retrieval-Augmented Generation (RAG) is a powerful AI framework that blends the retrieval of external data with content generation. Essentially, a RAG model retrieves information from external databases, knowledge bases, or the web and then uses that data to generate relevant, meaningful responses. Naive RAG begins by indexing the data source for quick retrieval of relevant information. Modular RAG builds on the basic principles of Naive RAG by breaking down the retrieval and generation processes into separate, specialized modules. The generation module in Advanced RAG then processes the refined data using sophisticated models like T5 or GPT-3.</Document>\n",
      "<Document source=\"web\" url=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\" title=\"How does Modular RAG improve upon Naive RAG? - ADaSci\">Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.</Document>\n",
      "<Document source=\"web\" url=\"https://www.linkedin.com/pulse/comparison-between-three-rag-paradigms-sanjay-kumar-mba-ms-phd-tzrdc\" title=\"Comparison between three RAG paradigms - LinkedIn\">Mastering Retrieval-Augmented Generation (RAG): A Deep Dive into Naive, Advanced, and Modular Paradigms The world of AI and natural language processing is rapidly evolving, and Retrieval-Augmented Generation (RAG) has emerged as a groundbreaking approach to enhance the capabilities of large language models (LLMs). By combining the power of retrieval systems with generative models, RAG allows AI to access external data sources, making responses more accurate, context-aware, and up-to-date. What is Retrieval-Augmented Generation (RAG)? * The model uses the retrieved chunks as context to ensure the output is relevant to the query. For applications where accuracy and relevance are more critical, Advanced RAG builds upon the naive approach by adding pre- and post-retrieval enhancements.</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"web\" url=\"https://g3lu.tistory.com/42\" title=\"RAG의 패러다임(Naive RAG, Advanced RAG, Modular RAG)\">## RAG의 패러다임(Naive RAG, Advanced RAG, Modular RAG) 본문 Retrieval-Augmented Geneartion(RAG)는 외부 지식 소스로부터 추가적인 정보를 통합하여 대형 언어 모델(LLM)을 개선하는 과정이다. 이는 중요한 정보를 놓칠 수 있게 된다. * **잘못된 정보 제공** : 유용한 정보를 제공하지 않고 검색된 내용을 단순히 반복하는 결과를 초래할 수 있으며, 일관성 없는 답변을 뱉는 경우가 발생한다. Advanced RAG는 Naive RAG 방식에서 직면하고 있는 문제를 해결하기 위해 고안되었다. 위의 세 가지 고찰을 보완하기 위해 **Pre-Retreival 및 Post-Retrieval**를 기존 RAG 아키텍처에 추가한 것이 Advanced RAG이다. 하지만 검색된 청크들이 간혹 중복이 되거나 의미 없는 정보를 담는 경우 발생하게 되는데, 이는 LLM이 주어진 컨텍스트를 처리하는 방식에 영향을 미칠 수 있다. * **Prompt Compression** : 검색된 정보에 Noisy가 많을 수 있으므로, LLM에 태우기전에 관련 없는 정보를 압축하고 길이를 줄이는 것도 중요하다.</Document>\n",
      "<Document source=\"web\" url=\"https://brunch.co.kr/@@aPda/338\" title=\"12화 복잡한 RAG 분해하기-Modular RAG란? - 브런치\">모듈러 RAG는 복잡한 RAG 시스템을 마치 레고 블록처럼 여러 개의 독립적인 모듈로 나누어, 필요에 따라 각 모듈을 교체하거나 조합할 수 있게 만들어 줍니다. **모듈러 RAG는 각 모듈을 독립적으로 설계하고 이를 필요에 따라 교체하거나 결합할 수 있도록 합니다.** 예를 들어, 새로운 임베딩 모델이 등장하거나 기존의 벡터 DB가 성능을 더 높일 수 있다고 판단되면, 해당 모듈만 교체하는 방식으로 시스템을 최적화할 수 있습니다. **모듈러 RAG는 또한 동적이고 적응 가능한 시스템을 가능하게 만듭니다.** 예를 들어, 특정 작업이나 데이터 소스에 맞는 모듈을 선택하고, 이를 조합함으로써 효율적인 RAG 시스템을 구성할 수 있습니다. **또한, 모듈러 RAG는 시스템의 복잡도를 낮추고, 성능을 더욱 향상할 수 있는 가능성을 제공합니다.** 예를 들어, 특정 데이터 소스에 더 적합한 벡터 DB를 찾거나, 최신의 임베딩 모델을 도입하는 등의 작업을 통해 성능을 지속적으로 개선할 수 있습니다.</Document>\n",
      "<Document source=\"web\" url=\"https://brunch.co.kr/@vsongyev/28\" title=\"RAG 완벽 가이드: 세 가지 패러다임으로 보는 RAG - 브런치\">RAG의 세 가지 기술 패러다임에 대해 소개하고 어떤 과정으로 진행되는지, 각 패러다임에 대한 한계점과 여기서 얻을 수 있는 UX 인사이트까지 모두 알려 Drill 게요~! 이를 통해, 인공지능 모델의 추가 학습 없이도 외부 지식을 효과적으로 활용하여 보다 정확한 정보를 제공할 수 있으며, 환각 문제를 줄일 수 있습니다. 기본 RAG부터 모듈형 RAG까지 어떻게 구성되어 있는지 위의 이미지를 보시면 한눈에 확인할 수 있습니다. 아래의 이미지를 보시게 되면 기본 RAG에서 검색 전 과정과 검색 후 과정이 추가된 것을 보실 수 있습니다. 고급 RAG는 기존 데이터의 색인화와 검색 품질 개선에 중점을 두지만, 여전히 처리할 수 있는 데이터의 양과 종류에 제한이 있을 수 있습니다. 앞에서 다뤘던 기본 RAG는 검색(retrieval)과 생성(generation)의 두 가지 모듈로 구성할 수 있습니다.</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_answer\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_answer\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2508.18748v2\" date=\"2025-10-13\" authors=\"Byeongjeong Kim, Jeonghyun Park, Joonho Yang, Hwanhee Lee\"/>\n",
      "<Title>\n",
      "Chronological Passage Assembling in RAG framework for Temporal Question Answering\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Long-context question answering over narrative tasks is challenging because\n",
      "correct answers often hinge on reconstructing a coherent timeline of events\n",
      "while preserving contextual f low in a limited context window.\n",
      "Retrievalaugmented generation (RAG) methods aim to address this challenge by\n",
      "selectively retrieving only necessary document segments. However, narrative\n",
      "texts possess unique characteristics that limit the effectiveness of these\n",
      "existing approaches. Specifically, understanding narrative texts requires more\n",
      "than isolated segments, as the broader context and sequential relationships\n",
      "between segments are crucial for comprehension. To address these limitations,\n",
      "we propose ChronoRAG, a novel RAG framework specialized for narrative texts.\n",
      "This approach focuses on two essential aspects: refining dispersed document\n",
      "information into coherent and structured passages and preserving narrative flow\n",
      "by explicitly capturing and maintaining the temporal order among retrieved\n",
      "passages. We empirically demonstrate the effectiveness of ChronoRAG through\n",
      "experiments on the NarrativeQA and GutenQAdataset, showing substantial\n",
      "improvements in tasks requiring both factual identification and comprehension\n",
      "of complex sequential relationships, underscoring that reasoning over temporal\n",
      "order is crucial in resolving narrative QA.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Chronological Passage Assembling in RAG framework for Temporal\n",
      "Question Answering\n",
      "Byeongjeong Kim, Jeonghyun Park, Joonho Yang, Hwanhee Lee*\n",
      "Department of Artificial Intelligence, Chung-Ang University\n",
      "{michael97k, tom0365, plm3332, hwanheelee}@cau.ac.kr\n",
      "Abstract\n",
      "Long-context question answering over narra-\n",
      "tive tasks is challenging because correct an-\n",
      "swers often hinge on reconstructing a coherent\n",
      "timeline of events while preserving contextual\n",
      "flow in a limited context window. Retrieval-\n",
      "augmented generation (RAG) methods aim to\n",
      "address this challenge by selectively retrieving\n",
      "only necessary document segments. However,\n",
      "narrative texts possess unique characteristics\n",
      "that limit the effectiveness of these existing ap-\n",
      "proaches. Specifically, understanding narrative\n",
      "texts requires more than isolated segments, as\n",
      "the broader context and sequential relationships\n",
      "between segments are crucial for comprehen-\n",
      "sion. To address these limitations, we propose\n",
      "ChronoRAG, a novel RAG framework special-\n",
      "ized for narrative texts. This approach focuses\n",
      "on two essential aspects: refining dispersed\n",
      "document information into coherent and struc-\n",
      "tured passages and preserving narrative flow\n",
      "by explicitly capturing and maintaining the\n",
      "temporal order among retrieved passages. We\n",
      "empirically demonstrate the effectiveness of\n",
      "ChronoRAG through experiments on the Narra-\n",
      "tiveQA and GutenQA dataset, showing substan-\n",
      "tial improvements in tasks requiring both fac-\n",
      "tual identification and comprehension of com-\n",
      "plex sequential relationships, underscoring that\n",
      "reasoning over temporal order is crucial in re-\n",
      "solving narrative QA. 1\n",
      "1\n",
      "Introduction\n",
      "Long-context question answering tasks, which re-\n",
      "quire the ability to utilize one or more long doc-\n",
      "uments (Pang et al., 2022), present a significant\n",
      "challenge in natural language processing. While\n",
      "modern transformer-based Large Language Models\n",
      "(LLMs) have shown a remarkable ability to han-\n",
      "dle long contexts (Liu et al., 2025; Wang et al.,\n",
      "2024), they face fundamental limitations when con-\n",
      "fronted with extremely long-form text. Processing\n",
      "*Corresponding Author.\n",
      "1The source code will be released upon paper acceptance.\n",
      "Query:  Where is George Darrow residing when he prepares to join Anna Leath in France? \n",
      "Answer:  In London \n",
      "(a) Retrieved Sentences by General Method\n",
      "(b) Retrieved Passages by Chronological Assembling (Ours)\n",
      "George Darrow is in London for a dinner party where he reunites with Anna\n",
      "Anna and Darrow met in Paris, which is relevant to their conversation\n",
      "Anna Leath feels reassured by Darrow's arrival and a sense of normalcy is restored\n",
      "Darrow met Mr. Leath, Anna's husband, in the past\n",
      "Anna and Darrow are parting ways and Anna is drawn to Darrow\n",
      "Anna is engaged to George Darrow\n",
      "Anna and Darrow met in Paris, which is relevant to their conversation \n",
      "George Darrow is in London for a dinner party where he reunites with Anna\n",
      "“Darrow and Anna Summers have a past connection and are rekindling their relationship” +\n",
      " + “George Darrow and Anna have a past romantic relationship and are reuniting after 12 years” \n",
      "+ “Anna and Darrow have a heart-wrenching goodbye, with Darrow revealing he won't return”\n",
      "“Darrow is Anna's partner, and their conversation is tense and awkward” +\n",
      "Figure 1: Retrieval comparison for a narrative query. (a)\n",
      "Fine-grained indexing returns six standalone sentences,\n",
      "leaving key clues detached. (b) Our chronological as-\n",
      "sembling retrieves passages that include their immedi-\n",
      "ate chronological context, preserving the narrative flow.\n",
      "Boxes indicate the directly retrieved sentences.\n",
      "extensive documents for every query leads to ma-\n",
      "jor computational inefficiency, and as the context\n",
      "grows longer, the models’ ability to accurately iden-\n",
      "tify and prioritize relevant information decreases,\n",
      "impacting the reliability of their outputs.\n",
      "To\n",
      "address\n",
      "these\n",
      "challenges,\n",
      "Retrieval-\n",
      "Augmented Generation (RAG) (Lewis et al., 2020)\n",
      "has become a standard approach, focusing on\n",
      "efficiently retrieving only relevant segments from\n",
      "large\n",
      "</Content>\n",
      "</Document>\n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2509.11937v1\" date=\"2025-09-15\" authors=\"Alexandre Sallinen, Stefan Krsteski, Paul Teiletche, Marc-Antoine Allard, Baptiste Lecoeur, Michael Zhang, Fabrice Nemo, David Kalajdzic, Matthias Meyer, Mary-Anne Hartley\"/>\n",
      "<Title>\n",
      "MMORE: Massive Multimodal Open RAG & Extraction\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "We introduce MMORE, an open-source pipeline for Massive Multimodal Open\n",
      "RetrievalAugmented Generation and Extraction, designed to ingest, transform,\n",
      "and retrieve knowledge from heterogeneous document formats at scale. MMORE\n",
      "supports more than fifteen file types, including text, tables, images, emails,\n",
      "audio, and video, and processes them into a unified format to enable downstream\n",
      "applications for LLMs. The architecture offers modular, distributed processing,\n",
      "enabling scalable parallelization across CPUs and GPUs. On processing\n",
      "benchmarks, MMORE demonstrates a 3.8-fold speedup over single-node baselines\n",
      "and 40% higher accuracy than Docling on scanned PDFs. The pipeline integrates\n",
      "hybrid dense-sparse retrieval and supports both interactive APIs and batch RAG\n",
      "endpoints. Evaluated on PubMedQA, MMORE-augmented medical LLMs improve\n",
      "biomedical QA accuracy with increasing retrieval depth. MMORE provides a\n",
      "robust, extensible foundation for deploying task-agnostic RAG systems on\n",
      "diverse, real-world multimodal data. The codebase is available at\n",
      "https://github.com/swiss-ai/mmore.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "MMORE: Massive Multimodal Open RAG & Extraction\n",
      "Alexandre Sallinen 1 Stefan Krsteski 1 Paul Teiletche 1 Marc-Antoine Allard 1 Baptiste Lecoeur 1\n",
      "Michael Zhang 1 David Kalajdzic 1 Matthias Meyer 2 Fabrice Nemo 1 Mary-Anne Hartley 1 3\n",
      "1 EPFL, Switzerland\n",
      "2 ETHZ, Switzerland\n",
      "3 Harvard University, USA\n",
      "Abstract\n",
      "We\n",
      "introduce MMORE,\n",
      "an\n",
      "open-source\n",
      "pipeline for Massive Multimodal Open Retrieval-\n",
      "Augmented Generation and Extraction, designed\n",
      "to ingest, transform, and retrieve knowledge\n",
      "from heterogeneous document formats at scale.\n",
      "MMORE supports more than fifteen file types,\n",
      "including text, tables, images, emails, audio, and\n",
      "video, and processes them into a unified format to\n",
      "enable downstream applications for LLMs. The\n",
      "architecture offers modular, distributed process-\n",
      "ing, enabling scalable parallelization across CPUs\n",
      "and GPUs. On processing benchmarks, MMORE\n",
      "demonstrates a 3.8-fold speedup over single-node\n",
      "baselines and 40% higher accuracy than Docling\n",
      "on scanned PDFs. The pipeline integrates hybrid\n",
      "dense-sparse retrieval and supports both interac-\n",
      "tive APIs and batch RAG endpoints. Evaluated\n",
      "on PubMedQA, MMORE-augmented medical\n",
      "LLMs improve biomedical QA accuracy with\n",
      "increasing retrieval depth. MMORE provides\n",
      "a robust, extensible foundation for deploying\n",
      "task-agnostic RAG systems on diverse, real-world\n",
      "multimodal data. The codebase is available at\n",
      "https://github.com/swiss-ai/mmore.\n",
      "1. Introduction\n",
      "As of 2025, the public web is conservatively estimated\n",
      "to host more than 2.5 trillion PDF documents, alongside\n",
      "petabytes of mixed-modality slide decks, spreadsheets, im-\n",
      "ages, and audiovisual artefacts (CloudFiles, 2025). Yet\n",
      "fewer than one percent of these resources are represented\n",
      "in popular machine-learning corpora as they are remain\n",
      "locked behind brittle, heterogeneous formats that frustrate\n",
      "automated parsing at scale. Existing pipelines rely on ad\n",
      "hoc mosaics of format-specific utilities, limiting throughput,\n",
      "reproducibility, and long-term maintainability.\n",
      "As data-supply forecasts estimate that the pool of high-\n",
      "quality human-generated text could be exhausted by prevail-\n",
      "ing scaling trends as early as 2026 (Villalobos et al., 2022;\n",
      "2024), it has become essential to find more format-agnostic\n",
      "preprocessing workflows. Much of this data, particularly in\n",
      "specialized or institutional settings, is unavailable for train-\n",
      "ing but remains crucial for improving the verifiability of\n",
      "LLM outputs through RAG. Hallucinations (OpenAI, 2025)\n",
      "and factual drift (Huang et al., 2025) remain significant chal-\n",
      "lenges, and robust RAG pipelines are increasingly explored\n",
      "as a means to mitigate these issues, thereby reducing the bur-\n",
      "den of manual validation and better aligning model outputs\n",
      "with trustworthy source material.\n",
      "To address these limitations, we introduce MMORE an\n",
      "open-source tool for Massive Multimodal Open Retrieval-\n",
      "Augmented Generation and Extraction, a unified pipeline\n",
      "for scalable extraction, transformation, and retrieval of mul-\n",
      "timodal data. MMORE supports diverse formats such as\n",
      "documents, presentations, spreadsheets, and multimedia and\n",
      "integrates them into a structured knowledge base, enabling\n",
      "LLMs to access accurate, contextually grounded informa-\n",
      "tion via the RAG paradigm.\n",
      "Designed for modularity and scalability, our pipeline na-\n",
      "tively supports parallelized processing across multi-node\n",
      "architectures and distributed environments such as Kuber-\n",
      "netes clusters. Compared to Docling demonstrates more\n",
      "than 2-fold faster end-to-end processing, while achieving\n",
      "40% higher layout accuracy on scanned PDFs. In distributed\n",
      "mode, we show that our pipeline processes 720 pages in\n",
      "185s using four nodes, resulting in 3.8-fold speedup over\n",
      "single-node mode. The results demonstrate MMORE’s ef-\n",
      "fectiveness as a scalable, high-accuracy solution for multi-\n",
      "modal document processing in real-world deployment.\n",
      "2. Related Work\n",
      "Large-scale transformation of unstructured documents into\n",
      "structured, machine-readable format has attracted substan-\n",
      "tial attention. We gr\n",
      "</Content>\n",
      "</Document>\n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2508.14064v1\" date=\"2025-08-11\" authors=\"Yao Ding, Yuqing Wu, Ziyang Ding\"/>\n",
      "<Title>\n",
      "An automatic patent literature retrieval system based on LLM-RAG\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "With the acceleration of technological innovation efficient retrieval and\n",
      "classification of patent literature have become essential for intellectual\n",
      "property management and enterprise RD Traditional keyword and rulebased\n",
      "retrieval methods often fail to address complex query intents or capture\n",
      "semantic associations across technical domains resulting in incomplete and\n",
      "lowrelevance results This study presents an automated patent retrieval\n",
      "framework integrating Large Language Models LLMs with RetrievalAugmented\n",
      "Generation RAG technology The system comprises three components: 1) a\n",
      "preprocessing module for patent data standardization, 2) a highefficiency\n",
      "vector retrieval engine leveraging LLMgenerated embeddings, and 3) a\n",
      "RAGenhanced query module that combines external document retrieval with\n",
      "contextaware response generation Evaluations were conducted on the Google\n",
      "Patents dataset 20062024 containing millions of global patent records with\n",
      "metadata such as filing date domain and status The proposed gpt35turbo0125RAG\n",
      "configuration achieved 805 semantic matching accuracy and 92.1% recall\n",
      "surpassing baseline LLM methods by 28 percentage points The framework also\n",
      "demonstrated strong generalization in crossdomain classification and semantic\n",
      "clustering tasks These results validate the effectiveness of LLMRAG integration\n",
      "for intelligent patent retrieval providing a foundation for nextgeneration\n",
      "AIdriven intellectual property analysis platforms\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "An automatic patent literature retrieval system based on \n",
      "LLM-RAG \n",
      "Yao Ding1,4, Yuqing Wu2,5, Ziyang Ding3,6 \n",
      "1 Belarusian State University, Belarus \n",
      "2 Uber Technologies, Inc., Seattle, USA \n",
      "3 School of Humanities and Sciences, Stanford University, USA \n",
      " \n",
      " \n",
      "415503636910@163.com  \n",
      "5wuyuqing2018@gmail.com \n",
      "6 zd26@stanford.edu \n",
      " \n",
      "Abstract. With the acceleration of technological innovation, efficient retrieval and \n",
      "classification of patent literature have become essential for intellectual property \n",
      "management and enterprise R&D. Traditional keyword- and rule-based retrieval \n",
      "methods often fail to address complex query intents or capture semantic associations \n",
      "across technical domains, resulting in incomplete and low-relevance results. This study \n",
      "presents an automated patent retrieval framework integrating Large Language Models \n",
      "(LLMs) with Retrieval-Augmented Generation (RAG) technology. The system \n",
      "comprises three components: (1) a preprocessing module for patent data \n",
      "standardization, (2) a high-efficiency vector retrieval engine leveraging LLM-\n",
      "generated embeddings, and (3) a RAG-enhanced query module that combines external \n",
      "document retrieval with context-aware response generation. Evaluations were \n",
      "conducted on the Google Patents dataset (2006–2024), containing millions of global \n",
      "patent records with metadata such as filing date, domain, and status. The proposed gpt-\n",
      "3.5-turbo-0125+RAG configuration achieved 80.5% semantic matching accuracy and \n",
      "92.1% recall, surpassing baseline LLM methods by 28 percentage points. The \n",
      "framework also demonstrated strong generalization in cross-domain classification and \n",
      "semantic clustering tasks. These results validate the effectiveness of LLM–RAG \n",
      "integration for intelligent patent retrieval, providing a foundation for next-generation \n",
      "AI-driven intellectual property analysis platforms. \n",
      "Keywords: Rag technology, knowledge base retrieval, big language model, patent \n",
      "literature retrieval \n",
      "1.  Introduction \n",
      "In the context of today’s rapid knowledge expansion and technological innovation, patents \n",
      "serve as a critical indicator of technological advancement and intellectual property protection. \n",
      "With millions of patents issued by more than a dozen global patent offices, the challenge of \n",
      "efficiently and accurately retrieving relevant documents from massive patent databases has \n",
      "become a major bottleneck for technological intelligence mining and enterprise R&D decision-\n",
      "making. Traditional patent search methods, which rely heavily on keyword matching and \n",
      "manually designed rules, often fail to capture the nuanced intent behind queries or detect \n",
      "semantic relationships across technical domains—leading to limited recall and low relevance \n",
      "in retrieved results [1]. \n",
      "To address these limitations, Large Language Models (LLMs) have recently demonstrated \n",
      "remarkable capabilities in natural language understanding and generation, offering new \n",
      "potential for intelligent retrieval systems. However, general-purpose LLMs struggle when \n",
      "applied directly to patent documents, which combine structured metadata with dense, domain-\n",
      "specific technical descriptions. They often lack sufficient domain knowledge and fail to grasp \n",
      "specialized terminologies. Retrieval-Augmented Generation (RAG) technology has emerged as \n",
      "a cutting-edge solution by combining LLMs with external document retrieval systems, enabling \n",
      "the model to dynamically incorporate relevant knowledge during generation. This significantly \n",
      "enhances both semantic understanding and precision in specialized tasks such as patent analysis \n",
      "[2]. \n",
      "In this work, we propose an automatic patent literature retrieval system based on the LLM-\n",
      "RAG framework. Our goal is to integrate the deep semantic modeling capabilities of LLMs \n",
      "with the broad coverage and efficiency of vector-based retrieval, thereby enhancing the \n",
      "performance of patent document matching, semantic relevance scoring, and cross-domain \n",
      "similarity analysis. The system consists of three main component\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstract—Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of “retrieve-then-generate”. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patterns—linear, conditional,\n",
      "branching, and looping—and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Terms—Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]–[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLM’s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2501.00353v1\" date=\"2024-12-31\" authors=\"Wanlong Liu, Junying Chen, Ke Ji, Li Zhou, Wenyu Chen, Benyou Wang\"/>\n",
      "<Title>\n",
      "RAG-Instruct: Boosting LLMs with Diverse Retrieval-Augmented Instructions\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-Augmented Generation (RAG) has emerged as a key paradigm for\n",
      "enhancing large language models (LLMs) by incorporating external knowledge.\n",
      "However, current RAG methods face two limitations: (1) they only cover limited\n",
      "RAG scenarios. (2) They suffer from limited task diversity due to the lack of a\n",
      "general RAG dataset. To address these limitations, we propose RAG-Instruct, a\n",
      "general method for synthesizing diverse and high-quality RAG instruction data\n",
      "based on any source corpus. Our approach leverages (1) five RAG paradigms,\n",
      "which encompass diverse query-document relationships, and (2) instruction\n",
      "simulation, which enhances instruction diversity and quality by utilizing the\n",
      "strengths of existing instruction datasets. Using this method, we construct a\n",
      "40K instruction dataset from Wikipedia, comprehensively covering diverse RAG\n",
      "scenarios and tasks. Experiments demonstrate that RAG-Instruct effectively\n",
      "enhances LLMs' RAG capabilities, achieving strong zero-shot performance and\n",
      "significantly outperforming various RAG baselines across a diverse set of\n",
      "tasks. RAG-Instruct is publicly available at\n",
      "https://github.com/FreedomIntelligence/RAG-Instruct.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "RAG-Instruct: Boosting LLMs with Diverse Retrieval-Augmented\n",
      "Instructions\n",
      "Wanlong Liu2†, Junying Chen1†, Ke Ji1, Li Zhou1, Wenyu Chen2, Benyou Wang1*\n",
      "1 The Chinese University of Hong Kong, Shenzhen,\n",
      "2 University of Electronic Science and Technology of China\n",
      "wangbenyou@cuhk.edu.cn\n",
      "Abstract\n",
      "Retrieval-Augmented Generation (RAG) has\n",
      "emerged as a key paradigm for enhancing large\n",
      "language models (LLMs) by incorporating\n",
      "external knowledge. However, current RAG\n",
      "methods face two limitations: (1) they only\n",
      "cover limited RAG scenarios. (2) They suffer\n",
      "from limited task diversity due to the lack\n",
      "of a general RAG dataset. To address these\n",
      "limitations, we propose RAG-Instruct, a\n",
      "general method for synthesizing diverse and\n",
      "high-quality RAG instruction data based on\n",
      "any source corpus. Our approach leverages\n",
      "(1) five RAG paradigms, which encompass\n",
      "diverse query-document relationships, and\n",
      "(2) instruction simulation, which enhances\n",
      "instruction diversity and quality by utilizing\n",
      "the strengths of existing instruction datasets.\n",
      "Using this method, we construct a 40K\n",
      "instruction dataset from Wikipedia, compre-\n",
      "hensively covering diverse RAG scenarios\n",
      "and tasks.\n",
      "Experiments demonstrate that\n",
      "RAG-Instruct effectively enhances LLMs’\n",
      "RAG capabilities, achieving strong zero-shot\n",
      "performance and significantly outperforming\n",
      "various RAG baselines across a diverse set of\n",
      "tasks. RAG-Instruct is publicly available at\n",
      "https://github.com/FreedomIntelligence/RAG-\n",
      "Instruct.\n",
      "1\n",
      "Introduction\n",
      "Retrieval-Augmented Generation (RAG) (Guu\n",
      "et al., 2020; Asai et al., 2024b) enhances large\n",
      "language models (LLMs) by integrating exter-\n",
      "nal knowledge through document retrieval, effec-\n",
      "tively reducing hallucinations and improving per-\n",
      "formance across diverse tasks (Asai et al., 2023;\n",
      "Jin et al., 2024; Lu et al., 2022; Liu et al., 2024a).\n",
      "Since retrievers are not perfect, and consider-\n",
      "able research has shown that noisy retrieval can\n",
      "adversely impact LLM performance (Petroni et al.,\n",
      "*Corresponding author. †Equal Contribution.\n",
      "2020; Shi et al., 2023; Maekawa et al., 2024), nu-\n",
      "merous studies have focused on enhancing the ro-\n",
      "bustness of RAG in handling noisy retrieval con-\n",
      "texts (Wei et al., 2024; Chan et al., 2024). On the\n",
      "one hand, some studies involve adaptive retrieval\n",
      "based on query analysis (Asai et al., 2024a; Jeong\n",
      "et al., 2024), or query reformulation (Chan et al.,\n",
      "2024; Ma et al., 2023) to enhance the robustness\n",
      "of LLM-based RAG systems. On the other hand,\n",
      "(Zhang et al., 2024; Liu et al., 2024b; Yoran et al.,\n",
      "2024) enhance the robustness of models’ naive\n",
      "RAG capabilities by training them to adapt to irrel-\n",
      "evant and noisy documents.\n",
      "However, existing RAG methods have two limi-\n",
      "tations: (1) Limited RAG scenarios. Real-world\n",
      "RAG scenarios are complex: Given the query, the\n",
      "retrieved information may directly contain the an-\n",
      "swer, offer partial help, or be helpless. Some an-\n",
      "swers can be obtained from a single document,\n",
      "while others require multi-hop reasoning across\n",
      "multiple documents. Our preliminary study demon-\n",
      "strates existing RAG methods cannot adequately\n",
      "handle all such scenarios (Chan et al., 2024; Asai\n",
      "et al., 2024a; Liu et al., 2024b).\n",
      "(2) Limited\n",
      "task diversity. Due to the lack of a general RAG\n",
      "dataset, most current RAG methods (Wei et al.,\n",
      "2024; Zhang et al., 2024) are fine-tuned on task-\n",
      "specific datasets (e.g., NQ (Kwiatkowski et al.,\n",
      "2019), TrivialQA (Joshi et al., 2017)), which suffer\n",
      "from limited question diversity and data volume.\n",
      "To address these limitations, we propose RAG-\n",
      "Instruct, a general method for synthesizing diverse\n",
      "and high-quality RAG instruction data based on any\n",
      "source corpus. Using this method, we construct a\n",
      "40K synthetic instruction dataset from Wikipedia\n",
      "tailored for RAG. Our method emphasizes the di-\n",
      "versity in two aspects:\n",
      "1. Defining diverse RAG paradigms: we define\n",
      "five RAG query paradigms that encompass\n",
      "various query-document relationships to adapt\n",
      "arXiv:2501.00353v1  [cs.CL]  31 Dec 2024\n",
      "to different RAG scenarios, considering both\n",
      "doc\n",
      "</Content>\n",
      "</Document>\n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2505.13006v1\" date=\"2025-05-19\" authors=\"Yuyang Li, Philip J. M. Kerbusch, Raimon H. R. Pruim, Tobias Käfer\"/>\n",
      "<Title>\n",
      "Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Airports from the top 20 in terms of annual passengers are highly dynamic\n",
      "environments with thousands of flights daily, and they aim to increase the\n",
      "degree of automation. To contribute to this, we implemented a Conversational AI\n",
      "system that enables staff in an airport to communicate with flight information\n",
      "systems. This system not only answers standard airport queries but also\n",
      "resolves airport terminology, jargon, abbreviations, and dynamic questions\n",
      "involving reasoning. In this paper, we built three different\n",
      "Retrieval-Augmented Generation (RAG) methods, including traditional RAG, SQL\n",
      "RAG, and Knowledge Graph-based RAG (Graph RAG). Experiments showed that\n",
      "traditional RAG achieved 84.84% accuracy using BM25 + GPT-4 but occasionally\n",
      "produced hallucinations, which is risky to airport safety. In contrast, SQL RAG\n",
      "and Graph RAG achieved 80.85% and 91.49% accuracy respectively, with\n",
      "significantly fewer hallucinations. Moreover, Graph RAG was especially\n",
      "effective for questions that involved reasoning. Based on our observations, we\n",
      "thus recommend SQL RAG and Graph RAG are better for airport environments, due\n",
      "to fewer hallucinations and the ability to handle dynamic questions.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "arXiv:2505.13006v1  [cs.CL]  19 May 2025\n",
      "Evaluating the Performance of RAG Methods for Conversational AI in the\n",
      "Airport Domain\n",
      "Yuyang Li1, Philip J.M. Kerbusch2, Raimon H.R. Pruim2, Tobias Käfer1\n",
      "1Karlsruhe Institute of Technology, 2Royal Schiphol Group\n",
      "2Royal Schiphol Group, 1Karlsruhe Institute of Technology\n",
      "yuyang.li@kit.edu,\n",
      "tobias.kaefer@kit.edu\n",
      "Abstract\n",
      "Airports from the top 20 in terms of annual\n",
      "passengers are highly dynamic environments\n",
      "with thousands of flights daily, and they aim\n",
      "to increase the degree of automation. To con-\n",
      "tribute to this, we implemented a Conversa-\n",
      "tional AI system that enables staff in an air-\n",
      "port to communicate with flight information\n",
      "systems. This system not only answers stan-\n",
      "dard airport queries but also resolves airport ter-\n",
      "minology, jargon, abbreviations, and dynamic\n",
      "questions involving reasoning. In this paper, we\n",
      "built three different Retrieval-Augmented Gen-\n",
      "eration (RAG) methods, including traditional\n",
      "RAG, SQL RAG, and Knowledge Graph-based\n",
      "RAG (Graph RAG). Experiments showed that\n",
      "traditional RAG achieved 84.84% accuracy\n",
      "using BM25 + GPT-4 but occasionally pro-\n",
      "duced hallucinations, which is risky to airport\n",
      "safety. In contrast, SQL RAG and Graph RAG\n",
      "achieved 80.85% and 91.49% accuracy respec-\n",
      "tively, with significantly fewer hallucinations.\n",
      "Moreover, Graph RAG was especially effective\n",
      "for questions that involved reasoning. Based\n",
      "on our observations, we thus recommend SQL\n",
      "RAG and Graph RAG are better for airport en-\n",
      "vironments, due to fewer hallucinations and the\n",
      "ability to handle dynamic questions.\n",
      "1\n",
      "Introduction\n",
      "Amsterdam Airport Schiphol, one of the top 20\n",
      "airports in the world, ranked by annual passenger\n",
      "numbers, handles thousands of flights each day.\n",
      "These airports rely on staff like gate planners and\n",
      "apron controllers to access and update data across\n",
      "systems. For these employees, traditional database\n",
      "queries can be complex and time-consuming for\n",
      "some employees who are not query experts when\n",
      "they need flight information. A conversational AI\n",
      "system with a natural language query (NLQ) inter-\n",
      "face allows all employees to interact with systems\n",
      "naturally, asking questions like, “Which fights are\n",
      "at ramp D07?” and receiving instant answers. This\n",
      "improves productivity, and streamlines workflows,\n",
      "especially in high-pressure areas like at the gate,\n",
      "where less educated workers require access to up-\n",
      "to-date information. By replacing strict query for-\n",
      "mats with intuitive, real-time responses, conversa-\n",
      "tional AI enhances decision-making and efficiency,\n",
      "making it a suitable solution for dynamic environ-\n",
      "ments such as airports.\n",
      "Building such a system is challenging because\n",
      "flight data is stored by experts in tables using avi-\n",
      "ation abbreviations. We need our system to un-\n",
      "derstand these datasets to answer questions from\n",
      "the airport domain. Additionally, ensuring avia-\n",
      "tion safety is a major concern; the system must\n",
      "be safe and enable employees to perform accurate\n",
      "operations. We address those challenges using two\n",
      "research questions.\n",
      "The first question is how to handle flight data so\n",
      "that our system can answer different questions. We\n",
      "divided the questions into three types:\n",
      "• Straightforward questions: Questions that\n",
      "can be directly answered from the flight data.\n",
      "• Questions involving specialized airport jar-\n",
      "gon, abbreviations, and incomplete queries:\n",
      "Operators often use shorthand or omit con-\n",
      "text. Flight “KL0123” might be referred to as\n",
      "“0123” or “123,” while gate “C05” might be\n",
      "shortened to “C5.” Abbreviations like “KLM”\n",
      "for “KLM Royal Dutch Airlines” or “Delta”\n",
      "for “Delta Air Lines” are also common. Op-\n",
      "erators frequently ask short, incomplete ques-\n",
      "tions, e. g., “Which flights are at D04?” or\n",
      "“What is the gate for that Delta airline?” With-\n",
      "out resolving missing details such, these ques-\n",
      "tions cannot be answered.\n",
      "• Dynamic questions: Questions that involve\n",
      "additional calculations and reasoning, espe-\n",
      "cially related to time.\n",
      "Examples include\n",
      "“What is the connecting flight’s onramp time\n",
      "for D\n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"web\" url=\"https://www.moontechnolabs.com/blog/rag-use-cases/\" title=\"Top 14 RAG Use Cases You Need to Know in 2025\">Retrieval-augmented generation (RAG) enhances AI capabilities by combining large language models with real-time data retrieval. * **Retrieval:** RAG uses AI to encode the questions into vectors and searches the knowledge base, retrieving the top-most relevant text chunks. In supply chains, RAG helps optimize the logistics planning process by providing AI prompt engineering services for routes based on real-time traffic data. When a customer asks a question, RAG uses LLM to understand it, identifies relevant documents from the knowledge base, and generates an accurate and tailored response. Hence, businesses should explore RAG AI models, which aim to address this gap by integrating live information retrieval for real-time and context-aware responses.</Document>\n",
      "<Document source=\"web\" url=\"https://www.stack-ai.com/blog/benefits-of-rag\" title=\"7 Key Benefits of RAG in 2025 - Stack AI\">This methodology prioritizes the collection of authenticated, current information from reliable sources before initiating any content generation process, effectively reducing instances where systems might create fictitious details or generate irrelevant material. Within specialized professional environments including healthcare systems, legal practice, and customer service operations this enhanced accuracy fosters user confidence, mitigates potential financial losses from errors, and supports informed decision-making processes grounded in dependable, research-backed data. **Practical application:** Online retail platforms leverage RAG technology to **refresh product information** with current specifications, features, and availability data without the expense and complexity of comprehensive model reconstruction. RAG technology provides development teams with sophisticated **control mechanisms for context retrieval** and utilization processes, enabling the creation of highly customized responses that address specific user requirements or strategic application objectives.</Document>\n",
      "<Document source=\"web\" url=\"https://www.rapidinnovation.io/post/retrieval-augmented-generation-using-your-data-with-llms?ref=chitika.com\" title=\"Retrieval-Augmented Generation (RAG) for LLMs in 2025 Guide\">Retrieval-Augmented Generation (RAG) is an innovative approach that combines the strengths of large language models (LLMs) with external data retrieval systems. By integrating retrieval mechanisms, retrieval-augmented generation can pull in real-time data or specific information that may not be part of the model's training set. At Rapid Innovation, we harness the power of retrieval-augmented generation to help our clients achieve greater ROI by implementing tailored AI solutions that enhance operational efficiency and decision-making. At Rapid Innovation, we harness the potential of RAG architecture to develop tailored solutions that enhance customer engagement and streamline information retrieval processes, ultimately driving greater ROI for our clients. * Recent advancements have led to the development of hybrid models like RAG architecture, which combine retrieval and generation, enhancing the performance of LLMs in real-world applications.</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_answer\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_question\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_answer\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"web\" url=\"https://brunch.co.kr/@@aPda/338\" title=\"12화 복잡한 RAG 분해하기-Modular RAG란? - 브런치\">모듈러 RAG는 복잡한 RAG 시스템을 마치 레고 블록처럼 여러 개의 독립적인 모듈로 나누어, 필요에 따라 각 모듈을 교체하거나 조합할 수 있게 만들어 줍니다. **모듈러 RAG는 각 모듈을 독립적으로 설계하고 이를 필요에 따라 교체하거나 결합할 수 있도록 합니다.** 예를 들어, 새로운 임베딩 모델이 등장하거나 기존의 벡터 DB가 성능을 더 높일 수 있다고 판단되면, 해당 모듈만 교체하는 방식으로 시스템을 최적화할 수 있습니다. **모듈러 RAG는 또한 동적이고 적응 가능한 시스템을 가능하게 만듭니다.** 예를 들어, 특정 작업이나 데이터 소스에 맞는 모듈을 선택하고, 이를 조합함으로써 효율적인 RAG 시스템을 구성할 수 있습니다. **또한, 모듈러 RAG는 시스템의 복잡도를 낮추고, 성능을 더욱 향상할 수 있는 가능성을 제공합니다.** 예를 들어, 특정 데이터 소스에 더 적합한 벡터 DB를 찾거나, 최신의 임베딩 모델을 도입하는 등의 작업을 통해 성능을 지속적으로 개선할 수 있습니다.</Document>\n",
      "<Document source=\"web\" url=\"https://g3lu.tistory.com/42\" title=\"RAG의 패러다임(Naive RAG, Advanced RAG, Modular RAG)\">## RAG의 패러다임(Naive RAG, Advanced RAG, Modular RAG) 본문 Retrieval-Augmented Geneartion(RAG)는 외부 지식 소스로부터 추가적인 정보를 통합하여 대형 언어 모델(LLM)을 개선하는 과정이다. 이는 중요한 정보를 놓칠 수 있게 된다. * **잘못된 정보 제공** : 유용한 정보를 제공하지 않고 검색된 내용을 단순히 반복하는 결과를 초래할 수 있으며, 일관성 없는 답변을 뱉는 경우가 발생한다. Advanced RAG는 Naive RAG 방식에서 직면하고 있는 문제를 해결하기 위해 고안되었다. 위의 세 가지 고찰을 보완하기 위해 **Pre-Retreival 및 Post-Retrieval**를 기존 RAG 아키텍처에 추가한 것이 Advanced RAG이다. 하지만 검색된 청크들이 간혹 중복이 되거나 의미 없는 정보를 담는 경우 발생하게 되는데, 이는 LLM이 주어진 컨텍스트를 처리하는 방식에 영향을 미칠 수 있다. * **Prompt Compression** : 검색된 정보에 Noisy가 많을 수 있으므로, LLM에 태우기전에 관련 없는 정보를 압축하고 길이를 줄이는 것도 중요하다.</Document>\n",
      "<Document source=\"web\" url=\"https://brunch.co.kr/@vsongyev/28\" title=\"RAG 완벽 가이드: 세 가지 패러다임으로 보는 RAG - 브런치\">RAG의 세 가지 기술 패러다임에 대해 소개하고 어떤 과정으로 진행되는지, 각 패러다임에 대한 한계점과 여기서 얻을 수 있는 UX 인사이트까지 모두 알려 Drill 게요~! 이를 통해, 인공지능 모델의 추가 학습 없이도 외부 지식을 효과적으로 활용하여 보다 정확한 정보를 제공할 수 있으며, 환각 문제를 줄일 수 있습니다. 기본 RAG부터 모듈형 RAG까지 어떻게 구성되어 있는지 위의 이미지를 보시면 한눈에 확인할 수 있습니다. 아래의 이미지를 보시게 되면 기본 RAG에서 검색 전 과정과 검색 후 과정이 추가된 것을 보실 수 있습니다. 고급 RAG는 기존 데이터의 색인화와 검색 품질 개선에 중점을 두지만, 여전히 처리할 수 있는 데이터의 양과 종류에 제한이 있을 수 있습니다. 앞에서 다뤘던 기본 RAG는 검색(retrieval)과 생성(generation)의 두 가지 모듈로 구성할 수 있습니다.</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_arxiv\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2407.21059v1\" date=\"2024-07-26\" authors=\"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\"/>\n",
      "<Title>\n",
      "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\n",
      "of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\n",
      "increasing demands of application scenarios have driven the evolution of RAG,\n",
      "leading to the integration of advanced retrievers, LLMs and other complementary\n",
      "technologies, which in turn has amplified the intricacy of RAG systems.\n",
      "However, the rapid advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process of\n",
      "\"retrieve-then-generate\". In this context, this paper examines the limitations\n",
      "of the existing RAG paradigm and introduces the modular RAG framework. By\n",
      "decomposing complex RAG systems into independent modules and specialized\n",
      "operators, it facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a more advanced\n",
      "design that integrates routing, scheduling, and fusion mechanisms. Drawing on\n",
      "extensive research, this paper further identifies prevalent RAG\n",
      "patterns-linear, conditional, branching, and looping-and offers a comprehensive\n",
      "analysis of their respective implementation nuances. Modular RAG presents\n",
      "innovative opportunities for the conceptualization and deployment of RAG\n",
      "systems. Finally, the paper explores the potential emergence of new operators\n",
      "and paradigms, establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment of RAG\n",
      "technologies.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "1\n",
      "Modular RAG: Transforming RAG Systems into\n",
      "LEGO-like Reconfigurable Frameworks\n",
      "Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\n",
      "Abstract—Retrieval-augmented\n",
      "Generation\n",
      "(RAG)\n",
      "has\n",
      "markedly enhanced the capabilities of Large Language Models\n",
      "(LLMs) in tackling knowledge-intensive tasks. The increasing\n",
      "demands of application scenarios have driven the evolution\n",
      "of RAG, leading to the integration of advanced retrievers,\n",
      "LLMs and other complementary technologies, which in turn\n",
      "has amplified the intricacy of RAG systems. However, the rapid\n",
      "advancements are outpacing the foundational RAG paradigm,\n",
      "with many methods struggling to be unified under the process\n",
      "of “retrieve-then-generate”. In this context, this paper examines\n",
      "the limitations of the existing RAG paradigm and introduces\n",
      "the modular RAG framework. By decomposing complex RAG\n",
      "systems into independent modules and specialized operators, it\n",
      "facilitates a highly reconfigurable framework. Modular RAG\n",
      "transcends the traditional linear architecture, embracing a\n",
      "more advanced design that integrates routing, scheduling, and\n",
      "fusion mechanisms. Drawing on extensive research, this paper\n",
      "further identifies prevalent RAG patterns—linear, conditional,\n",
      "branching, and looping—and offers a comprehensive analysis\n",
      "of their respective implementation nuances. Modular RAG\n",
      "presents\n",
      "innovative\n",
      "opportunities\n",
      "for\n",
      "the\n",
      "conceptualization\n",
      "and deployment of RAG systems. Finally, the paper explores\n",
      "the potential emergence of new operators and paradigms,\n",
      "establishing a solid theoretical foundation and a practical\n",
      "roadmap for the continued evolution and practical deployment\n",
      "of RAG technologies.\n",
      "Index Terms—Retrieval-augmented generation, large language\n",
      "model, modular system, information retrieval\n",
      "I. INTRODUCTION\n",
      "L\n",
      "ARGE Language Models (LLMs) have demonstrated\n",
      "remarkable capabilities, yet they still face numerous\n",
      "challenges, such as hallucination and the lag in information up-\n",
      "dates [1]. Retrieval-augmented Generation (RAG), by access-\n",
      "ing external knowledge bases, provides LLMs with important\n",
      "contextual information, significantly enhancing their perfor-\n",
      "mance on knowledge-intensive tasks [2]. Currently, RAG, as\n",
      "an enhancement method, has been widely applied in various\n",
      "practical application scenarios, including knowledge question\n",
      "answering, recommendation systems, customer service, and\n",
      "personal assistants. [3]–[6]\n",
      "During the nascent stages of RAG , its core framework is\n",
      "constituted by indexing, retrieval, and generation, a paradigm\n",
      "referred to as Naive RAG [7]. However, as the complexity\n",
      "of tasks and the demands of applications have escalated, the\n",
      "Yunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\n",
      "Systems, Tongji University, Shanghai, 201210, China.\n",
      "Yun Xiong is with Shanghai Key Laboratory of Data Science, School of\n",
      "Computer Science, Fudan University, Shanghai, 200438, China.\n",
      "Meng Wang and Haofen Wang are with College of Design and Innovation,\n",
      "Tongji University, Shanghai, 20092, China. (Corresponding author: Haofen\n",
      "Wang. E-mail: carter.whfcarter@gmail.com)\n",
      "limitations of Naive RAG have become increasingly apparent.\n",
      "As depicted in Figure 1, it predominantly hinges on the\n",
      "straightforward similarity of chunks, result in poor perfor-\n",
      "mance when confronted with complex queries and chunks with\n",
      "substantial variability. The primary challenges of Naive RAG\n",
      "include: 1) Shallow Understanding of Queries. The semantic\n",
      "similarity between a query and document chunk is not always\n",
      "highly consistent. Relying solely on similarity calculations\n",
      "for retrieval lacks an in-depth exploration of the relationship\n",
      "between the query and the document [8]. 2) Retrieval Re-\n",
      "dundancy and Noise. Feeding all retrieved chunks directly\n",
      "into LLMs is not always beneficial. Research indicates that\n",
      "an excess of redundant and noisy information may interfere\n",
      "with the LLM’s identification of key information, thereby\n",
      "increasing the risk of generating erroneous and hallucinated\n",
      "responses. [9]\n",
      "To overcome the aforementioned limitations, \n",
      "</Content>\n",
      "</Document>\n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2508.13828v1\" date=\"2025-08-19\" authors=\"Yifei Chen, Guanting Dong, Yutao Zhu, Zhicheng Dou\"/>\n",
      "<Title>\n",
      "Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG System Collaboration\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-Augmented Generation (RAG) technology has been widely applied in\n",
      "recent years. However, despite the emergence of various RAG frameworks, a\n",
      "single RAG framework still cannot adapt well to a broad range of downstream\n",
      "tasks. Therefore, how to leverage the advantages of multiple RAG systems has\n",
      "become an area worth exploring. To address this issue, we have conducted a\n",
      "comprehensive and systematic investigation into ensemble methods based on RAG\n",
      "systems. Specifically, we have analyzed the RAG ensemble framework from both\n",
      "theoretical and mechanistic analysis perspectives. From the theoretical\n",
      "analysis, we provide the first explanation of the RAG ensemble framework from\n",
      "the perspective of information entropy. In terms of mechanism analysis, we have\n",
      "explored the RAG ensemble framework from both the pipeline and module levels.\n",
      "We carefully select four different pipelines (Branching, Iterative, Loop, and\n",
      "Agentic) and three different modules (Generator, Retriever, and Reranker) to\n",
      "solve seven different research questions. The experiments show that aggregating\n",
      "multiple RAG systems is both generalizable and robust, whether at the pipeline\n",
      "level or the module level. Our work lays the foundation for similar research on\n",
      "the multi-RAG system ensemble.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "Revisiting RAG Ensemble: A Theoretical and Mechanistic\n",
      "Analysis of Multi-RAG System Collaboration\n",
      "Yifei Chen\n",
      "zhangboguodong@ruc.edu.cn\n",
      "Gaoling School of Artificial Intelligence, Renmin\n",
      "University of China\n",
      "Haidian Qu, Beijing Shi, China\n",
      "Guanting Dong\n",
      "Gaoling School of Artificial Intelligence, Renmin\n",
      "University of China\n",
      "Haidian Qu, Beijing Shi, China\n",
      "Yutao Zhu\n",
      "Gaoling School of Artificial Intelligence, Renmin\n",
      "University of China\n",
      "Haidian Qu, Beijing Shi, China\n",
      "Zhicheng Dou\n",
      "Gaoling School of Artificial Intelligence, Renmin\n",
      "University of China\n",
      "Haidian Qu, Beijing Shi, China\n",
      "Abstract\n",
      "Retrieval-Augmented Generation (RAG) technology has been widely\n",
      "applied in recent years. However, despite the emergence of various\n",
      "RAG frameworks, a single RAG framework still cannot adapt well\n",
      "to a broad range of downstream tasks. Therefore, how to leverage\n",
      "the advantages of multiple RAG systems has become an area worth\n",
      "exploring. To address this issue, we have conducted a comprehen-\n",
      "sive and systematic investigation into ensemble methods based on\n",
      "RAG systems. Specifically, we have analyzed the RAG ensemble\n",
      "framework from both theoretical and mechanistic analysis perspec-\n",
      "tives. From the theoretical analysis, we provide the first explanation\n",
      "of the RAG ensemble framework from the perspective of informa-\n",
      "tion entropy. In terms of mechanism analysis, we have explored\n",
      "the RAG ensemble framework from both the pipeline and module\n",
      "levels. We carefully select four different pipelines (Branching, Iter-\n",
      "ative, Loop, and Agentic) and three different modules (Generator,\n",
      "Retriever, and Reranker) to solve seven different research questions.\n",
      "The experiments show that aggregating multiple RAG systems is\n",
      "both generalizable and robust, whether at the pipeline level or the\n",
      "module level. Our work lays the foundation for similar research on\n",
      "the multi-RAG system ensemble.\n",
      "CCS Concepts\n",
      "• Information systems →Information integration.\n",
      "Keywords\n",
      "Retrieval-Augmented Generation, Pipeline Ensemble, Module En-\n",
      "semble, Model Preference\n",
      "ACM Reference Format:\n",
      "Yifei Chen, Guanting Dong, Yutao Zhu, and Zhicheng Dou. 2025. Revisiting\n",
      "RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for components of this work owned by others than the\n",
      "author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\n",
      "republish, to post on servers or to redistribute to lists, requires prior specific permission\n",
      "and/or a fee. Request permissions from permissions@acm.org.\n",
      "CIKM’25, Seoul, Korea\n",
      "© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n",
      "ACM ISBN 978-1-4503-XXXX-X/2018/06\n",
      "https://doi.org/XXXXXXX.XXXXXXX\n",
      "System Collaboration. In Proceedings of CIKM’25. ACM, New York, NY, USA,\n",
      "13 pages. https://doi.org/XXXXXXX.XXXXXXX\n",
      "1\n",
      "Introduction\n",
      "The emergence of Large Language Models (LLMs) has profoundly\n",
      "revolutionized many real-world tasks that rely on natural lan-\n",
      "guage [4, 45, 70]. However, when dealing with knowledge-intensive\n",
      "tasks, LLMs relying solely on their parametric knowledge often suf-\n",
      "fer from factual inconsistencies or hallucinations. To address these\n",
      "limitations, Retrieval-Augmented Generation (RAG) methods have\n",
      "been proposed, augmenting LLMs with dynamically retrieved exter-\n",
      "nal knowledge. This integration enhances response accuracy and\n",
      "reliability by grounding outputs in verifiable information sources.\n",
      "As research in this field advances, more and more RAG methods\n",
      "have been proposed. Component Module RAG inserts various mod-\n",
      "ules into the standard pipeline to better complete the retrieval task.\n",
      "For instance, the LongLLMLingua and RECOMP methods refine\n",
      "the retrieved knowledge with a refiner, and the SKR and Adaptive\n",
      "RAG methods distinguish the diffi\n",
      "</Content>\n",
      "</Document>\n",
      "<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2407.11005v2\" date=\"2025-01-16\" authors=\"Robert Friel, Masha Belyi, Atindriyo Sanyal\"/>\n",
      "<Title>\n",
      "RAGBench: Explainable Benchmark for Retrieval-Augmented Generation Systems\n",
      "</Title>\n",
      "\n",
      "<Summary>\n",
      "Retrieval-Augmented Generation (RAG) has become a standard architectural\n",
      "pattern for incorporating domain-specific knowledge into user-facing chat\n",
      "applications powered by Large Language Models (LLMs). RAG systems are\n",
      "characterized by (1) a document retriever that queries a domain-specific corpus\n",
      "for context information relevant to an input query, and (2) an LLM that\n",
      "generates a response based on the provided query and context. However,\n",
      "comprehensive evaluation of RAG systems remains a challenge due to the lack of\n",
      "unified evaluation criteria and annotated datasets. In response, we introduce\n",
      "RAGBench: the first comprehensive, large-scale RAG benchmark dataset of 100k\n",
      "examples. It covers five unique industry-specific domains and various RAG task\n",
      "types. RAGBench examples are sourced from industry corpora such as user\n",
      "manuals, making it particularly relevant for industry applications. Further, we\n",
      "formalize the TRACe evaluation framework: a set of explainable and actionable\n",
      "RAG evaluation metrics applicable across all RAG domains. We release the\n",
      "labeled dataset at https://huggingface.co/datasets/rungalileo/ragbench.\n",
      "RAGBench explainable labels facilitate holistic evaluation of RAG systems,\n",
      "enabling actionable feedback for continuous improvement of production\n",
      "applications. Thorough extensive benchmarking, we find that LLM-based RAG\n",
      "evaluation methods struggle to compete with a finetuned RoBERTa model on the\n",
      "RAG evaluation task. We identify areas where existing approaches fall short and\n",
      "propose the adoption of RAGBench with TRACe towards advancing the state of RAG\n",
      "evaluation systems.\n",
      "</Summary>\n",
      "\n",
      "<Content>\n",
      "RAGBench: Explainable Benchmark for\n",
      "Retrieval-Augmented Generation Systems\n",
      "Robert Friel∗\n",
      "Galileo Technologies Inc.\n",
      "rob@rungalileo.io\n",
      "Masha Belyi∗\n",
      "Galileo Technologies Inc.\n",
      "masha@rungalileo.io\n",
      "Atindriyo Sanyal\n",
      "Galileo Technologies Inc.\n",
      "atin@rungalileo.io\n",
      "Abstract\n",
      "Retrieval-Augmented Generation (RAG) has become a standard architectural pat-\n",
      "tern for incorporating domain-specific knowledge into user-facing chat applica-\n",
      "tions powered by Large Language Models (LLMs). RAG systems are charac-\n",
      "terized by (1) a document retriever that queries a domain-specific corpus for\n",
      "context information relevant to an input query, and (2) an LLM that generates\n",
      "a response based on the provided query and context.\n",
      "However, comprehen-\n",
      "sive evaluation of RAG systems remains a challenge due to the lack of unified\n",
      "evaluation criteria and annotated datasets. In response, we introduce RAGBench:\n",
      "the first comprehensive, large-scale RAG benchmark dataset of 100k examples.\n",
      "It covers five unique industry-specific domains and various RAG task types.\n",
      "RAGBench examples are sourced from industry corpora such as user manuals,\n",
      "making it particularly relevant for industry applications. Further, we formalize the\n",
      "TRACe evaluation framework: a set of explainable and actionable RAG evalua-\n",
      "tion metrics applicable across all RAG domains. We release the labeled dataset\n",
      "at https://huggingface.co/datasets/rungalileo/ragbench. RAGBench\n",
      "explainable labels facilitate holistic evaluation of RAG systems, enabling action-\n",
      "able feedback for continuous improvement of production applications. Thorough\n",
      "extensive benchmarking, we find that LLM-based RAG evaluation methods strug-\n",
      "gle to compete with a finetuned RoBERTa model on the RAG evaluation task. We\n",
      "identify areas where existing approaches fall short and propose the adoption of\n",
      "RAGBench with TRACe towards advancing the state of RAG evaluation systems.\n",
      "1\n",
      "Introduction\n",
      "Despite remarkable reasoning and conversational abilities, out-of-the-box pre-trained Large Language\n",
      "Models (LLMs) struggle to reason about out-of-domain, knowledge-intensive queries [20, 13]. In\n",
      "response, Retriever-Augmented Generation (RAG) systems [20, 19] are becoming increasingly\n",
      "popular in user-facing dialogue applications [34]. Generally, RAG systems comprise a retriever\n",
      "component that queries relevant documents from an in-domain corpus and a downstream LLM\n",
      "generator model that incorporates the retrieved documents along with the original user query to output\n",
      "an informed response. The additional context helps ground the LLM in factual information and has\n",
      "been shown to boost performance on knowledge-intensive tasks [20].\n",
      "Still, when used in production settings, RAG systems are prone to hallucinations as the generator\n",
      "model struggles to retrieve relevant information from the context [1, 30, 7]. In the absence of a\n",
      "one-fits-all approach, application-specific RAG systems must be fine-tuned for optimal performance\n",
      "on domain-specific tasks. However, the choice of retriever and generator models for each application\n",
      "is complex and has serious implications on overall system quality and costs. With numerous\n",
      "*Equal Contributions\n",
      "Preprint. Under review.\n",
      "arXiv:2407.11005v2  [cs.CL]  16 Jan 2025\n",
      "commercial and open-source generative LLMs readily available1 and many variable parameters in the\n",
      "RAG system design (Figure 1), tuning an optimal system for a particular RAG application involves\n",
      "iterative evaluation of multiple configurations. This motivates the need for automated RAG evaluation\n",
      "solutions.\n",
      "In response, automated RAG evaluation systems like RAGAS [9] and TruLens [36] have emerged.\n",
      "These systems adopt a zero-shot LLM prompt-based approach to predict a set of curated RAG\n",
      "evaluation metrics. However, the lack of unified RAG benchmarks makes it difficult to compare\n",
      "approaches against each other. Each new study designs a new dataset, often employing LLMs as\n",
      "generators and labelers [9, 32, 4], which renders them irreproducible. A few benchmarks like RGB\n",
      "[4], AttributionBench \n",
      "</Content>\n",
      "</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_answer\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36msearch_web\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<Document source=\"web\" url=\"https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/\" title=\"How does Modular RAG improve upon Naive RAG? - ADaSci\">Naive RAG, the initial implementation of Retrieval-Augmented Generation, operates on a straightforward principle: retrieve relevant documents from an external knowledge base and use these documents to inform the generative process. The retrieval process in Naive RAG is relatively static and lacks flexibility, often leading to inefficiencies and suboptimal integration with the generative model. By adopting a modular architecture, this approach addresses the limitations of Naive RAG, offering enhanced flexibility, scalability, and efficiency. Unlike Naive RAG, which operates as a monolithic entity, Modular RAG breaks down the retrieval and generation processes into distinct, interchangeable modules. * *Seamless Integration*: Generative models in Modular RAG are designed to seamlessly integrate with various retrieval modules, enhancing the coherence and relevance of generated responses.</Document>\n",
      "<Document source=\"web\" url=\"https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e\" title=\"LLM RAG Paradigms: Naive RAG, Advanced RAG & Modular RAG\">RAG applications must efficiently retrieve relevant documents from the data source. **Chunk Optimization** — when using external data sources / documents to build RAG pipeline, the initial step is break them down into smaller chunks to extract fine- grained features. After retrieving the context data (chunks) from a vector database, the next step is to merge the context with a query as an input into LLM. **Memory Module** — adding memory component into RAG system where LLM can refer not only to the chunks retrieved from the vector database but also to the previous queries and answers that are stored in the systems memory. ### Build intelligent RAG systems that know when to retrieve documents, search the web, or generate responses directly</Document>\n",
      "<Document source=\"web\" url=\"https://medium.com/@vipra_singh/ai-agents-agentic-rag-part-10-f1f7d6d5c8a9\" title=\"AI Agents: Agentic RAG (Part-10) - Medium\"># AI Agents: Agentic RAG (Part-10) 3. ***AI Agent Frameworks*** 6. ***Agent Architectures*** 7. ***Multi-Agent Architectures*** 8. ***Building Multi-Agent System*** ***Agentic RAG (This Post)*** Introduction** ∘ 1.1 Overview of Agentic RAG ∘ 1.2 RAG Versus Agentic RAG**·** **2. Evolution of RAG Paradigms** ∘ 2.1 Naïve RAG  ∘ 2.2 Advanced RAG ∘ 2.3 Modular RAG ∘ 2.4 Graph RAG ∘ 2.5 Agentic RAG**·** **3. Taxonomy of Agentic RAG** ∘ 4.1 Single Agent Agentic RAG: Router ∘ 4.2 Multi-Agent Agentic RAG Systems ∘ 4.3 Hierarchical Agentic RAG Systems ∘ 4.4 Agentic Corrective RAG ∘ 4.5 Adaptive Agentic RAG ∘ 4.6 Graph-Based Agentic RAG ∘ 4.6.1 Agent-G: Agentic Framework for Graph RAG ∘ 4.6.2 GeAR: Graph-Enhanced Agent for RAG ∘ 4.7 Agentic Document Workflows (ADW) in Agentic RAG**·** **5. Comparative Analysis of Agentic RAG Frameworks****·** **6.</Document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mgenerate_answer\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mwrite_section\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## 모듈형 RAG: 창업자 출신 분석가 관점에서 본 유연성과 혁신의 비즈니스 가치\n",
      "\n",
      "### 요약\n",
      "\n",
      "Retrieval-Augmented Generation(RAG)은 대형 언어 모델(LLM)에 외부 지식 검색을 결합해 복잡한 지식 집약적 과제를 해결하는 데 혁신을 가져왔습니다. 초기 RAG(단순 RAG)는 쿼리에 대해 관련 문서 청크를 단순 유사도로 검색하고 이를 바탕으로 생성하는 선형적인 ‘검색-생성’ 프로세스에 기반합니다. 하지만 이 방식은 쿼리와 문서 간 의미 분석이 얕고, 중복정보 및 노이즈가 많아 답변의 정확성과 일관성을 저해한다는 한계가 존재합니다[1][4]. \n",
      "\n",
      "이에 대응해 등장한 모듈형 RAG는 복잡한 RAG 시스템을 LEGO 블록처럼 독립 모듈과 전문화된 연산자로 분해해 자유롭게 조합하고 교체할 수 있는 ‘적응형 시스템’ 패러다임입니다[1]. 이 구조는 라우팅, 스케줄링, 융합 등 고급 설계 기법을 통합하여, 각 모듈을 별도로 최적화하고, 기술 변화나 시장 요구에 따라 신속한 재구성이 가능하도록 합니다[4]. \n",
      "\n",
      "스타트업과 같은 빠르게 변화하는 비즈니스 환경에서는 이러한 유연성과 확장성이 특히 중요합니다. 모듈별 독립성은 시스템 유지보수를 용이하게 하고, 반복적 작업, 조건부 흐름, 분기 처리 등 복잡한 업무 처리를 가능케 하여 광범위한 산업과 도메인에 맞춤형 대응이 가능합니다[1][4]. \n",
      "\n",
      "본 보고서에서는 모듈형 RAG의 기술적 차별점과, 생산 환경에서의 적용 사례 및 이점을 중심으로 스타트업의 비즈니스 모델 혁신에 미치는 의미를 심층 분석합니다.\n",
      "\n",
      "### 종합 분석\n",
      "\n",
      "#### 1. 단순 RAG vs. 모듈형 RAG: 구조와 한계\n",
      "\n",
      "기존 단순 RAG(‘Naive RAG’)는 인덱싱, 검색, 생성의 3단계로 구성된 단순 선형 구조로서, 사용자 쿼리에 대해 관련 문서를 단순 유사도 방식으로 조회한 뒤, LLM이 이를 그대로 활용해 답변을 생성합니다. 이 프로세스는 구현이 쉬운 반면 복잡한 쿼리나 다양한 문서 형식 처리에 한계가 명확합니다. 특히:\n",
      "\n",
      "- **쿼리와 문서 간 의미적 일치 부족**: 단순 유사도 기반 검색은 쿼리와 문서 청크 간 의미적 관계를 깊이 분석하지 못해, 핵심 정보를 놓칠 위험이 큽니다.\n",
      "- **중복 정보 및 노이즈**: 단순히 많이 검색된 문서 청크를 모두 LLM에 투입 시 오히려 노이즈가 증가해 출력의 질과 신뢰도를 떨어뜨릴 수 있습니다[1].\n",
      "\n",
      "이로 인해 단순 RAG는 생산 단계의 복잡한 실무 환경 요구를 충족하지 못하고, 모델의 정확성과 효율성을 저해하는 ‘병목’으로 작용할 여지가 큽니다.\n",
      "\n",
      "#### 2. 모듈형 RAG: 레고처럼 조립하는 혁신 아키텍처\n",
      "\n",
      "모듈형 RAG는 이러한 한계 극복을 위해 RAG 시스템을 여러 독립적 모듈과 전문 연산자로 쪼갭니다. 각 모듈은 특정 역할(예: 검색기, 임베딩, 라우터, 집계자 등)을 수행하며, 자유롭게 조합·교체가 가능합니다(‘LEGO-like reconfigurable framework’)[1].  \n",
      "\n",
      "이 아키텍처의 핵심 특징은 다음과 같습니다:\n",
      "\n",
      "- **비선형 고급 설계**: 전통적 선형 ‘검색-생성’ 구조를 뛰어넘어 라우팅, 스케줄링, 융합 등의 복합 메커니즘을 포함합니다. 이를 통해 다양한 비즈니스 요구에 따른 조건부 처리, 분기, 반복 작업도 구현 가능[1].\n",
      "- **유연한 모듈 교체 및 확장성**: 최신 임베딩 기술이나 벡터 DB가 등장할 경우, 해당 모듈만 교체하여 신속한 기술 적응과 성능 개선이 가능합니다. 이는 빠른 시장 변화 대응과 지속적인 시스템 혁신에 필수적입니다[4].\n",
      "- **진화하는 RAG 패턴 지원**: 선형뿐 아니라 조건부, 분기(branching), 반복(looping) 패턴을 아우르는 다양한 RAG 운영 모델을 구현하여 복잡한 업무 흐름을 충실히 처리할 수 있습니다[1].\n",
      "\n",
      "#### 3. 생산 환경에서의 비즈니스 및 운영적 이점\n",
      "\n",
      "스타트업과 혁신 기업 입장에서는 신속한 제품 출시 및 시장 적응력이 핵심 경쟁력입니다. 모듈형 RAG는 이를 가능케 하는 여러 측면에서 이점을 제공합니다.\n",
      "\n",
      "- **빠른 적응성 및 민첩성(Agility)**: 새로 등장하는 기술, 데이터 소스, 고객 요구에 맞춰 모듈 단위로 즉각 수정·교체가 가능해 운영 리스크를 줄이고 대응 속도를 높입니다.\n",
      "- **운영 효율성 및 성능 최적화**: 중복·불필요 데이터 감소, 전문 연산자에 의한 노이즈 필터링으로 LLM 활용 효율성을 극대화하여 처리 비용과 응답시간 감소를 기대할 수 있습니다.\n",
      "- **유지보수 및 문제 해결 용이성**: 독립 모듈로 책임이 분리되어 장애 원인 추적이 용이하고, 특정 모듈만 단기간 내 교체·업그레이드 가능해 안정적 시스템 운영에 용이합니다.\n",
      "- **다양한 비즈니스 시나리오 대응**: RAG 패턴의 다양화로 복잡한 질문응답, 다중 단계 추론, 특정 도메인 맞춤 처리 등 다양한 산업(금융, 의료, 물류 등)에 폭넓게 적용할 수 있습니다.\n",
      "\n",
      "#### 4. 사례와 전망\n",
      "\n",
      "실제 사례로는 최신 임베딩이나 벡터 DB 도입으로 검색 정확도를 높이거나, 업무별로 조건부 흐름 처리를 구현해 고객 요구에 최적화된 답변 시스템으로 안정적 운영하는 성공적 도입 사례가 보고되고 있습니다[4]. \n",
      "\n",
      "더 나아가 MA-RAG와 같은 다중 에이전트 협력 체계는 각기 다른 전문 모듈들이 협력해 다중 단계 추론을 수행하며, 단일 LLM 단독 운용보다 높은 정확도와 신뢰도를 구현, 특히 의료 영역 등 전문화된 도메인에서 강력한 성과를 내고 있습니다[3].\n",
      "\n",
      "또한 평가 플랫폼 OmniBench RAG는 다양한 도메인과 모델별로 RAG 성능을 체계적이고 재현 가능하게 측정함으로써, 비즈니스 환경에 최적화된 RAG 구성을 모듈화 접근법과 함께 설계·선택하는 데 도움을 줍니다[2].\n",
      "\n",
      "#### 5. 스타트업과 기업 혁신에 주는 시사점\n",
      "\n",
      "- **시장 및 기술 변화에 발 빠르게 대응 가능**: 다양한 RAG 모듈을 교체·조합해 최적화하며, 신기술 도입 시 전체 시스템 교체가 아니라 비용 효율적 업그레이드 가능.\n",
      "- **비즈니스 모델 혁신을 지원하는 적응형 AI 시스템 구현**: 복잡한 업무 시나리오 및 고객 요구에 맞춘 맞춤형 AI 서비스 제공 가능.\n",
      "- **운영 리스크 최소화 및 안정성 보장**: 분리된 모듈로 장애 관리가 쉬워 서비스 신뢰도를 높임.\n",
      "- **지속적 혁신과 성장 촉진**: 실험적 모듈 추가 및 제거를 통한 빠른 제품 개선 및 AI 서비스 확대가 가능.\n",
      "\n",
      "이런 점에서 모듈형 RAG는 스타트업의 빠른 시장 출현과 유연한 성장 전략에 있어 필수 아키텍처로 자리매김할 전망입니다.\n",
      "\n",
      "### 출처\n",
      "\n",
      "[1] http://arxiv.org/abs/2407.21059v1  \n",
      "[2] http://arxiv.org/abs/2508.05650v1  \n",
      "[3] http://arxiv.org/abs/2505.20096v2  \n",
      "[4] https://brunch.co.kr/@@aPda/338\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mconduct_interview\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## 모듈형 RAG: 창업자 출신 분석가 관점에서 본 유연성과 혁신의 비즈니스 가치\n",
      "\n",
      "### 요약\n",
      "\n",
      "Retrieval-Augmented Generation(RAG)은 대형 언어 모델(LLM)에 외부 지식 검색을 결합해 복잡한 지식 집약적 과제를 해결하는 데 혁신을 가져왔습니다. 초기 RAG(단순 RAG)는 쿼리에 대해 관련 문서 청크를 단순 유사도로 검색하고 이를 바탕으로 생성하는 선형적인 ‘검색-생성’ 프로세스에 기반합니다. 하지만 이 방식은 쿼리와 문서 간 의미 분석이 얕고, 중복정보 및 노이즈가 많아 답변의 정확성과 일관성을 저해한다는 한계가 존재합니다[1][4]. \n",
      "\n",
      "이에 대응해 등장한 모듈형 RAG는 복잡한 RAG 시스템을 LEGO 블록처럼 독립 모듈과 전문화된 연산자로 분해해 자유롭게 조합하고 교체할 수 있는 ‘적응형 시스템’ 패러다임입니다[1]. 이 구조는 라우팅, 스케줄링, 융합 등 고급 설계 기법을 통합하여, 각 모듈을 별도로 최적화하고, 기술 변화나 시장 요구에 따라 신속한 재구성이 가능하도록 합니다[4]. \n",
      "\n",
      "스타트업과 같은 빠르게 변화하는 비즈니스 환경에서는 이러한 유연성과 확장성이 특히 중요합니다. 모듈별 독립성은 시스템 유지보수를 용이하게 하고, 반복적 작업, 조건부 흐름, 분기 처리 등 복잡한 업무 처리를 가능케 하여 광범위한 산업과 도메인에 맞춤형 대응이 가능합니다[1][4]. \n",
      "\n",
      "본 보고서에서는 모듈형 RAG의 기술적 차별점과, 생산 환경에서의 적용 사례 및 이점을 중심으로 스타트업의 비즈니스 모델 혁신에 미치는 의미를 심층 분석합니다.\n",
      "\n",
      "### 종합 분석\n",
      "\n",
      "#### 1. 단순 RAG vs. 모듈형 RAG: 구조와 한계\n",
      "\n",
      "기존 단순 RAG(‘Naive RAG’)는 인덱싱, 검색, 생성의 3단계로 구성된 단순 선형 구조로서, 사용자 쿼리에 대해 관련 문서를 단순 유사도 방식으로 조회한 뒤, LLM이 이를 그대로 활용해 답변을 생성합니다. 이 프로세스는 구현이 쉬운 반면 복잡한 쿼리나 다양한 문서 형식 처리에 한계가 명확합니다. 특히:\n",
      "\n",
      "- **쿼리와 문서 간 의미적 일치 부족**: 단순 유사도 기반 검색은 쿼리와 문서 청크 간 의미적 관계를 깊이 분석하지 못해, 핵심 정보를 놓칠 위험이 큽니다.\n",
      "- **중복 정보 및 노이즈**: 단순히 많이 검색된 문서 청크를 모두 LLM에 투입 시 오히려 노이즈가 증가해 출력의 질과 신뢰도를 떨어뜨릴 수 있습니다[1].\n",
      "\n",
      "이로 인해 단순 RAG는 생산 단계의 복잡한 실무 환경 요구를 충족하지 못하고, 모델의 정확성과 효율성을 저해하는 ‘병목’으로 작용할 여지가 큽니다.\n",
      "\n",
      "#### 2. 모듈형 RAG: 레고처럼 조립하는 혁신 아키텍처\n",
      "\n",
      "모듈형 RAG는 이러한 한계 극복을 위해 RAG 시스템을 여러 독립적 모듈과 전문 연산자로 쪼갭니다. 각 모듈은 특정 역할(예: 검색기, 임베딩, 라우터, 집계자 등)을 수행하며, 자유롭게 조합·교체가 가능합니다(‘LEGO-like reconfigurable framework’)[1].  \n",
      "\n",
      "이 아키텍처의 핵심 특징은 다음과 같습니다:\n",
      "\n",
      "- **비선형 고급 설계**: 전통적 선형 ‘검색-생성’ 구조를 뛰어넘어 라우팅, 스케줄링, 융합 등의 복합 메커니즘을 포함합니다. 이를 통해 다양한 비즈니스 요구에 따른 조건부 처리, 분기, 반복 작업도 구현 가능[1].\n",
      "- **유연한 모듈 교체 및 확장성**: 최신 임베딩 기술이나 벡터 DB가 등장할 경우, 해당 모듈만 교체하여 신속한 기술 적응과 성능 개선이 가능합니다. 이는 빠른 시장 변화 대응과 지속적인 시스템 혁신에 필수적입니다[4].\n",
      "- **진화하는 RAG 패턴 지원**: 선형뿐 아니라 조건부, 분기(branching), 반복(looping) 패턴을 아우르는 다양한 RAG 운영 모델을 구현하여 복잡한 업무 흐름을 충실히 처리할 수 있습니다[1].\n",
      "\n",
      "#### 3. 생산 환경에서의 비즈니스 및 운영적 이점\n",
      "\n",
      "스타트업과 혁신 기업 입장에서는 신속한 제품 출시 및 시장 적응력이 핵심 경쟁력입니다. 모듈형 RAG는 이를 가능케 하는 여러 측면에서 이점을 제공합니다.\n",
      "\n",
      "- **빠른 적응성 및 민첩성(Agility)**: 새로 등장하는 기술, 데이터 소스, 고객 요구에 맞춰 모듈 단위로 즉각 수정·교체가 가능해 운영 리스크를 줄이고 대응 속도를 높입니다.\n",
      "- **운영 효율성 및 성능 최적화**: 중복·불필요 데이터 감소, 전문 연산자에 의한 노이즈 필터링으로 LLM 활용 효율성을 극대화하여 처리 비용과 응답시간 감소를 기대할 수 있습니다.\n",
      "- **유지보수 및 문제 해결 용이성**: 독립 모듈로 책임이 분리되어 장애 원인 추적이 용이하고, 특정 모듈만 단기간 내 교체·업그레이드 가능해 안정적 시스템 운영에 용이합니다.\n",
      "- **다양한 비즈니스 시나리오 대응**: RAG 패턴의 다양화로 복잡한 질문응답, 다중 단계 추론, 특정 도메인 맞춤 처리 등 다양한 산업(금융, 의료, 물류 등)에 폭넓게 적용할 수 있습니다.\n",
      "\n",
      "#### 4. 사례와 전망\n",
      "\n",
      "실제 사례로는 최신 임베딩이나 벡터 DB 도입으로 검색 정확도를 높이거나, 업무별로 조건부 흐름 처리를 구현해 고객 요구에 최적화된 답변 시스템으로 안정적 운영하는 성공적 도입 사례가 보고되고 있습니다[4]. \n",
      "\n",
      "더 나아가 MA-RAG와 같은 다중 에이전트 협력 체계는 각기 다른 전문 모듈들이 협력해 다중 단계 추론을 수행하며, 단일 LLM 단독 운용보다 높은 정확도와 신뢰도를 구현, 특히 의료 영역 등 전문화된 도메인에서 강력한 성과를 내고 있습니다[3].\n",
      "\n",
      "또한 평가 플랫폼 OmniBench RAG는 다양한 도메인과 모델별로 RAG 성능을 체계적이고 재현 가능하게 측정함으로써, 비즈니스 환경에 최적화된 RAG 구성을 모듈화 접근법과 함께 설계·선택하는 데 도움을 줍니다[2].\n",
      "\n",
      "#### 5. 스타트업과 기업 혁신에 주는 시사점\n",
      "\n",
      "- **시장 및 기술 변화에 발 빠르게 대응 가능**: 다양한 RAG 모듈을 교체·조합해 최적화하며, 신기술 도입 시 전체 시스템 교체가 아니라 비용 효율적 업그레이드 가능.\n",
      "- **비즈니스 모델 혁신을 지원하는 적응형 AI 시스템 구현**: 복잡한 업무 시나리오 및 고객 요구에 맞춘 맞춤형 AI 서비스 제공 가능.\n",
      "- **운영 리스크 최소화 및 안정성 보장**: 분리된 모듈로 장애 관리가 쉬워 서비스 신뢰도를 높임.\n",
      "- **지속적 혁신과 성장 촉진**: 실험적 모듈 추가 및 제거를 통한 빠른 제품 개선 및 AI 서비스 확대가 가능.\n",
      "\n",
      "이런 점에서 모듈형 RAG는 스타트업의 빠른 시장 출현과 유연한 성장 전략에 있어 필수 아키텍처로 자리매김할 전망입니다.\n",
      "\n",
      "### 출처\n",
      "\n",
      "[1] http://arxiv.org/abs/2407.21059v1  \n",
      "[2] http://arxiv.org/abs/2508.05650v1  \n",
      "[3] http://arxiv.org/abs/2505.20096v2  \n",
      "[4] https://brunch.co.kr/@@aPda/338\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mwrite_section\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## 혁신적 스타트업을 위한 모듈형 RAG: 기존 Naive RAG와의 차별성과 생산 단계 적용 이점\n",
      "\n",
      "### 요약  \n",
      "스타트업과 빠르게 변화하는 시장 환경에서 적응성과 확장성은 핵심 경쟁력입니다. 기존의 Naive RAG(Retrieval-Augmented Generation)는 단순히 대규모 데이터베이스에서 관련 문서를 키워드 기반으로 검색하여 이를 LLM(대형 언어 모델)에 넘겨주는 구조로, 구현이 간단하다는 장점이 있으나 검색 정확도와 맥락 이해에 한계를 보입니다. 이러한 단순 RAG 방식은 생산 현장에서 답변의 신뢰성과 품질 저하, 중복 정보 처리의 비효율성 문제로 인해 운영 효율성을 떨어뜨릴 수 있습니다.\n",
      "\n",
      "반면, 모듈형 RAG는 시스템을 쿼리 해석, 도메인별 지식 저장, 문서 순위 매김, 답변 생성 등 독립적인 기능 단위로 분리해 각 모듈을 최적화하고 필요에 따라 쉽게 교체·조합할 수 있도록 설계되었습니다. 이는 마치 레고 블록처럼 유연한 맞춤 구성이 가능하며, 새로운 임베딩 모델과 벡터 DB 도입, 데이터 소스 변경 시 전체 시스템 재구성 없이도 빠른 적응이 가능합니다[4][5]. 실제 스타트업 고객지원 챗봇 사례에서 모듈형 RAG의 사용은 사용자 의도 파악 정확도 향상과 불필요한 노이즈 감소로 고객 만족도와 운영 효율성을 크게 끌어올렸습니다.\n",
      "\n",
      "이와 더불어, 최근 연구들은 복잡하고 다양한 RAG 시스템의 협업과 앙상블 방식을 제안하며, 모듈형 RAG의 구조적 확장성 및 다중 RAG 시스템 연동 가능성도 강조합니다[8]. 모듈형 구조는 산업 맞춤형, 동적 워크플로우 구현에 적합하며, 생산에서 유지보수 비용 절감, 신뢰성 강화, 빠른 시장 대응을 가능하게 하는 혁신적 플랫폼 토대가 됩니다.\n",
      "\n",
      "본 보고서에서는 스타트업 전문가의 시각으로, 모듈형 RAG가 Naive RAG 대비 가지는 기술적 우위와 맞춤형 비즈니스 모델 혁신, 그리고 실질적인 생산 적용 효과를 심도 있게 분석하였습니다.\n",
      "\n",
      "참고 출처: [1][4][5][8]\n",
      "\n",
      "### 종합 분석  \n",
      "\n",
      "#### 1. Naive RAG의 구조와 한계  \n",
      "Naive RAG는 기본적으로 검색(Retrieval)과 생성(Generation) 두 단계로 단선적인 구조를 가집니다. 외부 지식베이스에서 단순 유사도 기반으로 문서나 텍스트 청크를 찾아내고 이를 대형 언어 모델에 바로 전달하여 답변을 생성하죠. 이 과정의 장점은 구현 난이도가 낮고, 단순 검색-생성 모델로 빠르게 적용 가능하다는 점입니다.  \n",
      "하지만, 대형 데이터베이스를 무차별적으로 검색하다보니 다음과 같은 문제가 나타납니다.  \n",
      "- **검색 정확도 저하** : 키워드 매칭이나 단순 청크 유사도는 쿼리의 심층적 의미해석을 반영하지 못해 관련성 낮은 문서가 포함될 위험이 큽니다.  \n",
      "- **중복 및 노이즈 증가** : 유사한 정보가 반복되어 LLM에 전달되고, 불필요한 정보가 모델의 판단을 방해해 ‘환각(hallucination)’ 문제를 악화시킵니다.  \n",
      "- **확장성 부족** : 새로운 임베딩 기법 도입이나 데이터 소스 변경 시 전체 시스템 재설계가 필요해, 빠른 비즈니스 변화에 대응하기 어렵습니다.\n",
      "\n",
      "이러한 한계는 특히 다중 도메인, 심층 질의에 대한 정확한 답변과 신뢰성 요구가 높은 산업 현장에서 치명적일 수 있습니다.\n",
      "\n",
      "#### 2. 모듈형 RAG의 아키텍처 혁신  \n",
      "모듈형 RAG는 Naive RAG의 직선적 구조에서 벗어나, 기능 단위별 독립 모듈로 시스템을 분해합니다. 주로 쿼리 해석, 임베딩 생성, 효율적 벡터 검색, 문서 랭킹, 답변 생성 모듈 등으로 나뉘며, 각 모듈마다 특화된 알고리즘·기술 도입과 최적화가 가능합니다[4][5][6].  \n",
      "- **유연한 모듈 교체와 조합**: 예를 들어 모델링 성능이 향상된 임베딩 모듈이 등장하면, 기존의 전체 RAG를 변경할 필요 없이 해당 임베딩 모듈만 교체할 수 있습니다.  \n",
      "- **동적 적응과 확장성 확보**: 특정 업무에 적합한 문서 재순위 모듈 또는 쿼리 이해 모듈을 도입하여 성능을 개인화할 수 있죠. 신규 데이터 소스도 기존 구조에 추가하는 형태로 빠르게 연동됩니다.  \n",
      "- **복잡도 관리 및 성능 향상** : 기능 분리와 모듈화는 시스템 복잡도를 줄이고, 병렬 처리나 분산 컴퓨팅을 통한 처리량 확대도 용이하게 합니다[2].  \n",
      "\n",
      "한 연구에서는 “레고 블록”처럼 조립식 모듈 구성이 실제 RAG 시스템의 사용자 맞춤화와 고도화에 결정적 역할을 함을 보여줬습니다[6].\n",
      "\n",
      "#### 3. 생산 환경에서의 실질적 이점  \n",
      "모듈형 RAG를 생산 단계에 적용하면 여러 가지 중요한 비즈니스적·운영적 이점이 있습니다.  \n",
      "\n",
      "- **신속한 시장 대응 및 유지보수 용이성**  \n",
      "  스타트업 환경과 같이 급변하는 시장 상황에 맞춰 빠르게 새로운 데이터 유형, 정보원 또는 기능을 추가할 수 있습니다. 예를 들어, 고객지원 챗봇에서 사용자의 복잡한 의도를 정확히 파악하는 모듈을 강화해 오답률이 크게 감소한 사례는 구체적인 성공 지표입니다[4][5]. 유지보수 시에도 변경 영역이 집중되어 전체 시스템 리스크 감소 및 비용 절감이 가능합니다.  \n",
      "\n",
      "- **운영 효율과 고객 경험 향상**  \n",
      "  적절한 문서 재평가 모듈과 쿼리 해석 모듈 덕분에 불필요한 중복 정보나 노이즈가 획기적으로 줄고, LLM의 생성 컨텍스트가 정제되면서 답변 품질이 개선됩니다. 고객 만족도는 물론, 내부 문제 해결 속도도 빨라집니다.  \n",
      "\n",
      "- **확장성 높은 플랫폼 구축**  \n",
      "  모듈별 독립 최적화가 가능해 도메인별 맞춤 확장이 자유롭고, 멀티모달(MMORE[2]과 같은) 및 대규모 분산 처리 기술 적용도 가능해 대형 조직이나 스타트업 모두에게 적합한 인프라를 제공합니다.  \n",
      "\n",
      "#### 4. 최신 연구 동향 및 미래 가능성  \n",
      "최근 RAG 시스템의 앙상블 및 협업 연구는 다중 RAG 모델을 통합해 범용성과 신뢰성을 더욱 높이려는 시도를 보여줍니다[8]. 모듈형 RAG는 이러한 다수 시스템 연동 및 조건부 흐름, 반복적 처리 등을 자연스럽게 수용할 수 있는 설계로 평가받고 있습니다. 또한, 템포럴 컨텍스트 유지(ChronoRAG[1]) 및 복합 쿼리 대응 능력도 모듈별 미세 조정으로 한층 진보가 기대됩니다.  \n",
      "\n",
      "이러한 동향은 스타트업이 한정된 자원으로도 변화무쌍한 시장의 요구에 맞춰 신속한 사업적 의사결정과 혁신적 고객 서비스를 구현하는 데 큰 기여를 할 것입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 출처  \n",
      "[1] http://arxiv.org/abs/2508.18748v2  \n",
      "[2] http://arxiv.org/abs/2509.11937v1  \n",
      "[4] https://g3lu.tistory.com/42  \n",
      "[5] https://brunch.co.kr/@@aPda/338  \n",
      "[6] http://arxiv.org/abs/2407.21059v1  \n",
      "[8] http://arxiv.org/abs/2508.13828v1\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mconduct_interview\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## 혁신적 스타트업을 위한 모듈형 RAG: 기존 Naive RAG와의 차별성과 생산 단계 적용 이점\n",
      "\n",
      "### 요약  \n",
      "스타트업과 빠르게 변화하는 시장 환경에서 적응성과 확장성은 핵심 경쟁력입니다. 기존의 Naive RAG(Retrieval-Augmented Generation)는 단순히 대규모 데이터베이스에서 관련 문서를 키워드 기반으로 검색하여 이를 LLM(대형 언어 모델)에 넘겨주는 구조로, 구현이 간단하다는 장점이 있으나 검색 정확도와 맥락 이해에 한계를 보입니다. 이러한 단순 RAG 방식은 생산 현장에서 답변의 신뢰성과 품질 저하, 중복 정보 처리의 비효율성 문제로 인해 운영 효율성을 떨어뜨릴 수 있습니다.\n",
      "\n",
      "반면, 모듈형 RAG는 시스템을 쿼리 해석, 도메인별 지식 저장, 문서 순위 매김, 답변 생성 등 독립적인 기능 단위로 분리해 각 모듈을 최적화하고 필요에 따라 쉽게 교체·조합할 수 있도록 설계되었습니다. 이는 마치 레고 블록처럼 유연한 맞춤 구성이 가능하며, 새로운 임베딩 모델과 벡터 DB 도입, 데이터 소스 변경 시 전체 시스템 재구성 없이도 빠른 적응이 가능합니다[4][5]. 실제 스타트업 고객지원 챗봇 사례에서 모듈형 RAG의 사용은 사용자 의도 파악 정확도 향상과 불필요한 노이즈 감소로 고객 만족도와 운영 효율성을 크게 끌어올렸습니다.\n",
      "\n",
      "이와 더불어, 최근 연구들은 복잡하고 다양한 RAG 시스템의 협업과 앙상블 방식을 제안하며, 모듈형 RAG의 구조적 확장성 및 다중 RAG 시스템 연동 가능성도 강조합니다[8]. 모듈형 구조는 산업 맞춤형, 동적 워크플로우 구현에 적합하며, 생산에서 유지보수 비용 절감, 신뢰성 강화, 빠른 시장 대응을 가능하게 하는 혁신적 플랫폼 토대가 됩니다.\n",
      "\n",
      "본 보고서에서는 스타트업 전문가의 시각으로, 모듈형 RAG가 Naive RAG 대비 가지는 기술적 우위와 맞춤형 비즈니스 모델 혁신, 그리고 실질적인 생산 적용 효과를 심도 있게 분석하였습니다.\n",
      "\n",
      "참고 출처: [1][4][5][8]\n",
      "\n",
      "### 종합 분석  \n",
      "\n",
      "#### 1. Naive RAG의 구조와 한계  \n",
      "Naive RAG는 기본적으로 검색(Retrieval)과 생성(Generation) 두 단계로 단선적인 구조를 가집니다. 외부 지식베이스에서 단순 유사도 기반으로 문서나 텍스트 청크를 찾아내고 이를 대형 언어 모델에 바로 전달하여 답변을 생성하죠. 이 과정의 장점은 구현 난이도가 낮고, 단순 검색-생성 모델로 빠르게 적용 가능하다는 점입니다.  \n",
      "하지만, 대형 데이터베이스를 무차별적으로 검색하다보니 다음과 같은 문제가 나타납니다.  \n",
      "- **검색 정확도 저하** : 키워드 매칭이나 단순 청크 유사도는 쿼리의 심층적 의미해석을 반영하지 못해 관련성 낮은 문서가 포함될 위험이 큽니다.  \n",
      "- **중복 및 노이즈 증가** : 유사한 정보가 반복되어 LLM에 전달되고, 불필요한 정보가 모델의 판단을 방해해 ‘환각(hallucination)’ 문제를 악화시킵니다.  \n",
      "- **확장성 부족** : 새로운 임베딩 기법 도입이나 데이터 소스 변경 시 전체 시스템 재설계가 필요해, 빠른 비즈니스 변화에 대응하기 어렵습니다.\n",
      "\n",
      "이러한 한계는 특히 다중 도메인, 심층 질의에 대한 정확한 답변과 신뢰성 요구가 높은 산업 현장에서 치명적일 수 있습니다.\n",
      "\n",
      "#### 2. 모듈형 RAG의 아키텍처 혁신  \n",
      "모듈형 RAG는 Naive RAG의 직선적 구조에서 벗어나, 기능 단위별 독립 모듈로 시스템을 분해합니다. 주로 쿼리 해석, 임베딩 생성, 효율적 벡터 검색, 문서 랭킹, 답변 생성 모듈 등으로 나뉘며, 각 모듈마다 특화된 알고리즘·기술 도입과 최적화가 가능합니다[4][5][6].  \n",
      "- **유연한 모듈 교체와 조합**: 예를 들어 모델링 성능이 향상된 임베딩 모듈이 등장하면, 기존의 전체 RAG를 변경할 필요 없이 해당 임베딩 모듈만 교체할 수 있습니다.  \n",
      "- **동적 적응과 확장성 확보**: 특정 업무에 적합한 문서 재순위 모듈 또는 쿼리 이해 모듈을 도입하여 성능을 개인화할 수 있죠. 신규 데이터 소스도 기존 구조에 추가하는 형태로 빠르게 연동됩니다.  \n",
      "- **복잡도 관리 및 성능 향상** : 기능 분리와 모듈화는 시스템 복잡도를 줄이고, 병렬 처리나 분산 컴퓨팅을 통한 처리량 확대도 용이하게 합니다[2].  \n",
      "\n",
      "한 연구에서는 “레고 블록”처럼 조립식 모듈 구성이 실제 RAG 시스템의 사용자 맞춤화와 고도화에 결정적 역할을 함을 보여줬습니다[6].\n",
      "\n",
      "#### 3. 생산 환경에서의 실질적 이점  \n",
      "모듈형 RAG를 생산 단계에 적용하면 여러 가지 중요한 비즈니스적·운영적 이점이 있습니다.  \n",
      "\n",
      "- **신속한 시장 대응 및 유지보수 용이성**  \n",
      "  스타트업 환경과 같이 급변하는 시장 상황에 맞춰 빠르게 새로운 데이터 유형, 정보원 또는 기능을 추가할 수 있습니다. 예를 들어, 고객지원 챗봇에서 사용자의 복잡한 의도를 정확히 파악하는 모듈을 강화해 오답률이 크게 감소한 사례는 구체적인 성공 지표입니다[4][5]. 유지보수 시에도 변경 영역이 집중되어 전체 시스템 리스크 감소 및 비용 절감이 가능합니다.  \n",
      "\n",
      "- **운영 효율과 고객 경험 향상**  \n",
      "  적절한 문서 재평가 모듈과 쿼리 해석 모듈 덕분에 불필요한 중복 정보나 노이즈가 획기적으로 줄고, LLM의 생성 컨텍스트가 정제되면서 답변 품질이 개선됩니다. 고객 만족도는 물론, 내부 문제 해결 속도도 빨라집니다.  \n",
      "\n",
      "- **확장성 높은 플랫폼 구축**  \n",
      "  모듈별 독립 최적화가 가능해 도메인별 맞춤 확장이 자유롭고, 멀티모달(MMORE[2]과 같은) 및 대규모 분산 처리 기술 적용도 가능해 대형 조직이나 스타트업 모두에게 적합한 인프라를 제공합니다.  \n",
      "\n",
      "#### 4. 최신 연구 동향 및 미래 가능성  \n",
      "최근 RAG 시스템의 앙상블 및 협업 연구는 다중 RAG 모델을 통합해 범용성과 신뢰성을 더욱 높이려는 시도를 보여줍니다[8]. 모듈형 RAG는 이러한 다수 시스템 연동 및 조건부 흐름, 반복적 처리 등을 자연스럽게 수용할 수 있는 설계로 평가받고 있습니다. 또한, 템포럴 컨텍스트 유지(ChronoRAG[1]) 및 복합 쿼리 대응 능력도 모듈별 미세 조정으로 한층 진보가 기대됩니다.  \n",
      "\n",
      "이러한 동향은 스타트업이 한정된 자원으로도 변화무쌍한 시장의 요구에 맞춰 신속한 사업적 의사결정과 혁신적 고객 서비스를 구현하는 데 큰 기여를 할 것입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 출처  \n",
      "[1] http://arxiv.org/abs/2508.18748v2  \n",
      "[2] http://arxiv.org/abs/2509.11937v1  \n",
      "[4] https://g3lu.tistory.com/42  \n",
      "[5] https://brunch.co.kr/@@aPda/338  \n",
      "[6] http://arxiv.org/abs/2407.21059v1  \n",
      "[8] http://arxiv.org/abs/2508.13828v1\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mwrite_section\u001b[0m in [\u001b[1;33mconduct_interview\u001b[0m] 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## 모듈형 RAG: 스타트업 혁신을 이끄는 적응형 정보 생성 시스템\n",
      "\n",
      "### 요약  \n",
      "Retrieval-Augmented Generation(RAG)은 외부 데이터 소스에서 정보를 검색하여 이를 바탕으로 텍스트를 생성하는 AI 프레임워크로, 기업가 정신과 비즈니스 모델 혁신 측면에서 매우 중요한 기술입니다. 특히, 변화가 빠른 스타트업 환경에서는 유연성과 확장성이 뛰어난 정보처리 시스템이 필수적인데, 모듈형 RAG(Modular RAG)는 이러한 요구를 충족시키기에 적합한 진화된 형태입니다. 기존의 단순 RAG(Naive RAG)는 검색과 생성 과정이 하나의 통합된 단일 시스템으로 작동해 구조가 고정적이고 비효율적이었으나, 모듈형 RAG는 이 두 과정을 독립적인 모듈로 분리함으로써 각 부분을 최적화하고 필요시 교체할 수 있습니다. 이 모듈 분리는 시장 변화에 빠르게 대응하고, 시스템 확장 및 성능 개선을 용이하게 하여 스타트업이 혁신적 비즈니스 모델을 운영하는 데 큰 장점으로 작용합니다. 또한, 모듈 간 매끄러운 통합 덕분에 생성되는 응답의 관련성과 일관성이 향상되며, 다양한 데이터 소스나 생성 모델과 쉽게 연동할 수 있는 시스템 확장성을 제공합니다. 본 보고서는 모듈형 RAG가 기존 Naive RAG 대비 갖는 구조적 차별성과 생산 단계에서의 실질적 이점에 대해 심층적으로 분석합니다[1][2][3][4].\n",
      "\n",
      "### 종합 분석\n",
      "\n",
      "#### 1. RAG의 기본 원리와 Naive RAG의 한계  \n",
      "Retrieval-Augmented Generation(RAG)는 외부 지식베이스, 벡터 데이터베이스 또는 웹 등에서 관련 정보를 찾아내고, 그 정보를 바탕으로 자연어 생성 모델이 응답을 생성하는 AI 프레임워크입니다[1][3]. 기존의 Naive RAG 모델은 정보 검색과 생성 과정을 하나의 단순 통합 시스템으로 운영합니다. 즉, 데이터 소스를 먼저 색인(indexing)하고, 생성 모델과 밀접히 연동되어 해당 정보를 그대로 활용해 결과를 출력합니다. 이 접근법은 구현이 간단하다는 장점이 있으나, 검색과 생성 과정이 정적이고 밀접히 결합되어 있어 다음과 같은 문제점이 있습니다[2][4]:\n",
      "\n",
      "- **유연성 부족**: 검색 알고리즘이나 생성 모델을 변경할 경우 전체 시스템을 수정해야 하며, 새로운 데이터 소스 도입도 어렵다.\n",
      "- **확장성 한계**: 정보 소스가 다양해지고 생성 기법이 진화함에 따라 시스템 개선이 어렵다.\n",
      "- **비효율성**: 정보 검색과 응답 생성이 서로 긴밀히 엮여 최적화가 제한된다.\n",
      "\n",
      "이러한 한계는 빠르게 변화하는 시장과 사용자 요구에 대응이 필요한 스타트업 환경에서는 치명적일 수 있습니다.\n",
      "\n",
      "#### 2. 모듈형 RAG의 아키텍처와 주요 기능  \n",
      "모듈형 RAG는 기존 Naive RAG의 통합적 접근방식을 분할하여, 검색 모듈과 생성 모듈을 별도의 교체 가능하고 최적화 가능한 부품으로 분리했습니다[1][2]. 각 모듈은 다음과 같은 역할을 수행합니다:\n",
      "\n",
      "1. **검색(Retrieval) 모듈**  \n",
      "   - 외부 데이터베이스, 벡터 검색, 웹 크롤링 등 다양한 데이터 소스에서 관련 문서나 정보를 효율적으로 찾아냄  \n",
      "   - 최신 및 사용자 맞춤형 검색 알고리즘 적용 가능  \n",
      "   - 독립적으로 업그레이드 및 교체가 가능하여, 예를 들어 특정 산업별 데이터 소스에 특화된 검색 모듈을 빠르게 도입할 수 있음  \n",
      "2. **생성(Generation) 모듈**  \n",
      "   - GPT-3, T5 같은 고도화된 생성 모델들이 검색된 정보를 바탕으로 맥락에 적합한 텍스트 생성  \n",
      "   - 검색 모듈과 독립적으로 발전 가능, 생성 모델의 향상이나 다른 모델과의 교체가 용이  \n",
      "   - 생성 응답의 관련성과 일관성 강화에 중점  \n",
      "\n",
      "이 구분은 각 모듈을 전문화하고 독립적으로 최적화할 수 있도록 돕고, 전체 시스템의 개별 파트를 신속히 개선 가능하게 합니다. 그러면서 모듈 간 원활한 통합을 유지하는 것이 특징입니다[2][4].\n",
      "\n",
      "#### 3. 생산 단계에서 모듈형 RAG의 비즈니스적 이점  \n",
      "스타트업과 같이 환경 변화가 급격한 영역에서는 신속한 기술 적응과 시스템 개선이 생존과 직결됩니다. 모듈형 RAG는 다음과 같은 생산상의 이점으로 이를 지원합니다:\n",
      "\n",
      "- **유연성 및 적응성 강화**  \n",
      "  - 각 모듈을 독립적으로 교체하거나 개선 가능하므로 신제품 출시, 고객 요구 변화, 데이터 소스 변경에 효과적으로 대응  \n",
      "  - 단일 모듈 업데이트가 전체 시스템 안정성에 미치는 영향을 최소화  \n",
      "- **효율성 및 비용 최적화**  \n",
      "  - 검색과 생성 부품별로 성능 문제를 분리해 해결 가능  \n",
      "  - 리소스 집중이 필요한 부분(예: 생성 모델)만 교체하여 비용 효율성 제고  \n",
      "- **확장성 및 유지보수 용이**  \n",
      "  - 모듈 증설 혹은 변경에 따른 신규 기능 도입이 빠름  \n",
      "  - 기존 시스템 전체를 재설계하지 않고 점진적 개선 가능  \n",
      "- **시장 및 사용자 맞춤화 용이**  \n",
      "  - 다양한 도메인의 데이터베이스에 대응 가능한 검색 모듈 도입을 통해 특화 서비스 제공 가능  \n",
      "  - 생성 모델을 특정 언어, 스타일, 규격에 맞게 조정하여 차별화된 사용자 경험 창출  \n",
      "\n",
      "즉, 모듈형 RAG는 정적인 Naive RAG 대비 비즈니스를 빠르고 안정적으로 확장할 수 있는 기술적 토대이자, 혁신적인 비즈니스 모델의 필수 인프라로 자리잡을 수 있습니다[1][2][3].\n",
      "\n",
      "#### 4. 실제 사례 및 스타트업 적용 가능성  \n",
      "Naive RAG 사례에서는 시스템이 하나로 통합되어 있어 검색 알고리즘 변경 시 전체 시스템 수정을 요구하는 반면, 모듈형 RAG는 특정 모듈만 교체하여 최신 검색 방법이나 생성 모델을 신속히 도입할 수 있습니다. 스타트업은 이를 활용해 다음과 같은 전략적 이점을 누릴 수 있습니다:\n",
      "\n",
      "- 경쟁사 대비 빠른 기능 개선 및 시장 적응  \n",
      "- 신규 서비스 테스트 및 전문가 맞춤형 생성 구현에서 비용 및 시간 절감  \n",
      "- 운영 안정성 강화 및 장애 대응 속도 향상  \n",
      "\n",
      "상기 내용을 종합할 때, 모듈형 RAG는 기업가 정신을 가진 창업자와 혁신가들이 AI 기술을 활용해 비즈니스 모델 혁신을 꾀하는 데 최적화된 선택이라 할 수 있습니다[2][4].\n",
      "\n",
      "### 출처  \n",
      "[1] https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag  \n",
      "[2] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[3] https://www.linkedin.com/pulse/comparison-between-three-rag-paradigms-sanjay-kumar-mba-ms-phd-tzrdc  \n",
      "[4] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mconduct_interview\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## 모듈형 RAG: 스타트업 혁신을 이끄는 적응형 정보 생성 시스템\n",
      "\n",
      "### 요약  \n",
      "Retrieval-Augmented Generation(RAG)은 외부 데이터 소스에서 정보를 검색하여 이를 바탕으로 텍스트를 생성하는 AI 프레임워크로, 기업가 정신과 비즈니스 모델 혁신 측면에서 매우 중요한 기술입니다. 특히, 변화가 빠른 스타트업 환경에서는 유연성과 확장성이 뛰어난 정보처리 시스템이 필수적인데, 모듈형 RAG(Modular RAG)는 이러한 요구를 충족시키기에 적합한 진화된 형태입니다. 기존의 단순 RAG(Naive RAG)는 검색과 생성 과정이 하나의 통합된 단일 시스템으로 작동해 구조가 고정적이고 비효율적이었으나, 모듈형 RAG는 이 두 과정을 독립적인 모듈로 분리함으로써 각 부분을 최적화하고 필요시 교체할 수 있습니다. 이 모듈 분리는 시장 변화에 빠르게 대응하고, 시스템 확장 및 성능 개선을 용이하게 하여 스타트업이 혁신적 비즈니스 모델을 운영하는 데 큰 장점으로 작용합니다. 또한, 모듈 간 매끄러운 통합 덕분에 생성되는 응답의 관련성과 일관성이 향상되며, 다양한 데이터 소스나 생성 모델과 쉽게 연동할 수 있는 시스템 확장성을 제공합니다. 본 보고서는 모듈형 RAG가 기존 Naive RAG 대비 갖는 구조적 차별성과 생산 단계에서의 실질적 이점에 대해 심층적으로 분석합니다[1][2][3][4].\n",
      "\n",
      "### 종합 분석\n",
      "\n",
      "#### 1. RAG의 기본 원리와 Naive RAG의 한계  \n",
      "Retrieval-Augmented Generation(RAG)는 외부 지식베이스, 벡터 데이터베이스 또는 웹 등에서 관련 정보를 찾아내고, 그 정보를 바탕으로 자연어 생성 모델이 응답을 생성하는 AI 프레임워크입니다[1][3]. 기존의 Naive RAG 모델은 정보 검색과 생성 과정을 하나의 단순 통합 시스템으로 운영합니다. 즉, 데이터 소스를 먼저 색인(indexing)하고, 생성 모델과 밀접히 연동되어 해당 정보를 그대로 활용해 결과를 출력합니다. 이 접근법은 구현이 간단하다는 장점이 있으나, 검색과 생성 과정이 정적이고 밀접히 결합되어 있어 다음과 같은 문제점이 있습니다[2][4]:\n",
      "\n",
      "- **유연성 부족**: 검색 알고리즘이나 생성 모델을 변경할 경우 전체 시스템을 수정해야 하며, 새로운 데이터 소스 도입도 어렵다.\n",
      "- **확장성 한계**: 정보 소스가 다양해지고 생성 기법이 진화함에 따라 시스템 개선이 어렵다.\n",
      "- **비효율성**: 정보 검색과 응답 생성이 서로 긴밀히 엮여 최적화가 제한된다.\n",
      "\n",
      "이러한 한계는 빠르게 변화하는 시장과 사용자 요구에 대응이 필요한 스타트업 환경에서는 치명적일 수 있습니다.\n",
      "\n",
      "#### 2. 모듈형 RAG의 아키텍처와 주요 기능  \n",
      "모듈형 RAG는 기존 Naive RAG의 통합적 접근방식을 분할하여, 검색 모듈과 생성 모듈을 별도의 교체 가능하고 최적화 가능한 부품으로 분리했습니다[1][2]. 각 모듈은 다음과 같은 역할을 수행합니다:\n",
      "\n",
      "1. **검색(Retrieval) 모듈**  \n",
      "   - 외부 데이터베이스, 벡터 검색, 웹 크롤링 등 다양한 데이터 소스에서 관련 문서나 정보를 효율적으로 찾아냄  \n",
      "   - 최신 및 사용자 맞춤형 검색 알고리즘 적용 가능  \n",
      "   - 독립적으로 업그레이드 및 교체가 가능하여, 예를 들어 특정 산업별 데이터 소스에 특화된 검색 모듈을 빠르게 도입할 수 있음  \n",
      "2. **생성(Generation) 모듈**  \n",
      "   - GPT-3, T5 같은 고도화된 생성 모델들이 검색된 정보를 바탕으로 맥락에 적합한 텍스트 생성  \n",
      "   - 검색 모듈과 독립적으로 발전 가능, 생성 모델의 향상이나 다른 모델과의 교체가 용이  \n",
      "   - 생성 응답의 관련성과 일관성 강화에 중점  \n",
      "\n",
      "이 구분은 각 모듈을 전문화하고 독립적으로 최적화할 수 있도록 돕고, 전체 시스템의 개별 파트를 신속히 개선 가능하게 합니다. 그러면서 모듈 간 원활한 통합을 유지하는 것이 특징입니다[2][4].\n",
      "\n",
      "#### 3. 생산 단계에서 모듈형 RAG의 비즈니스적 이점  \n",
      "스타트업과 같이 환경 변화가 급격한 영역에서는 신속한 기술 적응과 시스템 개선이 생존과 직결됩니다. 모듈형 RAG는 다음과 같은 생산상의 이점으로 이를 지원합니다:\n",
      "\n",
      "- **유연성 및 적응성 강화**  \n",
      "  - 각 모듈을 독립적으로 교체하거나 개선 가능하므로 신제품 출시, 고객 요구 변화, 데이터 소스 변경에 효과적으로 대응  \n",
      "  - 단일 모듈 업데이트가 전체 시스템 안정성에 미치는 영향을 최소화  \n",
      "- **효율성 및 비용 최적화**  \n",
      "  - 검색과 생성 부품별로 성능 문제를 분리해 해결 가능  \n",
      "  - 리소스 집중이 필요한 부분(예: 생성 모델)만 교체하여 비용 효율성 제고  \n",
      "- **확장성 및 유지보수 용이**  \n",
      "  - 모듈 증설 혹은 변경에 따른 신규 기능 도입이 빠름  \n",
      "  - 기존 시스템 전체를 재설계하지 않고 점진적 개선 가능  \n",
      "- **시장 및 사용자 맞춤화 용이**  \n",
      "  - 다양한 도메인의 데이터베이스에 대응 가능한 검색 모듈 도입을 통해 특화 서비스 제공 가능  \n",
      "  - 생성 모델을 특정 언어, 스타일, 규격에 맞게 조정하여 차별화된 사용자 경험 창출  \n",
      "\n",
      "즉, 모듈형 RAG는 정적인 Naive RAG 대비 비즈니스를 빠르고 안정적으로 확장할 수 있는 기술적 토대이자, 혁신적인 비즈니스 모델의 필수 인프라로 자리잡을 수 있습니다[1][2][3].\n",
      "\n",
      "#### 4. 실제 사례 및 스타트업 적용 가능성  \n",
      "Naive RAG 사례에서는 시스템이 하나로 통합되어 있어 검색 알고리즘 변경 시 전체 시스템 수정을 요구하는 반면, 모듈형 RAG는 특정 모듈만 교체하여 최신 검색 방법이나 생성 모델을 신속히 도입할 수 있습니다. 스타트업은 이를 활용해 다음과 같은 전략적 이점을 누릴 수 있습니다:\n",
      "\n",
      "- 경쟁사 대비 빠른 기능 개선 및 시장 적응  \n",
      "- 신규 서비스 테스트 및 전문가 맞춤형 생성 구현에서 비용 및 시간 절감  \n",
      "- 운영 안정성 강화 및 장애 대응 속도 향상  \n",
      "\n",
      "상기 내용을 종합할 때, 모듈형 RAG는 기업가 정신을 가진 창업자와 혁신가들이 AI 기술을 활용해 비즈니스 모델 혁신을 꾀하는 데 최적화된 선택이라 할 수 있습니다[2][4].\n",
      "\n",
      "### 출처  \n",
      "[1] https://rabiloo.com/blog/the-3-types-of-rag-models-naive-rag-modular-rag-and-advanced-rag  \n",
      "[2] https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/  \n",
      "[3] https://www.linkedin.com/pulse/comparison-between-three-rag-paradigms-sanjay-kumar-mba-ms-phd-tzrdc  \n",
      "[4] https://medium.com/@drjulija/what-are-naive-rag-advanced-rag-modular-rag-paradigms-edff410c202e\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "At key 'sections': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43minvoke_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuman_feedback\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langchain_teddynote/messages.py:409\u001b[39m, in \u001b[36minvoke_graph\u001b[39m\u001b[34m(graph, inputs, config, node_names, callback)\u001b[39m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m namespace[-\u001b[32m1\u001b[39m].split(\u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(namespace) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mroot graph\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# subgraphs=True 를 통해 서브그래프의 출력도 포함\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    411\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# node_names가 비어있지 않은 경우에만 필터링\u001b[39;49;00m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnode_names\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnode_names\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2667\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2657\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.tick(\n\u001b[32m   2658\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2659\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2662\u001b[39m ):\n\u001b[32m   2663\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2664\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[32m   2665\u001b[39m         stream_mode, print_mode, subgraphs, stream.get, queue.Empty\n\u001b[32m   2666\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2667\u001b[39m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_tick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2668\u001b[39m \u001b[38;5;66;03m# wait for checkpoint\u001b[39;00m\n\u001b[32m   2669\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m durability_ == \u001b[33m\"\u001b[39m\u001b[33msync\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langgraph/pregel/_loop.py:527\u001b[39m, in \u001b[36mPregelLoop.after_tick\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    525\u001b[39m writes = [w \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tasks.values() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m t.writes]\n\u001b[32m    526\u001b[39m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m527\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpointer_get_next_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# produce values output\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.updated_channels.isdisjoint(\n\u001b[32m    536\u001b[39m     (\u001b[38;5;28mself\u001b[39m.output_keys,)\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.output_keys, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_keys\n\u001b[32m    539\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langgraph/pregel/_algo.py:295\u001b[39m, in \u001b[36mapply_writes\u001b[39m\u001b[34m(checkpoint, channels, tasks, get_next_version, trigger_to_nodes)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel.items():\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    296\u001b[39m             checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m][chan] = next_version\n\u001b[32m    297\u001b[39m             \u001b[38;5;66;03m# unavailable channels can't trigger tasks, so don't add them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langgraph/channels/last_value.py:64\u001b[39m, in \u001b[36mLastValue.update\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) != \u001b[32m1\u001b[39m:\n\u001b[32m     60\u001b[39m     msg = create_error_message(\n\u001b[32m     61\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt key \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: Can receive only one value per step. Use an Annotated key to handle multiple values.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m         error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n\u001b[32m     63\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m.value = values[-\u001b[32m1\u001b[39m]\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: At key 'sections': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE"
     ]
    }
   ],
   "source": [
    "invoke_graph(graph, Command(update={\"human_feedback\": None}), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12c082b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "At key 'sections': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m final_state = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m report = final_state.values.get(\u001b[33m\"\u001b[39m\u001b[33mfinal_report\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m display(Markdown(report))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:1261\u001b[39m, in \u001b[36mPregel.get_state\u001b[39m\u001b[34m(self, config, subgraphs)\u001b[39m\n\u001b[32m   1258\u001b[39m     config[CONF][CONFIG_KEY_THREAD_ID] = \u001b[38;5;28mstr\u001b[39m(thread_id)\n\u001b[32m   1260\u001b[39m saved = checkpointer.get_tuple(config)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_state_snapshot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1263\u001b[39m \u001b[43m    \u001b[49m\u001b[43msaved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapply_pending_writes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG_KEY_CHECKPOINT_ID\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1266\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:1085\u001b[39m, in \u001b[36mPregel._prepare_state_snapshot\u001b[39m\u001b[34m(self, config, saved, recurse, apply_pending_writes)\u001b[39m\n\u001b[32m   1083\u001b[39m         next_tasks[tid].writes.append((k, v))\n\u001b[32m   1084\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tasks := [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m next_tasks.values() \u001b[38;5;28;01mif\u001b[39;00m t.writes]:\n\u001b[32m-> \u001b[39m\u001b[32m1085\u001b[39m         \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m            \u001b[49m\u001b[43msaved\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m tasks_with_writes = tasks_w_writes(\n\u001b[32m   1089\u001b[39m     next_tasks.values(),\n\u001b[32m   1090\u001b[39m     saved.pending_writes,\n\u001b[32m   1091\u001b[39m     task_states,\n\u001b[32m   1092\u001b[39m     \u001b[38;5;28mself\u001b[39m.stream_channels_asis,\n\u001b[32m   1093\u001b[39m )\n\u001b[32m   1094\u001b[39m \u001b[38;5;66;03m# assemble the state snapshot\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langgraph/pregel/_algo.py:295\u001b[39m, in \u001b[36mapply_writes\u001b[39m\u001b[34m(checkpoint, channels, tasks, get_next_version, trigger_to_nodes)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel.items():\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    296\u001b[39m             checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m][chan] = next_version\n\u001b[32m    297\u001b[39m             \u001b[38;5;66;03m# unavailable channels can't trigger tasks, so don't add them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/Wantedlab/langchain-academy/venv/lib/python3.12/site-packages/langgraph/channels/last_value.py:64\u001b[39m, in \u001b[36mLastValue.update\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) != \u001b[32m1\u001b[39m:\n\u001b[32m     60\u001b[39m     msg = create_error_message(\n\u001b[32m     61\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt key \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: Can receive only one value per step. Use an Annotated key to handle multiple values.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     62\u001b[39m         error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n\u001b[32m     63\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n\u001b[32m     66\u001b[39m \u001b[38;5;28mself\u001b[39m.value = values[-\u001b[32m1\u001b[39m]\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: At key 'sections': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "final_state = graph.get_state(config)\n",
    "report = final_state.values.get(\"final_report\")\n",
    "display(Markdown(report))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation-introduction-to-langgraph (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
