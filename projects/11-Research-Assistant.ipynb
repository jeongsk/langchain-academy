{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d140c86",
   "metadata": {},
   "source": [
    "## STORM: 연구를 위한 멀티 에이전트\n",
    "\n",
    "### 개요\n",
    "\n",
    "STORM(Synthesis of Topic Outline through Retrieval and Multi-perspective Question Asking)은 Stanford 대학에서 개발한 LLM 기반의 지식 큐레이션 시스템입니다. 이 시스템은 인터넷 리서치를 통해 Wikipedia 수준의 포괄적이고 체계적인 장문의 기사를 자동으로 생성하는 것을 목표로 합니다.\n",
    "\n",
    "![](https://github.com/stanford-oval/storm/raw/main/assets/two_stages.jpg)\n",
    "\n",
    "### 핵심 아키텍처\n",
    "\n",
    "STORM은 두 단계의 파이프라인으로 구성됩니다:\n",
    "\n",
    "1. **사전 작성 단계(Pre-writing Stage)**\n",
    "   - 인터넷 기반 리서치를 수행하여 참고 자료 수집\n",
    "   - 다양한 관점(perspective) 발견\n",
    "   - 주제에 대한 개요(outline) 생성\n",
    "\n",
    "2. **작성 단계(Writing Stage)**\n",
    "   - 생성된 개요와 수집된 참고 자료를 활용\n",
    "   - 인용(citation)이 포함된 전체 기사 작성\n",
    "\n",
    "### 멀티 에이전트 접근법\n",
    "\n",
    "STORM의 핵심은 **관점 기반 질문 생성(Perspective-Guided Question Asking)** 과 **시뮬레이션된 대화(Simulated Conversation)** 전략입니다:\n",
    "\n",
    "- **다양한 관점 발견**: 유사한 주제의 기존 기사들을 조사하여 다양한 시각을 발견하고, 이를 질문 생성 과정에 활용\n",
    "- **역할 기반 대화 시뮬레이션**: Wikipedia 작성자와 주제 전문가 간의 대화를 시뮬레이션\n",
    "  - 작성자 에이전트: 다양한 관점에서 질문 제기\n",
    "  - 전문가 에이전트: 인터넷 소스에 기반한 답변 제공\n",
    "  - 이를 통해 이해도를 업데이트하고 후속 질문 생성\n",
    "\n",
    "### Co-STORM: 협업 확장\n",
    "\n",
    "Co-STORM은 STORM을 협업 기능으로 확장한 버전으로, 다음과 같은 멀티 에이전트 구성을 포함합니다:\n",
    "\n",
    "\n",
    "- **LLM 전문가 에이전트**: 외부 소스에 기반한 답변 생성 및 후속 질문 제기\n",
    "- **중재자 에이전트(Moderator)**: 발견된 정보에서 영감을 받은 사고를 자극하는 질문 생성\n",
    "- **동적 마인드맵**: 정보를 계층적으로 정리하여 인간과 시스템 간의 공유 개념 공간 생성\n",
    "\n",
    "![](https://github.com/stanford-oval/storm/raw/main/assets/co-storm-workflow.jpg)\n",
    "\n",
    "### 주요 특징\n",
    "\n",
    "- **포괄적 커버리지**: 다양한 관점에서 주제를 탐색하여 Wikipedia 수준의 광범위한 내용 생성\n",
    "- **구조화된 정보**: 자동으로 생성된 개요를 통해 체계적으로 정보 조직\n",
    "- **신뢰할 수 있는 출처**: 인터넷 소스에 기반하여 모든 정보에 인용 포함\n",
    "- **평가 검증**: FreshWiki 데이터셋을 통한 평가에서 기존 방법 대비 조직성 25%, 커버리지 10% 향상\n",
    "\n",
    "STORM은 복잡한 연구 작업을 자동화하고, 다양한 관점에서 정보를 종합하며, 신뢰할 수 있는 장문의 리포트를 생성하는 멀티 에이전트 시스템의 우수한 사례입니다.\n",
    "\n",
    "---\n",
    "\n",
    "- 참고 자료: https://wikidocs.net/270693\n",
    "- 관련 논문: https://arxiv.org/abs/2402.14207\n",
    "- GitHub 저장소: https://github.com/stanford-oval/storm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb325a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "112e4070",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84dd060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\", override=True)\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\"\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c360a",
   "metadata": {},
   "source": [
    "## 분석가 생성 에이전트 with Human-In-The-Loop\n",
    "\n",
    "분석가 생성이 필요한 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e07bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    \"\"\"분석가 속성과 메타데이터를 정의\"\"\"\n",
    "\n",
    "    affiliation: Annotated[str, Field(description=\"분석가의 주요 소속 기관\")]\n",
    "    name: Annotated[str, Field(description=\"분석가 이름\")]\n",
    "    role: Annotated[str, Field(description=\"주제 맥락에서의 분석가의 역할\")]\n",
    "    description: Annotated[\n",
    "        str, Field(description=\"분석가의 관심사, 우려 사항 및 동기 설명\")\n",
    "    ]\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return (\n",
    "            f\"이름: {self.name}\\n\"\n",
    "            f\"역할: {self.role}\\n\"\n",
    "            f\"소속 기관: {self.affiliation}\\n\"\n",
    "            f\"설명: {self.description}\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    \"\"\"분석가들의 집합\"\"\"\n",
    "\n",
    "    analysts: Annotated[\n",
    "        list[Analyst],\n",
    "        Field(description=\"분석가들의 역할 및 소속 기관을 포함한 종합 목록\"),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6778d7",
   "metadata": {},
   "source": [
    "### 분석가 생성 상태 및 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61f39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 정의\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: Annotated[str, \"연구 주제\"]\n",
    "    max_analysts: Annotated[int, \"생성할 분석가의 최대 수\"]\n",
    "    human_analyst_feedback: Annotated[str, \"휴먼 피드백\"]\n",
    "    analysts: Annotated[list[Analyst], \"분석가 목록\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46502385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석가 생성 프롬프트\n",
    "analyst_instructions = \"\"\"AI 애널리스트 페르소나 세트를 생성하는 임무를 맡았습니다.\n",
    "\n",
    "다음 지침을 주의 깊게 따르십시오:\n",
    "\n",
    "1. 먼저 연구 주제를 검토하십시오:\n",
    "\n",
    "{topic}\n",
    "\n",
    "2. 애널리스트 생성 가이드로 제공된 선택적 편집 피드백을 검토하십시오:\n",
    "\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3. 위 문서 및/또는 피드백을 바탕으로 가장 흥미로운 테마를 결정하십시오.\n",
    "\n",
    "4. 상위 {max_analysts}개 테마를 선정하십시오.\n",
    "\n",
    "5. 각 테마에 한 명의 애널리스트를 배정하십시오.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bcfdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "# 분석가 생성 노드\n",
    "def create_analysts(state: GenerateAnalystsState):\n",
    "    \"\"\"분석가 페르소나를 생성합니다.\"\"\"\n",
    "\n",
    "    topic = state[\"topic\"]\n",
    "    max_analysts = state[\"max_analysts\"]\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "\n",
    "    llm_with_structured = llm.with_structured_output(Perspectives)\n",
    "\n",
    "    system_message = analyst_instructions.format(\n",
    "        topic=topic,\n",
    "        human_analyst_feedback=human_analyst_feedback,\n",
    "        max_analysts=max_analysts,\n",
    "    )\n",
    "\n",
    "    response = llm_with_structured.invoke(\n",
    "        [SystemMessage(content=system_message)]\n",
    "        + [HumanMessage(content=\"Generate the set of analysts.\")]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"analysts\": response.analysts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c51fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysts': [Analyst(affiliation='MIT Computer Science and Artificial Intelligence Laboratory', name='Dr. Aiden Lee', role='Multi-Agent Systems Theorist', description='Specializes in the foundational theories of multi-agent interactions, coordination algorithms, and emergent behavior in decentralized systems.'),\n",
       "  Analyst(affiliation='Stanford University, Human-Centered AI Institute', name='Prof. Emily Chen', role='Human-Multi-Agent Interaction Specialist', description='Focuses on designing multi-agent systems that effectively collaborate with humans, emphasizing usability, trust, and ethical considerations.'),\n",
       "  Analyst(affiliation='OpenAI Research', name='Dr. Ravi Kumar', role='Applied Multi-Agent Reinforcement Learning Researcher', description='Expert in developing practical multi-agent reinforcement learning algorithms for complex, real-world applications including robotics and autonomous vehicles.')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_analysts({\"topic\": \"멀티 에이전트\", \"max_analysts\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b276ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 피드백 노드\n",
    "def human_feedback(state: GenerateAnalystsState):\n",
    "    \"\"\"사용자 피드백을 받기 위한 중단점 노드\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a9c93",
   "metadata": {},
   "source": [
    "### 분석가 생성 그래프 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509107a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "def should_continue(state: GenerateAnalystsState) -> Literal[\"create_analysts\", END]:\n",
    "    \"\"\"워크플로우의 다음 노드를 결정합니다.\"\"\"\n",
    "\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", \"\")\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "    return END\n",
    "\n",
    "\n",
    "builder = StateGraph(GenerateAnalystsState)\n",
    "builder.add_node(create_analysts)\n",
    "builder.add_node(human_feedback)\n",
    "\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\n",
    "    \"human_feedback\", should_continue, {\"create_analysts\": \"create_analysts\", END: END}\n",
    ")\n",
    "builder.set_entry_point(\"create_analysts\")\n",
    "graph = builder.compile(\n",
    "    interrupt_before=[\"human_feedback\"], checkpointer=InMemorySaver()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8274f81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e503e",
   "metadata": {},
   "source": [
    "### 분석가 생성 그래프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07008ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### create_analysts #####\n",
      "{'analysts': [Analyst(affiliation='OmniData AI Research Lab', name='Dr. Mina Lee', role='AI Systems Researcher', description='Dr. Mina Lee specializes in AI retrieval-augmented generation systems, focusing on the agentic capabilities of language models to autonomously decide and execute information search and synthesis steps. She explores how Agentic RAG frameworks empower models with proactive decision-making and iterative interaction with retrieval components.'),\n",
      "              Analyst(affiliation='Adaptive Intelligence Solutions', name='Prof. Jun-ho Kim', role='Machine Learning Strategist', description='Prof. Jun-ho Kim investigates adaptive mechanisms in retrieval-augmented generation architectures where models dynamically adjust their retrieval strategies based on context and feedback. His work sheds light on how Adaptive RAG differs from agentic approaches by emphasizing flexibility and responsiveness in information retrieval processes.'),\n",
      "              Analyst(affiliation='NextGen AI Innovators', name='Eunseo Park', role='AI Product Analyst', description='Eunseo Park analyzes practical implications and product design involving Agentic versus Adaptive RAG systems, focusing on user experience and system performance trade-offs. She examines how the contrasting characteristics of these frameworks influence the deployment of AI-driven applications in real-world settings.')]}\n",
      "\n",
      "##### __interrupt__ #####\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from random import random\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(configurable={\"thread_id\": random()})\n",
    "\n",
    "inputs = {\n",
    "    \"max_analysts\": 3,\n",
    "    \"topic\": \"Agentic RAG와 Adaptive RAG의 차이점은 무엇인가요?\",\n",
    "}\n",
    "for event in graph.stream(inputs, config=config):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n##### {key} #####\")\n",
    "        pprint(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab4a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysts': [Analyst(affiliation='OmniData AI Research Lab', name='Dr. Mina Lee', role='AI Systems Researcher', description='Dr. Mina Lee specializes in AI retrieval-augmented generation systems, focusing on the agentic capabilities of language models to autonomously decide and execute information search and synthesis steps. She explores how Agentic RAG frameworks empower models with proactive decision-making and iterative interaction with retrieval components.'),\n",
      "              Analyst(affiliation='Adaptive Intelligence Solutions', name='Prof. Jun-ho Kim', role='Machine Learning Strategist', description='Prof. Jun-ho Kim investigates adaptive mechanisms in retrieval-augmented generation architectures where models dynamically adjust their retrieval strategies based on context and feedback. His work sheds light on how Adaptive RAG differs from agentic approaches by emphasizing flexibility and responsiveness in information retrieval processes.'),\n",
      "              Analyst(affiliation='NextGen AI Innovators', name='Eunseo Park', role='AI Product Analyst', description='Eunseo Park analyzes practical implications and product design involving Agentic versus Adaptive RAG systems, focusing on user experience and system performance trade-offs. She examines how the contrasting characteristics of these frameworks influence the deployment of AI-driven applications in real-world settings.')],\n",
      " 'max_analysts': 3,\n",
      " 'topic': 'Agentic RAG와 Adaptive RAG의 차이점은 무엇인가요?'}\n",
      "('human_feedback',)\n"
     ]
    }
   ],
   "source": [
    "# 현재 상태 스냅샷\n",
    "snapshot = graph.get_state(config)\n",
    "pprint(snapshot.values)\n",
    "pprint(snapshot.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb64c3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### human_feedback #####\n",
      "None\n",
      "\n",
      "##### create_analysts #####\n",
      "{'analysts': [Analyst(affiliation='Tech Startup - Seoul', name='Seokho Phil', role='Founder & AI Product Strategist', description='Startup founder with deep expertise in AI integration, focusing on bridging technical RAG solutions with entrepreneurial business models to foster adaptive growth and competitive advantage.'),\n",
      "              Analyst(affiliation='Innovative AI Research Lab', name='Dr. Min-Jae Lee', role='Lead Research Scientist', description='Expert in agentic AI systems, specializing in the design and implementation of agentic Retrieval-Augmented Generation models that take autonomous initiative in information retrieval and decision-making.'),\n",
      "              Analyst(affiliation='Adaptive Computing Institute', name='Prof. Hana Kim', role='Professor of Adaptive AI Systems', description='Academic researcher focused on Adaptive RAG models that dynamically adjust their retrieval and generation processes based on context awareness and user feedback to enhance performance and relevance.')]}\n",
      "\n",
      "##### __interrupt__ #####\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# 휴먼 피드백 전달\n",
    "from langgraph.types import Command\n",
    "\n",
    "for event in graph.stream(\n",
    "    Command(\n",
    "        update={\n",
    "            \"human_analyst_feedback\": \"스타트업 출신의 석호필이라는 인물을 추가해 기업가적 관점을 더해주세요.\"\n",
    "        },\n",
    "    ),\n",
    "    config=config,\n",
    "):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n##### {key} #####\")\n",
    "        pprint(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "913e6244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### human_feedback #####\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(\n",
    "    Command(update={\"human_analyst_feedback\": None}),\n",
    "    config=config,\n",
    "):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n##### {key} #####\")\n",
    "        pprint(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5bcba8",
   "metadata": {},
   "source": [
    "최종 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0da29cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={'topic': 'Agentic RAG와 Adaptive RAG의 차이점은 무엇인가요?', 'max_analysts': 3, 'human_analyst_feedback': None, 'analysts': [Analyst(affiliation='Tech Startup - Seoul', name='Seokho Phil', role='Founder & AI Product Strategist', description='Startup founder with deep expertise in AI integration, focusing on bridging technical RAG solutions with entrepreneurial business models to foster adaptive growth and competitive advantage.'), Analyst(affiliation='Innovative AI Research Lab', name='Dr. Min-Jae Lee', role='Lead Research Scientist', description='Expert in agentic AI systems, specializing in the design and implementation of agentic Retrieval-Augmented Generation models that take autonomous initiative in information retrieval and decision-making.'), Analyst(affiliation='Adaptive Computing Institute', name='Prof. Hana Kim', role='Professor of Adaptive AI Systems', description='Academic researcher focused on Adaptive RAG models that dynamically adjust their retrieval and generation processes based on context awareness and user feedback to enhance performance and relevance.')]}, next=(), config={'configurable': {'thread_id': '0.8998343459486847', 'checkpoint_ns': '', 'checkpoint_id': '1f0abb45-11e8-616c-8004-24a134b798ef'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-10-17T23:52:19.190196+00:00', parent_config={'configurable': {'thread_id': '0.8998343459486847', 'checkpoint_ns': '', 'checkpoint_id': '1f0abb45-11c9-6e10-8003-cc7091e311b5'}}, tasks=(), interrupts=())\n"
     ]
    }
   ],
   "source": [
    "# 스냅샷을 가져옵니다.\n",
    "final_state = graph.get_state(config)\n",
    "pprint(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a99468a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 분석가 수: 3\n",
      "================================\n",
      "이름: Seokho Phil\n",
      "역할: Founder & AI Product Strategist\n",
      "소속 기관: Tech Startup - Seoul\n",
      "설명: Startup founder with deep expertise in AI integration, focusing on bridging technical RAG solutions with entrepreneurial business models to foster adaptive growth and competitive advantage.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "이름: Dr. Min-Jae Lee\n",
      "역할: Lead Research Scientist\n",
      "소속 기관: Innovative AI Research Lab\n",
      "설명: Expert in agentic AI systems, specializing in the design and implementation of agentic Retrieval-Augmented Generation models that take autonomous initiative in information retrieval and decision-making.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "이름: Prof. Hana Kim\n",
      "역할: Professor of Adaptive AI Systems\n",
      "소속 기관: Adaptive Computing Institute\n",
      "설명: Academic researcher focused on Adaptive RAG models that dynamically adjust their retrieval and generation processes based on context awareness and user feedback to enhance performance and relevance.\n",
      "\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "analysts = final_state.values.get(\"analysts\")\n",
    "print(f\"생성된 분석가 수: {len(analysts)}\", end=\"\\n================================\\n\")\n",
    "\n",
    "for analyst in analysts:\n",
    "    print(analyst.persona)\n",
    "    print(\"- \" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90393571",
   "metadata": {},
   "source": [
    "## 인터뷰 에이전트\n",
    "\n",
    "### 질문 생성 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364a5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    \"\"\"인터뷰 상태를 저장합니다.\"\"\"\n",
    "\n",
    "    max_num: Annotated[int, \"대화 턴수\"]\n",
    "    context: Annotated[list, operator.add]\n",
    "    analyst: Annotated[Analyst, \"분석가\"]\n",
    "    interview: Annotated[str, \"인터뷰 내용\"]\n",
    "    sections: Annotated[list, \"보고서 섹션 목록\"]\n",
    "\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: Annotated[str, Field(None, description=\"retrieval를 위한 검색 쿼리\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d484c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인터뷰 시스템 프롬프트\n",
    "question_instructions = \"\"\"당신은 특정 주제에 대해 알아보기 위해 전문가를 인터뷰하는 임무를 맡은 분석가입니다.\n",
    "\n",
    "당신의 목표는 주제에 관련된 흥미롭고 구체적인 통찰력을 추출하는 것입니다.\n",
    "\n",
    "1. 흥미로움: 사람들이 놀라워하거나 당연하지 않다고 느낄 만한 통찰력.\n",
    "2. 구체성: 일반론을 피하고 전문가의 구체적인 사례를 포함하는 통찰력.\n",
    "\n",
    "다음은 집중할 주제와 목표 목록입니다: {goals}\n",
    "\n",
    "먼저, 당신의 인물을 반영하는 이름으로 자신을 소개한 후 질문을 시작하세요.\n",
    "\n",
    "주제에 대한 이해를 심화하고 정교화하기 위해 계속해서 질문을 이어가세요.\n",
    "\n",
    "이해가 충분하다고 판단되면 \"도움 주셔서 정말 감사합니다!\"라고 말하며 인터뷰를 마무리하세요.\n",
    "\n",
    "응답 전반에 걸쳐 제공된 인물과 목표를 반영하여 캐릭터를 유지하는 것을 잊지 마세요.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32f5de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 생성 노드\n",
    "def generate_question(state: InterviewState):\n",
    "    analyst = state[\"analyst\"]\n",
    "\n",
    "    system_message = question_instructions.format(goals=analyst.persona)\n",
    "    response = llm.invoke([SystemMessage(content=system_message)] + state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b9591fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요, 저는 김필입니다. Tech Innovators Inc.에서 기업가 출신 애널리스트로 일하고 있습니다. 주로 스타트업들의 기업가 정신과 비즈니스 모델 혁신을 연구하며, 적응형 시스템과 시장에서의 유연성을 중점적으로 다룹니다. 오늘 저와 함께 어떤 점을 깊이 탐구해 보실까요?\n"
     ]
    }
   ],
   "source": [
    "response = generate_question(\n",
    "    {\n",
    "        \"analyst\": Analyst(\n",
    "            name=\"김필\",\n",
    "            affiliation=\"Tech Innovators Inc.\",\n",
    "            role=\"기업가적 분석가\",\n",
    "            description=\"창업자 출신 애널리스트로, 기업가 정신과 비즈니스 모델 혁신에 주력합니다. 스타트업 관점에서 적응형 시스템에 대한 통찰력을 제공하며, 유연성과 시장 적응력을 강조합니다.\",\n",
    "        ),\n",
    "        \"messages\": [],\n",
    "    }\n",
    ")\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53075650",
   "metadata": {},
   "source": [
    "### 도구 정의\n",
    "\n",
    "#### 웹검색 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2a89434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "web_search = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc7fd6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '지난 윔블던에서 무슨 일이 있었나요?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'http://m.tennispeople.kr/news/articleView.html?idxno=17168',\n",
       "   'title': '윔블던 컴퓨터 라인 판정 믿어도 되나 - 테니스피플',\n",
       "   'content': '사건은 6일 윔블던 센터 코트에서 열린 여자 단식 16강전 1세트 4-4 상황에서 발생했다. 영국 소니 카르탈과 러시아의 아나스타샤 파블류첸코바가 맞붙',\n",
       "   'score': 0.38498205,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://sports.news.nate.com/view/20250704n04849',\n",
       "   'title': '\"아웃, 인은 기계가 판정\" 148년 전통 깬 윔블던, 인간 선심 사라졌다',\n",
       "   'content': '올해 윔블던 테니스 대회는 148년 역사상 처음으로 인간 선심이 사라진 대회로 기록됐다. CNN은 4일 “윔블던 라인 콜은 전적으로 전자 판독',\n",
       "   'score': 0.34846824,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.busan.com/view/busan/view.php?code=2025070317510369945',\n",
       "   'title': \"톱시드 23명 1회전 탈락… '이변의 윔블던' - 부산일보\",\n",
       "   'content': '폭염 속에 진행된 윔블던 테니스 대회에서 이변이 속출하고 있다. 남녀 16명의 시드 배정자, 총 32명 중 무려 23명이 1회전에서 탈락했다.',\n",
       "   'score': 0.2246166,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.7,\n",
       " 'request_id': 'a1cfeb0f-0566-4f47-a3aa-8cc943f2a7c7'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search.invoke({\"query\": \"지난 윔블던에서 무슨 일이 있었나요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac7eed",
   "metadata": {},
   "source": [
    "#### 논문 검색 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f49ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import ArxivRetriever\n",
    "\n",
    "arxiv_retriever = ArxivRetriever(\n",
    "    load_max_docs=3,\n",
    "    load_all_available_meta=True,\n",
    "    get_full_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f016ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2024-07-26', 'Title': 'Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks', 'Authors': 'Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang', 'Summary': 'Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities\\nof Large Language Models (LLMs) in tackling knowledge-intensive tasks. The\\nincreasing demands of application scenarios have driven the evolution of RAG,\\nleading to the integration of advanced retrievers, LLMs and other complementary\\ntechnologies, which in turn has amplified the intricacy of RAG systems.\\nHowever, the rapid advancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process of\\n\"retrieve-then-generate\". In this context, this paper examines the limitations\\nof the existing RAG paradigm and introduces the modular RAG framework. By\\ndecomposing complex RAG systems into independent modules and specialized\\noperators, it facilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a more advanced\\ndesign that integrates routing, scheduling, and fusion mechanisms. Drawing on\\nextensive research, this paper further identifies prevalent RAG\\npatterns-linear, conditional, branching, and looping-and offers a comprehensive\\nanalysis of their respective implementation nuances. Modular RAG presents\\ninnovative opportunities for the conceptualization and deployment of RAG\\nsystems. Finally, the paper explores the potential emergence of new operators\\nand paradigms, establishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment of RAG\\ntechnologies.', 'entry_id': 'http://arxiv.org/abs/2407.21059v1', 'published_first_time': '2024-07-26', 'comment': None, 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI', 'cs.IR'], 'links': ['http://arxiv.org/abs/2407.21059v1', 'http://arxiv.org/pdf/2407.21059v1']}, page_content='1\\nModular RAG: Transforming RAG Systems into\\nLEGO-like Reconfigurable Frameworks\\nYunfan Gao, Yun Xiong, Meng Wang, Haofen Wang\\nAbstract—Retrieval-augmented\\nGeneration\\n(RAG)\\nhas\\nmarkedly enhanced the capabilities of Large Language Models\\n(LLMs) in tackling knowledge-intensive tasks. The increasing\\ndemands of application scenarios have driven the evolution\\nof RAG, leading to the integration of advanced retrievers,\\nLLMs and other complementary technologies, which in turn\\nhas amplified the intricacy of RAG systems. However, the rapid\\nadvancements are outpacing the foundational RAG paradigm,\\nwith many methods struggling to be unified under the process\\nof “retrieve-then-generate”. In this context, this paper examines\\nthe limitations of the existing RAG paradigm and introduces\\nthe modular RAG framework. By decomposing complex RAG\\nsystems into independent modules and specialized operators, it\\nfacilitates a highly reconfigurable framework. Modular RAG\\ntranscends the traditional linear architecture, embracing a\\nmore advanced design that integrates routing, scheduling, and\\nfusion mechanisms. Drawing on extensive research, this paper\\nfurther identifies prevalent RAG patterns—linear, conditional,\\nbranching, and looping—and offers a comprehensive analysis\\nof their respective implementation nuances. Modular RAG\\npresents\\ninnovative\\nopportunities\\nfor\\nthe\\nconceptualization\\nand deployment of RAG systems. Finally, the paper explores\\nthe potential emergence of new operators and paradigms,\\nestablishing a solid theoretical foundation and a practical\\nroadmap for the continued evolution and practical deployment\\nof RAG technologies.\\nIndex Terms—Retrieval-augmented generation, large language\\nmodel, modular system, information retrieval\\nI. INTRODUCTION\\nL\\nARGE Language Models (LLMs) have demonstrated\\nremarkable capabilities, yet they still face numerous\\nchallenges, such as hallucination and the lag in information up-\\ndates [1]. Retrieval-augmented Generation (RAG), by access-\\ning external knowledge bases, provides LLMs with important\\ncontextual information, significantly enhancing their perfor-\\nmance on knowledge-intensive tasks [2]. Currently, RAG, as\\nan enhancement method, has been widely applied in various\\npractical application scenarios, including knowledge question\\nanswering, recommendation systems, customer service, and\\npersonal assistants. [3]–[6]\\nDuring the nascent stages of RAG , its core framework is\\nconstituted by indexing, retrieval, and generation, a paradigm\\nreferred to as Naive RAG [7]. However, as the complexity\\nof tasks and the demands of applications have escalated, the\\nYunfan Gao is with Shanghai Research Institute for Intelligent Autonomous\\nSystems, Tongji University, Shanghai, 201210, China.\\nYun Xiong is with Shanghai Key Laboratory of Data Science, School of\\nComputer Science, Fudan University, Shanghai, 200438, China.\\nMeng Wang and Haofen Wang are with College of Design and Innovation,\\nTongji University, Shanghai, 20092, China. (Corresponding author: Haofen\\nWang. E-mail: carter.whfcarter@gmail.com)\\nlimitations of Naive RAG have become increasingly apparent.\\nAs depicted in Figure 1, it predominantly hinges on the\\nstraightforward similarity of chunks, result in poor perfor-\\nmance when confronted with complex queries and chunks with\\nsubstantial variability. The primary challenges of Naive RAG\\ninclude: 1) Shallow Understanding of Queries. The semantic\\nsimilarity between a query and document chunk is not always\\nhighly consistent. Relying solely on similarity calculations\\nfor retrieval lacks an in-depth exploration of the relationship\\nbetween the query and the document [8]. 2) Retrieval Re-\\ndundancy and Noise. Feeding all retrieved chunks directly\\ninto LLMs is not always beneficial. Research indicates that\\nan excess of redundant and noisy information may interfere\\nwith the LLM’s identification of key information, thereby\\nincreasing the risk of generating erroneous and hallucinated\\nresponses. [9]\\nTo overcome the aforementioned limitations, '),\n",
       " Document(metadata={'Published': '2024-03-27', 'Title': 'Retrieval-Augmented Generation for Large Language Models: A Survey', 'Authors': 'Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, Haofen Wang', 'Summary': \"Large Language Models (LLMs) showcase impressive capabilities but encounter\\nchallenges like hallucination, outdated knowledge, and non-transparent,\\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\\nemerged as a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the generation,\\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\\nupdates and integration of domain-specific information. RAG synergistically\\nmerges LLMs' intrinsic knowledge with the vast, dynamic repositories of\\nexternal databases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\\ntripartite foundation of RAG frameworks, which includes the retrieval, the\\ngeneration and the augmentation techniques. The paper highlights the\\nstate-of-the-art technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG systems.\\nFurthermore, this paper introduces up-to-date evaluation framework and\\nbenchmark. At the end, this article delineates the challenges currently faced\\nand points out prospective avenues for research and development.\", 'entry_id': 'http://arxiv.org/abs/2312.10997v5', 'published_first_time': '2023-12-18', 'comment': 'Ongoing Work', 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI'], 'links': ['http://arxiv.org/abs/2312.10997v5', 'http://arxiv.org/pdf/2312.10997v5']}, page_content='1\\nRetrieval-Augmented Generation for Large\\nLanguage Models: A Survey\\nYunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\\nWangc, and Haofen Wang a,c\\naShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\\nbShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\\ncCollege of Design and Innovation, Tongji University\\nAbstract—Large Language Models (LLMs) showcase impres-\\nsive capabilities but encounter challenges like hallucination,\\noutdated knowledge, and non-transparent, untraceable reasoning\\nprocesses. Retrieval-Augmented Generation (RAG) has emerged\\nas a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the\\ngeneration, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-\\nsic knowledge with the vast, dynamic repositories of external\\ndatabases. This comprehensive review paper offers a detailed\\nexamination of the progression of RAG paradigms, encompassing\\nthe Naive RAG, the Advanced RAG, and the Modular RAG.\\nIt meticulously scrutinizes the tripartite foundation of RAG\\nframeworks, which includes the retrieval, the generation and the\\naugmentation techniques. The paper highlights the state-of-the-\\nart technologies embedded in each of these critical components,\\nproviding a profound understanding of the advancements in RAG\\nsystems. Furthermore, this paper introduces up-to-date evalua-\\ntion framework and benchmark. At the end, this article delineates\\nthe challenges currently faced and points out prospective avenues\\nfor research and development 1.\\nIndex Terms—Large language model, retrieval-augmented gen-\\neration, natural language processing, information retrieval\\nI. INTRODUCTION\\nL\\nARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing “hallucinations” [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown\\nCorresponding Author.Email:haofen.wang@tongji.edu.cn\\n1Resources\\nare\\navailable\\nat\\nhttps://github.com/Tongji-KGLLM/\\nRAG-Survey\\nin Figure 1. The development trajectory of RAG in the era\\nof large models exhibits several distinct stage characteristics.\\nInitially, RAG’s inception coincided with the rise of the\\nTransformer architecture, focusing on enhancing language\\nmodels by incorporating additional knowledge through Pre-\\nTraining Models (PTM). This early stage was characterized\\nby foundational work aimed at refining pre-training techniques\\n[3]–[5].The subsequent arrival of ChatGPT [6] marked a\\npivotal moment, with LLM demonstrating powerful in context\\nlearning (ICL) capabilities. RAG research shifted towards\\nproviding better information for LLMs to answer more com-\\nplex and knowledge-intensive tasks during the inference stage,\\nleading to rapid development in RAG studies. As research\\nprogressed, the enhancement of RAG was no longer limited\\nto the inference stage but began to incorporate more with LLM\\nfine-tuning techniques.\\nThe burgeoning field of RAG has experienced swift growth,\\nyet it has not been accompanied by a systematic synthesis that\\ncould clarify its broader trajectory. Thi'),\n",
       " Document(metadata={'Published': '2025-10-11', 'Title': 'MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning', 'Authors': 'Thang Nguyen, Peter Chin, Yu-Wing Tai', 'Summary': 'We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation\\n(RAG) that addresses the inherent ambiguities and reasoning challenges in\\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely on\\nend-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates\\na collaborative set of specialized AI agents: Planner, Step Definer, Extractor,\\nand QA Agents, each responsible for a distinct stage of the RAG pipeline. By\\ndecomposing tasks into subtasks such as query disambiguation, evidence\\nextraction, and answer synthesis, and enabling agents to communicate\\nintermediate reasoning via chain-of-thought prompting, MA-RAG progressively\\nrefines retrieval and synthesis while maintaining modular interpretability.\\nExtensive experiments on multi-hop and ambiguous QA benchmarks, including NQ,\\nHotpotQA, 2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly\\noutperforms standalone LLMs and existing RAG methods across all model scales.\\nNotably, even a small LLaMA3-8B model equipped with MA-RAG surpasses larger\\nstandalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\\nstate-of-the-art results on challenging multi-hop datasets. Ablation studies\\nreveal that both the planner and extractor agents are critical for multi-hop\\nreasoning, and that high-capacity models are especially important for the QA\\nagent to synthesize answers effectively. Beyond general-domain QA, MA-RAG\\ngeneralizes to specialized domains such as medical QA, achieving competitive\\nperformance against domain-specific models without any domain-specific\\nfine-tuning. Our results highlight the effectiveness of collaborative, modular\\nreasoning in retrieval-augmented systems: MA-RAG not only improves answer\\naccuracy and robustness but also provides interpretable intermediate reasoning\\nsteps, establishing a new paradigm for efficient and reliable multi-agent RAG.', 'entry_id': 'http://arxiv.org/abs/2505.20096v2', 'published_first_time': '2025-05-26', 'comment': None, 'journal_ref': None, 'doi': None, 'primary_category': 'cs.CL', 'categories': ['cs.CL', 'cs.AI'], 'links': ['http://arxiv.org/abs/2505.20096v2', 'http://arxiv.org/pdf/2505.20096v2']}, page_content='MA-RAG: MULTI-AGENT RETRIEVAL-AUGMENTED\\nGENERATION\\nVIA\\nCOLLABORATIVE\\nCHAIN-OF-\\nTHOUGHT REASONING\\nThang Nguyen & Peter Chin & Yu-Wing Tai\\nDartmouth College\\n{thangnv.th, peter.chin, yu-wing.tai}@dartmouth.edu\\nABSTRACT\\nWe present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Gener-\\nation (RAG) that addresses the inherent ambiguities and reasoning challenges in\\ncomplex information-seeking tasks. Unlike conventional RAG methods that rely\\non end-to-end fine-tuning or isolated component enhancements, MA-RAG orches-\\ntrates a collaborative set of specialized AI agents: Planner, Step Definer, Extrac-\\ntor, and QA Agents, each responsible for a distinct stage of the RAG pipeline.\\nBy decomposing tasks into subtasks such as query disambiguation, evidence ex-\\ntraction, and answer synthesis, and enabling agents to communicate intermedi-\\nate reasoning via chain-of-thought prompting, MA-RAG progressively refines re-\\ntrieval and synthesis while maintaining modular interpretability. Extensive exper-\\niments on multi-hop and ambiguous QA benchmarks, including NQ, HotpotQA,\\n2WikimQA, and TriviaQA, demonstrate that MA-RAG significantly outperforms\\nstandalone LLMs and existing RAG methods across all model scales. Notably,\\neven a small LLaMA3-8B model equipped with MA-RAG surpasses larger stan-\\ndalone LLMs, while larger variants (LLaMA3-70B and GPT-4o-mini) set new\\nstate-of-the-art results on challenging multi-hop datasets. Ablation studies reveal\\nthat both the planner and extractor agents are critical for multi-hop reasoning,\\nand that high-capacity models are especially important for the QA agent to syn-\\nthesize answers effectively. Beyond general-domain QA, MA-RAG generalizes\\nto specialized domains such as medical QA, achieving competitive performance\\nagainst domain-specific models without any domain-specific fine-tuning. Our re-\\nsults highlight the effectiveness of collaborative, modular reasoning in retrieval-\\naugmented systems: MA-RAG not only improves answer accuracy and robustness\\nbut also provides interpretable intermediate reasoning steps, establishing a new\\nparadigm for efficient and reliable multi-agent RAG1.\\n1\\nINTRODUCTION\\nRecent advances in natural language processing have driven the development of Retrieval-\\nAugmented Generation (RAG) models, which aim to enhance the factual accuracy and contextual\\nrelevance of generated text by integrating external knowledge sources (Lewis et al., 2020; Guu et al.,\\n2020; Izacard & Grave, 2021; Lin et al., 2024). These systems address core limitations of Large Lan-\\nguage Models (LLMs), such as outdated knowledge (Zhang et al., 2023b; Kasai et al., 2023) and\\npoor generalization to domain-specific queries (Siriwardhana et al., 2023; Xiong et al., 2024), by\\nretrieving top-k documents from an external corpus (Formal et al., 2022; Izacard et al., 2022; Wang\\net al., 2022a) to ground the model’s output in relevant evidence.\\nPrior research in RAG has largely concentrated on optimizing three key components—retrieval,\\naugmentation, and generation (Gao et al., 2024; Fan et al., 2024) (Figure 1(a)). Retrieval strate-\\ngies span sparse methods (Jones, 1972; Robertson & Zaragoza, 2009) and dense retrieval (Reimers\\n& Gurevych, 2019; Karpukhin et al., 2020), each with respective weaknesses such as lexical\\ngaps (Berger et al., 2000) or retrieval failure on out-of-distribution and multi-hop queries (Dai et al.,\\n1Our code is available at https://github.com/thangylvp/MA-RAG\\n1\\narXiv:2505.20096v2  [cs.CL]  11 Oct 2025\\nQuery\\nDocs\\nAnswer\\nDocs\\nAnswer\\nCoT\\nNotes\\nPost-process\\na) Vanilla RAG\\nStep 1\\nStep ...\\nCoT\\nSub-Query\\nQuery\\nDocs\\nNotes\\nCoT\\nQuery\\nSub-Answer\\nCoT\\nb) RAG with post-\\nprocessing retrieved docs\\nd) MA-RAG\\nQuery\\nDocs\\nAnswer\\nc) RAG with interleaving\\nretrieval and thoughts\\nAnswer\\nCoT\\nFigure 1: Architectural Comparison of MA-RAG and Prior RAG Methods. a) A naive RAG sys-\\ntem performs one-shot retrieval followed by direct answer generation. b) Enhanced systems incor-\\nporate post-retrieval processing such as document re-')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_retriever.invoke(\"Modular RAG vs Naive RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7d4c3",
   "metadata": {},
   "source": [
    "### 노드 작성\n",
    "\n",
    "#### 웹 검색 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 쿼리 변환 프롬프트\n",
    "search_instructions = \"\"\"분석가와 전문가 간의 대화가 제시됩니다.\n",
    "\n",
    "목표는 해당 대화와 관련된 검색 및/또는 웹 검색에 사용할 잘 구조화된 쿼리를 생성하는 것입니다.\n",
    "\n",
    "먼저 전체 대화를 분석하십시오.\n",
    "\n",
    "특히 분석가가 마지막에 제기한 질문에 주목하십시오.\n",
    "\n",
    "이 마지막 질문을 잘 구조화된 웹 검색 쿼리로 변환하십시오.\"\"\"\n",
    "\n",
    "\n",
    "def search_web(state: InterviewState):\n",
    "    \"\"\"웹 검색을 통한 문서 검색\"\"\"\n",
    "\n",
    "    llm_with_structured = llm.with_structured_output(SearchQuery)\n",
    "\n",
    "    response = llm_with_structured.invoke(\n",
    "        [(\"system\", search_instructions)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    results = web_search.invoke(response.search_query)\n",
    "    context = [\n",
    "        f'<Document source=\"web\" url=\"{doc[\"url\"]}\" title=\"{doc[\"title\"]}\">{doc[\"content\"]}</Document>'\n",
    "        for doc in results[\"results\"]\n",
    "    ]\n",
    "\n",
    "    return {\"context\": [*context]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9e12267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['<Document source=\"web\" url=\"https://dictionary.cambridge.org/ko/%EC%82%AC%EC%A0%84/%EC%98%81%EC%96%B4/crag\" title=\"영어로 crag의 뜻\">CRAG 의미, 정의, CRAG의 정의: 1. a high, rough mass of rock that sticks out from the land around it 2. a high, rough mass of rock…. 자세히 알아보기.</Document>',\n",
       "  '<Document source=\"web\" url=\"https://www.collinsdictionary.com/ko/dictionary/english/crag\" title=\"CRAG 정의 및 의미 | Collins 영어 사전\">carbon reduction action group or carbon rationing action group: a small association of citizens whose members attempt to reduce their environmental impact</Document>',\n",
       "  '<Document source=\"web\" url=\"https://www.lingq.com/ko/learn-english-online/translate/en/CRAG/\" title=\"CRAG | 한국어 번역과 뜻 | LingQ 사전\">언어 학습 앱 >; 온라인으로 English 배우기. crag. English에서 한국어로의 번역 및 의미. 영어. 한국어. CRAG. 암장. 다른 의미인기. 암장. crag 명사 험준한 바위 (</Document>']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_web({\"messages\": [(\"user\", \"CRAG에 대해서 설명해주세요.\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9959f7f",
   "metadata": {},
   "source": [
    "#### 논문 검색 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f25ee249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(state: InterviewState):\n",
    "    \"\"\"Arxiv 검색 노드\"\"\"\n",
    "\n",
    "    llm_with_structured = llm.with_structured_output(SearchQuery)\n",
    "\n",
    "    response = llm_with_structured.invoke(\n",
    "        [(\"system\", search_instructions)] + state[\"messages\"]\n",
    "    )\n",
    "\n",
    "    results = arxiv_retriever.invoke(\n",
    "        response.search_query,\n",
    "        load_max_docs=2,\n",
    "        load_all_available_meta=True,\n",
    "        get_full_documents=True,\n",
    "    )\n",
    "\n",
    "    context = [\n",
    "        f'<Document source=\"arxiv\" url=\"{doc.metadata[\"entry_id\"]}\" date=\"{doc.metadata.get(\"Published\", \"\")}\" authors=\"{doc.metadata.get(\"Authors\", \"\")}\"/>\\n<Title>\\n{doc.metadata[\"Title\"]}\\n</Title>\\n\\n<Summary>\\n{doc.metadata[\"Summary\"]}\\n</Summary>\\n\\n<Content>\\n{doc.page_content}\\n</Content>\\n</Document>'\n",
    "        for doc in results\n",
    "    ]\n",
    "\n",
    "    return {\"context\": [*context]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "606944ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': ['<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2502.19629v1\" date=\"2025-02-26\" authors=\"Tiffany J. Callahan, Nathaniel H. Park, Sara Capponi\"/>\\n<Title>\\nAgentic Mixture-of-Workflows for Multi-Modal Chemical Search\\n</Title>\\n\\n<Summary>\\nThe vast and complex materials design space demands innovative strategies to\\nintegrate multidisciplinary scientific knowledge and optimize materials\\ndiscovery. While large language models (LLMs) have demonstrated promising\\nreasoning and automation capabilities across various domains, their application\\nin materials science remains limited due to a lack of benchmarking standards\\nand practical implementation frameworks. To address these challenges, we\\nintroduce Mixture-of-Workflows for Self-Corrective Retrieval-Augmented\\nGeneration (CRAG-MoW) - a novel paradigm that orchestrates multiple agentic\\nworkflows employing distinct CRAG strategies using open-source LLMs. Unlike\\nprior approaches, CRAG-MoW synthesizes diverse outputs through an orchestration\\nagent, enabling direct evaluation of multiple LLMs across the same problem\\ndomain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical\\nreactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral\\nretrieval. Our results demonstrate that CRAG-MoWs achieve performance\\ncomparable to GPT-4o while being preferred more frequently in comparative\\nevaluations, highlighting the advantage of structured retrieval and multi-agent\\nsynthesis. By revealing performance variations across data types, CRAG-MoW\\nprovides a scalable, interpretable, and benchmark-driven approach to optimizing\\nAI architectures for materials discovery. These insights are pivotal in\\naddressing fundamental gaps in benchmarking LLMs and autonomous AI agents for\\nscientific applications.\\n</Summary>\\n\\n<Content>\\nAgentic Mixture-of-Workflows for Multi-Modal Chemical Search \\n \\n \\nTiffany J. Callahan1, Nathaniel H. Park1*, and Sara Capponi1 \\n1IBM Research–Almaden, 650 Harry Rd. San Jose, CA 95120  \\n \\n*Corresponding author. Email: npark@us.ibm.com \\n \\n \\nABSTRACT \\nThe vast and complex materials design space demands innovative strategies to integrate \\nmultidisciplinary scientific knowledge and optimize materials discovery. While large \\nlanguage models (LLMs) have demonstrated promising reasoning and automation \\ncapabilities across various domains, their application in materials science remains limited \\ndue to a lack of benchmarking standards and practical implementation frameworks. To \\naddress these challenges, we introduce Mixture-of-Workflows for Self-Corrective \\nRetrieval-Augmented Generation (CRAG-MoW)—a novel paradigm that orchestrates \\nmultiple agentic workflows employing distinct CRAG strategies using open-source LLMs. \\nUnlike prior approaches, CRAG-MoW synthesizes diverse outputs through an \\norchestration agent, enabling direct evaluation of multiple LLMs across the same problem \\ndomain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical \\nreactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral retrieval. \\nOur results demonstrate that CRAG-MoWs achieve performance comparable to GPT-4o \\nwhile being preferred more frequently in comparative evaluations, highlighting the \\nadvantage of structured retrieval and multi-agent synthesis. By revealing performance \\nvariations across data types, CRAG-MoW provides a scalable, interpretable, and \\nbenchmark-driven approach to optimizing AI architectures for materials discovery. These \\ninsights are pivotal in addressing fundamental gaps in benchmarking LLMs and \\nautonomous AI agents for scientific applications. \\n \\n \\nINTRODUCTION \\nThe vast size, high dimensionality, and complexity of the materials design space require \\nnew strategies for synthesizing and integrating multidisciplinary scientific knowledge. \\nSuch approaches are essential to drive advances in performance, cost-efficiency, and \\nsustainability [1]. Large language models (LLM), which are trained on large amounts of \\ndata and designed for human interaction, have demonstrated impressive reasoning \\nabilities in natural language processing [2–5]. Within the materials domain, LLMs have \\nbeen used to predict chemical properties [6–8], design new molecules [4, 9–12], automate \\nscientific coding [13, 14], develop AI agents [6, 15–17], extract and synthesize knowledge \\n[18, 19], and summarize and generate text [20]. Despite these successes, LLM adoption \\nin materials science lags behind other fields. This gap stems from a lack of standardized \\n \\n2\\nbenchmarks for validating LLM-based analyses, limited application to practical tasks, and \\nthe specialized expertise required for materials development [21–23].  \\n \\nThese challenges have led to increased interest in agentic workflows—LLM-driven \\nautonomous systems designed to perform complex reasoning, tool use, and multi-step \\ndecision-making [24]. Within the materials domain, agentic systems have been developed \\nto review the literature [25–27], implement routine chemical tasks [16, 21, 28–31] plan \\nexperiments [32–35], automate chemoinformatics analysis [36–39], and generate novel \\nhypotheses [40–42]. One of the most widely adopted implementations of agentic systems \\nis retrieval-augmented generation (RAG), which enhances LLM outputs by integrating \\ninformation retrieval techniques [25]. Rather than relying solely on pre-trained knowledge, \\nRAG dynamically retrieves and incorporates relevant external information, improving \\nresponse accuracy and contextual relevance. This capability is particularly valuable in \\nmaterials science, where access to domain-specific literature, experimental data, and \\nproperty databases is critical for precise predictions and reasoning. By leveraging RAG, \\nagentic workflows can provide more reliable and up-to-date insights, addressing key\\n</Content>\\n</Document>',\n",
       "  '<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2406.04744v2\" date=\"2024-11-01\" authors=\"Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla, Xiangsen Chen, Sajal Choudhary, Rongze Daniel Gui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong, Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan, Chenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang, Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah, Rakesh Wanga, Anuj Kumar, Wen-tau Yih, Xin Luna Dong\"/>\\n<Title>\\nCRAG -- Comprehensive RAG Benchmark\\n</Title>\\n\\n<Summary>\\nRetrieval-Augmented Generation (RAG) has recently emerged as a promising\\nsolution to alleviate Large Language Model (LLM)\\'s deficiency in lack of\\nknowledge. Existing RAG datasets, however, do not adequately represent the\\ndiverse and dynamic nature of real-world Question Answering (QA) tasks. To\\nbridge this gap, we introduce the Comprehensive RAG Benchmark (CRAG), a factual\\nquestion answering benchmark of 4,409 question-answer pairs and mock APIs to\\nsimulate web and Knowledge Graph (KG) search. CRAG is designed to encapsulate a\\ndiverse array of questions across five domains and eight question categories,\\nreflecting varied entity popularity from popular to long-tail, and temporal\\ndynamisms ranging from years to seconds. Our evaluation of this benchmark\\nhighlights the gap to fully trustworthy QA. Whereas most advanced LLMs achieve\\n<=34% accuracy on CRAG, adding RAG in a straightforward manner improves the\\naccuracy only to 44%. State-of-the-art industry RAG solutions only answer 63%\\nof questions without any hallucination. CRAG also reveals much lower accuracy\\nin answering questions regarding facts with higher dynamism, lower popularity,\\nor higher complexity, suggesting future research directions. The CRAG benchmark\\nlaid the groundwork for a KDD Cup 2024 challenge and attracted thousands of\\nparticipants and submissions. We commit to maintaining CRAG to serve research\\ncommunities in advancing RAG solutions and general QA solutions. CRAG is\\navailable at https://github.com/facebookresearch/CRAG/.\\n</Summary>\\n\\n<Content>\\nCRAG – Comprehensive RAG Benchmark\\nXiao Yang˚1, Kai Sun˚1, Hao Xin˚3, Yushi Sun˚3, Nikita Bhalla1, Xiangsen Chen4, Sajal\\nChoudhary1, Rongze Daniel Gui1, Ziran Will Jiang1, Ziyu Jiang4, Lingkun Kong1, Brian Moran1,\\nJiaqi Wang1, Yifan Ethan Xu1, An Yan1, Chenyu Yang4, Eting Yuan1, Hanwen Zha1, Nan Tang3,4,\\nLei Chen3,4, Nicolas Scheffer1, Yue Liu1, Nirav Shah1, Rakesh Wanga1, Anuj Kumar1, Wen-tau Yih2,\\nand Xin Luna Dong1\\n1Meta Reality Labs, 2 FAIR, Meta, 3 HKUST, 4 HKUST (GZ)\\nAbstract\\nRetrieval-Augmented Generation (RAG) has recently emerged as a promising solu-\\ntion to alleviate Large Language Model (LLM)’s deficiency in lack of knowledge.\\nExisting RAG datasets, however, do not adequately represent the diverse and dy-\\nnamic nature of real-world Question Answering (QA) tasks. To bridge this gap, we\\nintroduce the Comprehensive RAG Benchmark (CRAG), a factual question an-\\nswering benchmark of 4,409 question-answer pairs and mock APIs to simulate web\\nand Knowledge Graph (KG) search. CRAG is designed to encapsulate a diverse\\narray of questions across five domains and eight question categories, reflecting\\nvaried entity popularity from popular to long-tail, and temporal dynamisms ranging\\nfrom years to seconds. Our evaluation of this benchmark highlights the gap to\\nfully trustworthy QA. Whereas most advanced LLMs achieve ď 34% accuracy\\non CRAG, adding RAG in a straightforward manner improves the accuracy only\\nto 44%. State-of-the-art industry RAG solutions only answer 63% of questions\\nwithout any hallucination. CRAG also reveals much lower accuracy in answer-\\ning questions regarding facts with higher dynamism, lower popularity, or higher\\ncomplexity, suggesting future research directions. The CRAG benchmark laid the\\ngroundwork for a KDD Cup 2024 challenge and attracted thousands of participants\\nand submissions. We commit to maintaining CRAG to serve research communities\\nin advancing RAG solutions and general QA solutions. CRAG is available at\\nhttps://github.com/facebookresearch/CRAG/.\\n1\\nIntroduction\\nLarge Language Models (LLMs) have transformed the landscape of Natural Language Processing\\n(NLP) tasks, especially in Question Answering (QA) [20, 22, 38, 39]. Despite the advancements,\\nthe issue of hallucination persists as a significant challenge; LLMs may generate answers that lack\\nfactual accuracy or grounding [14,27,30,32]. Studies have shown that GPT-4’s accuracy in answering\\nquestions referring to slow-changing or fast-changing facts is below 15% [36]; even for stable (never-\\nchanging) facts, GPT-4’s accuracy in answering questions referring to torso-to-tail (less popular)\\nentities is below 35% [29]. Overcoming hallucinations thus becomes a priority in building reliable\\nQA systems [13,14].\\nRetrieval-Augmented Generation (RAG) [6,8,12,19] has recently emerged as a promising solution to\\nalleviate LLM’s deficiency in lack of knowledge and attracted a lot of attention from both academia\\nresearch and industry. Given a question, a RAG system searches external sources to retrieve relevant\\ninformation and then provides grounded answers [7,12,19] (see Figure 1 for an illustration). Despite\\n˚Equal contribution. Correspondence to: Xiao Yang (xiaoyangfb@meta.com).\\n38th Conference on Neural Information Processing Systems (NeurIPS 2024) Track on Datasets and Benchmarks.\\narXiv:2406.04744v2  [cs.CL]  1 Nov 2024\\nLLM\\nWhat is the gold \\nprice today?\\nGold price is at $1626.81 per \\nounce today Oct 21 2022.\\nGold price is at $2020.8 per \\nounce today Jan 28 2024.\\nDocuments\\nWeb \\nSearch\\nReal-time \\nAPIs\\nKnowledge \\nGraph\\nRetrieved \\nrelevant\\nknowledge\\nQuestion \\n(a) LLM Direct Generation\\n(b) RAG: Retrieved-Augmented \\nGeneration with LLM\\nFigure 1: QA using LLMs (a) without RAG vs. (b) with RAG.\\nits potential, RAG still faces many challenges, such as selecting the most relevant information,\\nreducing question answering latency, and synthesizing information to answer complex questions.\\nA comprehensive benchmark is currently missing to advance continued research efforts \\n</Content>\\n</Document>',\n",
       "  '<Document source=\"arxiv\" url=\"http://arxiv.org/abs/2409.15337v1\" date=\"2024-09-09\" authors=\"Jie Ouyang, Yucong Luo, Mingyue Cheng, Daoyu Wang, Shuo Yu, Qi Liu, Enhong Chen\"/>\\n<Title>\\nRevisiting the Solution of Meta KDD Cup 2024: CRAG\\n</Title>\\n\\n<Summary>\\nThis paper presents the solution of our team APEX in the Meta KDD CUP 2024:\\nCRAG Comprehensive RAG Benchmark Challenge. The CRAG benchmark addresses the\\nlimitations of existing QA benchmarks in evaluating the diverse and dynamic\\nchallenges faced by Retrieval-Augmented Generation (RAG) systems. It provides a\\nmore comprehensive assessment of RAG performance and contributes to advancing\\nresearch in this field. We propose a routing-based domain and dynamic adaptive\\nRAG pipeline, which performs specific processing for the diverse and dynamic\\nnature of the question in all three stages: retrieval, augmentation, and\\ngeneration. Our method achieved superior performance on CRAG and ranked 2nd for\\nTask 2&3 on the final competition leaderboard. Our implementation is available\\nat this link: https://github.com/USTCAGI/CRAG-in-KDD-Cup2024.\\n</Summary>\\n\\n<Content>\\nRevisiting the Solution of Meta KDD Cup 2024: CRAG\\nJie Ouyang\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nouyang_jie@mail.ustc.edu.cn\\nYucong Luo\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nprime666@mail.ustc.edu.cn\\nMingyue Cheng∗\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nmycheng@ustc.edu.cn\\nDaoyu Wang\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nwdy030428@mail.ustc.edu.cn\\nShuo Yu\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nyu12345@mail.ustc.edu.cn\\nQi Liu\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\nqiliuql@ustc.edu.cn\\nEnhong Chen\\nState Key Laboratory of Cognitive\\nIntelligence, University of Science and\\nTechnology of China\\nHefei, Anhui, China\\ncheneh@ustc.edu.cn\\nAbstract\\nThis paper presents the solution of our team APEX in the Meta KDD\\nCUP 2024: CRAG Comprehensive RAG Benchmark Challenge. The\\nCRAG benchmark addresses the limitations of existing QA bench-\\nmarks in evaluating the diverse and dynamic challenges faced by\\nRetrieval-Augmented Generation (RAG) systems. It provides a more\\ncomprehensive assessment of RAG performance and contributes\\nto advancing research in this field. We propose a routing-based do-\\nmain and dynamic adaptive RAG pipeline, which performs specific\\nprocessing for the diverse and dynamic nature of the question in all\\nthree stages: retrieval, augmentation, and generation. Our method\\nachieved superior performance on CRAG and ranked 2nd for Task\\n2&3 on the final competition leaderboard. Our implementation is\\navailable at this link: https://github.com/USTCAGI/CRAG-in-KDD-\\nCup2024.\\nCCS Concepts\\n• Information systems →Information retrieval.\\nKeywords\\nRetrieval-Augmented Generation, Large Language Model\\n1\\nIntroduction\\nLarge Language Models (LLMs) have revolutionized the landscape\\nof Natural Language Processing (NLP) tasks [5, 8, 10], particularly in\\nquestion answering (QA). Despite advances in LLMs, hallucination\\nremains a significant challenge, particularly for dynamic facts and\\ninformation about less prominent entities.\\nRetrieval-Augmented Generation (RAG) [9] has recently emerged\\nas a promising solution to mitigate LLMs’ knowledge deficiencies.\\n∗Mingyue Cheng is the corresponding author.\\nGiven a question, a RAG system queries external sources to re-\\ntrieve relevant information and subsequently provides grounded\\nanswers. Despite its potential, RAG continues to face numerous\\nchallenges, including the selection of the most relevant information,\\nthe reduction of question answering latency, and the synthesis of\\ninformation to address complex questions.\\nTo bridge this gap, Meta introduced the Comprehensive RAG\\nBenchmark (CRAG) [13], a factual question answering benchmark\\nof 4,409 question-answer pairs and Mock APIs to simulate web\\nand Knowledge Graph (KG) search, and hosted the KDD CUP 2024\\nChallenge.\\n1.1\\nDataset Description\\nThe CRAG contains two parts of data: the QA pairs and the content\\nfor retrieval.\\nQA pairs. The CRAG dataset contains a rich set of 4,409 QA\\npairs covering five domains: finance, sports, music, movie, and\\nopen domain, and eight types of questions. For the KDD CUP 2024\\nChallenge, the benchmark data were splited into three sets with\\nsimilar distributions: validation, public test, and private test at 30%,\\n30%, and 40%, respectively. In total, 2,706 examples from validation\\nand public test sets were shared.\\nThe dataset also reflects varied entity popularity from popular\\nto long-tail entities, and temporal spans ranging from seconds to\\nyears. Given the temporal nature of many questions, each question-\\nanswer pair is accompanied by an additional field denoted as \"query\\ntime.\" This temporal mark\\n</Content>\\n</Document>']}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_arxiv({\"messages\": [(\"user\", \"CRAG에 대해서 설명해주세요.\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fac6790",
   "metadata": {},
   "source": [
    "#### 답변 생성 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ce399",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_instructions = \"\"\"당신은 애널리스트에게 인터뷰를 받는 전문가입니다.\n",
    "애널리스트의 정보는 다음과 같습니다: \n",
    "{persona}\n",
    "\n",
    "당신의 목표는 인터뷰어가 제기한 질문에 답변하는 것입니다.\n",
    "\n",
    "질문에 답변할 때는 다음 맥락을 활용하십시오:\n",
    "{context}\n",
    "\n",
    "질문에 답변할 때는 다음 지침을 따르십시오:\n",
    "1. 맥락에 제공된 정보만 사용하십시오. \n",
    "2. 외부 정보를 도입하거나 컨텍스트에 명시적으로 언급된 내용을 넘어선 추측을 하지 마십시오.\n",
    "3. 컨텍스트에는 각 개별 문서의 주제별 출처가 포함되어 있습니다.\n",
    "4. 답변에서 관련 진술 옆에 해당 출처를 포함하십시오. 예를 들어 출처 #1의 경우 [1]을 사용하십시오.\n",
    "5. 답변 하단에 출처를 순서대로 나열하십시오. [1] 출처 1, [2] 출처 2, 등\n",
    "6. 출처가 다음과 같은 경우: <Document url=\"assistant/docs/llama3_1.pdf\" page=\"7\" />' \n",
    "    다음처럼 기재하십시오: [1] assistant/docs/llama3_1.pdf, 7 페이지\n",
    "\n",
    "인용 시 괄호 추가 및 Document source 서두 문구를 생략하십시오.\"\"\"\n",
    "\n",
    "\n",
    "def generate_answer(state: InterviewState):\n",
    "    \"\"\"질문에 대한 답변 노드\"\"\"\n",
    "\n",
    "    analyst = state[\"analyst\"]\n",
    "    context = state[\"context\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    system_message = answer_instructions.format(\n",
    "        persona=analyst.persona,\n",
    "        context=context,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe5c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation-introduction-to-langgraph (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
