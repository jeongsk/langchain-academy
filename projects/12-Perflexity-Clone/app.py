"""
Perplexity Clone - Streamlit UI
LangGraph ê¸°ë°˜ ì›¹ ê²€ìƒ‰ Agent UI
"""

import uuid

import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import AIMessage, HumanMessage
from langgraph.checkpoint.sqlite import SqliteSaver
from studio.graph import create_perplexity_graph

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Perplexity Clone",
    page_icon="ğŸ”",
    layout="wide",
)

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ” Perplexity Clone")
st.markdown(
    """
    LangGraph ê¸°ë°˜ **ì›¹ ê²€ìƒ‰ Agent**ì…ë‹ˆë‹¤.
    ì§ˆë¬¸í•˜ì‹œë©´ ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ **ì¶œì²˜ì™€ í•¨ê»˜** ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

if "graph" not in st.session_state:
    st.session_state.graph = None

if "graph_config" not in st.session_state:
    st.session_state.graph_config = {
        "model_name": "gpt-4.1-mini",
        "max_results": 3,
        "topic": "general",
        "include_domains": [],
        "exclude_domains": [],
    }

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.session_state.thread_id = str(uuid.uuid4())
        st.rerun()

    st.divider()

    # ëª¨ë¸ ì„¤ì •
    st.subheader("ğŸ¤– ëª¨ë¸ ì„¤ì •")
    model_name = st.selectbox(
        "LLM ëª¨ë¸",
        ["gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano"],
        index=1,
        key="model_select",
    )

    # ê²€ìƒ‰ ì„¤ì •
    st.subheader("ğŸ” ê²€ìƒ‰ ì„¤ì •")
    max_results = st.slider(
        "ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
        min_value=1,
        max_value=10,
        value=3,
        key="max_results_slider",
    )

    topic = st.selectbox("ê²€ìƒ‰ ì£¼ì œ", ["general", "news"], index=0, key="topic_select")

    # ë„ë©”ì¸ í•„í„°ë§
    st.subheader("ğŸŒ ë„ë©”ì¸ í•„í„°ë§")

    # í¬í•¨í•  ë„ë©”ì¸
    st.write("**í¬í•¨í•  ë„ë©”ì¸**")
    new_include_domain = st.text_input(
        "ë„ë©”ì¸ ì¶”ê°€ (ì˜ˆ: github.com)",
        key="new_include_domain",
        placeholder="github.com",
    )

    if st.button("â• ì¶”ê°€", key="add_include_domain"):
        if (
            new_include_domain
            and new_include_domain
            not in st.session_state.graph_config["include_domains"]
        ):
            st.session_state.graph_config["include_domains"].append(new_include_domain)
            st.rerun()

    # ë“±ë¡ëœ í¬í•¨ ë„ë©”ì¸ ëª©ë¡
    if st.session_state.graph_config["include_domains"]:
        for idx, domain in enumerate(st.session_state.graph_config["include_domains"]):
            col1, col2 = st.columns([4, 1])
            with col1:
                st.text(f"âœ“ {domain}")
            with col2:
                if st.button("âŒ", key=f"del_include_{idx}"):
                    st.session_state.graph_config["include_domains"].pop(idx)
                    st.rerun()

    st.divider()

    # ì œì™¸í•  ë„ë©”ì¸
    st.write("**ì œì™¸í•  ë„ë©”ì¸**")
    new_exclude_domain = st.text_input(
        "ë„ë©”ì¸ ì¶”ê°€ (ì˜ˆ: wikipedia.org)",
        key="new_exclude_domain",
        placeholder="wikipedia.org",
    )

    if st.button("â• ì¶”ê°€", key="add_exclude_domain"):
        if (
            new_exclude_domain
            and new_exclude_domain
            not in st.session_state.graph_config["exclude_domains"]
        ):
            st.session_state.graph_config["exclude_domains"].append(new_exclude_domain)
            st.rerun()

    # ë“±ë¡ëœ ì œì™¸ ë„ë©”ì¸ ëª©ë¡
    if st.session_state.graph_config["exclude_domains"]:
        for idx, domain in enumerate(st.session_state.graph_config["exclude_domains"]):
            col1, col2 = st.columns([4, 1])
            with col1:
                st.text(f"âœ“ {domain}")
            with col2:
                if st.button("âŒ", key=f"del_exclude_{idx}"):
                    st.session_state.graph_config["exclude_domains"].pop(idx)
                    st.rerun()

    st.divider()

    # ê·¸ë˜í”„ ìƒì„±/ì—…ë°ì´íŠ¸ ë²„íŠ¼
    if st.button("âœ… ì„¤ì • ì ìš©", type="primary", use_container_width=True):
        with st.spinner("ê·¸ë˜í”„ ìƒì„± ì¤‘..."):
            st.session_state.graph_config.update(
                {
                    "model_name": model_name,
                    "max_results": max_results,
                    "topic": topic,
                }
            )

            # ê·¸ë˜í”„ ìƒì„±
            st.session_state.graph = create_perplexity_graph(
                model_name=st.session_state.graph_config["model_name"],
                max_results=st.session_state.graph_config["max_results"],
                topic=st.session_state.graph_config["topic"],
                include_domains=st.session_state.graph_config["include_domains"]
                or None,
                exclude_domains=st.session_state.graph_config["exclude_domains"]
                or None,
                checkpointer=SqliteSaver.from_conn_string(":memory:"),
            )
            st.success("âœ… ì„¤ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!")

    st.divider()
    st.caption("Made with LangGraph ğŸ¦œğŸ”—")


# ì´ì „ ëŒ€í™” í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


# ì‚¬ìš©ì ì…ë ¥
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ê·¸ë˜í”„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°
    if st.session_state.graph is None:
        st.warning("âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ 'âœ… ì„¤ì • ì ìš©' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(user_input)

        # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_input})

        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ğŸ” ê²€ìƒ‰ ì¤‘..."):
                # ì‘ë‹µ ì»¨í…Œì´ë„ˆ
                response_container = st.empty()
                search_status_container = st.container()

                # ê·¸ë˜í”„ ì‹¤í–‰ ì„¤ì •
                config = {"configurable": {"thread_id": st.session_state.thread_id}}

                # ì…ë ¥ ë©”ì‹œì§€
                input_messages = {"messages": [HumanMessage(content=user_input)]}

                try:
                    # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
                    full_response = ""
                    tool_calls_made = []

                    for event in st.session_state.graph.stream(
                        input_messages, config, stream_mode="values"
                    ):
                        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ì¶œ
                        if "messages" in event:
                            last_message = event["messages"][-1]

                            # AI ë©”ì‹œì§€ì¸ ê²½ìš°
                            if isinstance(last_message, AIMessage):
                                # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš°
                                if (
                                    hasattr(last_message, "tool_calls")
                                    and last_message.tool_calls
                                ):
                                    for tool_call in last_message.tool_calls:
                                        if tool_call not in tool_calls_made:
                                            tool_calls_made.append(tool_call)
                                            with search_status_container:
                                                st.info(
                                                    f"ğŸ” ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘: `{tool_call['name']}`"
                                                )

                                # ìµœì¢… ì‘ë‹µ
                                if last_message.content:
                                    full_response = last_message.content
                                    response_container.markdown(full_response)

                    # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
                    st.session_state.messages.append(
                        {"role": "assistant", "content": full_response}
                    )

                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.exception(e)


# í•˜ë‹¨ ì •ë³´
st.divider()
with st.expander("â„¹ï¸ ì‚¬ìš© ë°©ë²•"):
    st.markdown("""
    ### ì‚¬ìš© ë°©ë²•

    1. **ì„¤ì • ì ìš©**: ì‚¬ì´ë“œë°”ì—ì„œ ì›í•˜ëŠ” ì„¤ì •ì„ ì„ íƒí•˜ê³  'âœ… ì„¤ì • ì ìš©' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.
    2. **ì§ˆë¬¸ ì…ë ¥**: í•˜ë‹¨ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.
    3. **ì‘ë‹µ í™•ì¸**: AIê°€ ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¶œì²˜ì™€ í•¨ê»˜ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

    ### ì£¼ìš” ê¸°ëŠ¥

    - **ì›¹ ê²€ìƒ‰**: Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰
    - **ì¶œì²˜ í‘œì‹œ**: ë‹µë³€ì— ì‚¬ìš©ëœ ëª¨ë“  ì¶œì²˜ë¥¼ ë²ˆí˜¸ì™€ í•¨ê»˜ í‘œì‹œ
    - **ë©€í‹°í„´ ëŒ€í™”**: ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ì—°ì†ì ì¸ ì§ˆë¬¸ ì§€ì›
    - **ë„ë©”ì¸ í•„í„°ë§**: íŠ¹ì • ë„ë©”ì¸ë§Œ í¬í•¨í•˜ê±°ë‚˜ ì œì™¸í•  ìˆ˜ ìˆìŒ

    ### ì˜ˆì‹œ ì§ˆë¬¸

    - "2024ë…„ AI íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
    - "LangGraphì™€ LangChainì˜ ì°¨ì´ì ì€?"
    - "ìµœê·¼ OpenAIì˜ ìƒˆë¡œìš´ ëª¨ë¸ ì†Œì‹ì€?"
    """)

with st.expander("ğŸ”§ í˜„ì¬ ì„¤ì •"):
    st.json(st.session_state.graph_config)
