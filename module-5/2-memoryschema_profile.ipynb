{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-5/memoryschema_profile.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/59970910-lesson-3-memory-schema-profile)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 프로필 스키마를 사용하는 챗봇\n",
                "\n",
                "## 복습\n",
                "\n",
                "우리는 장기 기억을 저장하고 검색하는 방법으로 [LangGraph 메모리 스토어](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)를 소개했습니다.\n",
                "\n",
                "또한 `단기 (스레드 내)` 메모리와 `장기 (스레드 간)` 메모리를 모두 사용하는 간단한 챗봇을 만들었습니다.\n",
                "\n",
                "이 챗봇은 사용자와 대화하는 중에 실시간으로[\"in the hot path\"](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories) 장기 [의미 기억(semantic memory)](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory)(사용자에 대한 사실)을 저장했습니다.\n",
                "\n",
                "## 목표\n",
                "\n",
                "이전 챗봇은 메모리를 문자열로 저장했습니다. 하지만 실제로는 메모리에 구조를 부여하는 것이 더 유용할 때가 많습니다.\n",
                "\n",
                "예를 들어, 메모리는 [지속적으로 업데이트되는 단일 스키마](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)가 될 수 있습니다.\n",
                "\n",
                "이번 예제에서는 이것을 단일 사용자 프로필로 만들어 보겠습니다.\n",
                "\n",
                "챗봇을 확장하여 의미 기억을 단일 [사용자 프로필](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)에 저장하도록 만들 것입니다.\n",
                "\n",
                "또한, 새로운 정보로 이 스키마를 업데이트하기 위해 [Trustcall](https://github.com/hinthornw/trustcall) 라이브러리를 소개할 것입니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture --no-stderr\n",
                "\n",
                "%pip install -U langchain_openai langgraph trustcall langchain_core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv(\"../.env\", override=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import getpass\n",
                "\n",
                "\n",
                "def _set_env(var: str):\n",
                "    env_value = os.environ.get(var)\n",
                "    if not env_value:\n",
                "        env_value = getpass.getpass(f\"{var}: \")\n",
                "\n",
                "    os.environ[var] = env_value"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "_set_env(\"LANGSMITH_API_KEY\")\n",
                "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
                "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 사용자 프로필 스키마 정의\n",
                "\n",
                "파이썬에는 TypedDict, 딕셔너리, JSON, [Pydantic](https://docs.pydantic.dev/latest/)과 같이 [구조화된 데이터](https://python.langchain.com/docs/concepts/structured_outputs/#schema-definition)를 위한 다양한 타입이 있습니다.\n",
                "\n",
                "먼저 TypedDict를 사용하여 사용자 프로필 스키마를 정의해 보겠습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import TypedDict, List\n",
                "\n",
                "\n",
                "class UserProfile(TypedDict):\n",
                "    \"\"\"타입이 지정된 필드를 가진 사용자 프로필 스키마\"\"\"\n",
                "\n",
                "    user_name: str  # 사용자가 선호하는 이름\n",
                "    interests: List[str]  # 사용자의 관심사 목록"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 스키마를 저장소에 저장하기\n",
                "\n",
                "[LangGraph 저장소](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)는 모든 파이썬 딕셔너리를 `value`로 받습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'user_name': '랜스', 'interests': ['자전거 타기', '기술', '커피']}"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# TypedDict 인스턴스\n",
                "user_profile: UserProfile = {\n",
                "    \"user_name\": \"랜스\",\n",
                "    \"interests\": [\"자전거 타기\", \"기술\", \"커피\"],\n",
                "}\n",
                "user_profile"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[put](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put) 메서드를 사용하여 TypedDict를 스토어에 저장합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "import uuid\n",
                "from langgraph.store.memory import InMemoryStore\n",
                "\n",
                "# 인메모리 저장소 초기화\n",
                "in_memory_store = InMemoryStore()\n",
                "\n",
                "# 저장할 메모리의 네임스페이스\n",
                "user_id = \"1\"\n",
                "namespace_for_memory = (user_id, \"memory\")\n",
                "\n",
                "# 네임스페이스에 메모리를 키와 값으로 저장\n",
                "key = \"user_profile\"\n",
                "value = user_profile\n",
                "in_memory_store.put(namespace_for_memory, key, value)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search)를 사용하여 네임스페이스로 저장소에서 객체를 검색합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': {'user_name': '랜스', 'interests': ['자전거 타기', '기술', '커피']}, 'created_at': '2025-10-02T08:02:49.497091+00:00', 'updated_at': '2025-10-02T08:02:49.497094+00:00', 'score': None}\n"
                    ]
                }
            ],
            "source": [
                "# 검색\n",
                "for m in in_memory_store.search(namespace_for_memory):\n",
                "    print(m.dict())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "또한 [get](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get)을 사용하여 네임스페이스와 키로 특정 객체를 검색할 수도 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'user_name': '랜스', 'interests': ['자전거 타기', '기술', '커피']}"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 네임스페이스와 키로 메모리 가져오기\n",
                "profile = in_memory_store.get(namespace_for_memory, \"user_profile\")\n",
                "profile.value"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 프로필 스키마를 사용하는 챗봇\n",
                "\n",
                "이제 메모리에 대한 스키마를 지정하고 스토어에 저장하는 방법을 알게 되었습니다.\n",
                "\n",
                "그렇다면, 이 특정 스키마에 맞춰 어떻게 메모리를 *생성*할 수 있을까요?\n",
                "\n",
                "우리가 만드는 챗봇에서는 [사용자와의 채팅으로부터 메모리를 생성](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)하고자 합니다.\n",
                "\n",
                "바로 이럴 때 [구조화된 출력(structured outputs)](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage)이라는 개념이 유용합니다.\n",
                "\n",
                "LangChain의 [채팅 모델](https://python.langchain.com/docs/concepts/chat_models/) 인터페이스에는 구조화된 출력을 강제하는 [`with_structured_output`](https://www.google.com/search?q=%5Bhttps://python.langchain.com/docs/concepts/structured_outputs/%23recommended-usage%5D\\(https://python.langchain.com/docs/concepts/structured_outputs/%23recommended-usage\\)) 메서드가 있습니다.\n",
                "\n",
                "이 기능은 출력이 특정 스키마를 따르도록 강제하고, 그 결과를 자동으로 파싱해주기 때문에 유용합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "_set_env(\"OPENAI_API_KEY\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "생성한 `UserProfile` 스키마를 `with_structured_output` 메서드에 전달해 보겠습니다.\n",
                "\n",
                "그런 다음 [메시지](https://python.langchain.com/docs/concepts/messages/) 목록으로 채팅 모델을 호출하여 스키마를 따르는 구조화된 출력을 얻을 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'user_name': '랜스', 'interests': ['자전거 타기']}"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from pydantic import BaseModel, Field\n",
                "from langchain_core.messages import HumanMessage\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "# 모델 초기화\n",
                "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
                "\n",
                "# 스키마를 모델에 바인딩\n",
                "model_with_structure = model.with_structured_output(UserProfile)\n",
                "\n",
                "# 스키마와 일치하는 구조화된 출력을 생성하기 위해 모델 호출\n",
                "structured_output = model_with_structure.invoke(\n",
                "    [HumanMessage(\"제 이름은 랜스입니다. 자전거 타는 걸 좋아합니다.\")]\n",
                ")\n",
                "structured_output"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이제 이것을 우리 챗봇과 함께 사용해 봅시다.\n",
                "\n",
                "이는 `write_memory` 함수에 약간의 변경만 필요합니다.\n",
                "\n",
                "위에서 정의한 `model_with_structure`를 사용하여 스키마와 일치하는 프로필을 생성합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image, display\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langgraph.graph import StateGraph, MessagesState, START, END\n",
                "from langgraph.store.base import BaseStore\n",
                "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
                "from langchain_core.runnables.config import RunnableConfig\n",
                "\n",
                "# 챗봇 지침\n",
                "MODEL_SYSTEM_MESSAGE = \"\"\"당신은 사용자에 대한 정보를 제공하는 기억력을 가진 유용한 어시스턴트입니다.\n",
                "이 사용자에 대한 기억이 있다면, 그것을 사용하여 응답을 개인화하세요.\n",
                "여기 기억이 있습니다 (비어 있을 수 있습니다): {memory}\"\"\"\n",
                "\n",
                "# 채팅 기록과 기존 메모리에서 새 메모리 생성\n",
                "CREATE_MEMORY_INSTRUCTION = \"\"\"사용자의 채팅 기록을 기반으로 사용자 프로필 메모리를 생성하거나 업데이트하세요.\n",
                "이것은 장기 기억을 위해 저장될 것입니다. 기존 메모리가 있다면 간단히 업데이트하세요.\n",
                "여기 기존 메모리가 있습니다 (비어 있을 수 있습니다): {memory}\"\"\"\n",
                "\n",
                "\n",
                "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
                "    \"\"\"저장소에서 메모리를 로드하고 이를 사용하여 챗봇의 응답을 개인화합니다.\"\"\"\n",
                "    # 설정에서 사용자 ID 가져오기\n",
                "    user_id = config[\"configurable\"][\"user_id\"]\n",
                "\n",
                "    # 저장소에서 메모리 검색\n",
                "    namespace = (\"memory\", user_id)\n",
                "    existing_memory = store.get(namespace, \"user_memory\")\n",
                "\n",
                "    # 시스템 프롬프트를 위한 메모리 형식 지정\n",
                "    if existing_memory and existing_memory.value:\n",
                "        memory_dict = existing_memory.value\n",
                "        formatted_memory = (\n",
                "            f\"이름: {memory_dict.get('user_name', '알 수 없음')}\\n\"\n",
                "            f\"관심사: {', '.join(memory_dict.get('interests', []))}\"\n",
                "        )\n",
                "    else:\n",
                "        formatted_memory = None\n",
                "\n",
                "    # 시스템 프롬프트에서 메모리 형식 지정\n",
                "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
                "\n",
                "    # 메모리와 채팅 기록을 사용하여 응답\n",
                "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
                "\n",
                "    return {\"messages\": response}\n",
                "\n",
                "\n",
                "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
                "    \"\"\"채팅 기록을 검토하고 저장소에 메모리를 저장합니다.\"\"\"\n",
                "\n",
                "    # 설정에서 사용자 ID 가져오기\n",
                "    user_id = config[\"configurable\"][\"user_id\"]\n",
                "\n",
                "    # 저장소에서 기존 메모리 검색\n",
                "    namespace = (\"memory\", user_id)\n",
                "    existing_memory = store.get(namespace, \"user_memory\")\n",
                "\n",
                "    # 시스템 프롬프트를 위한 메모리 형식 지정\n",
                "    if existing_memory and existing_memory.value:\n",
                "        memory_dict = existing_memory.value\n",
                "        formatted_memory = (\n",
                "            f\"이름: {memory_dict.get('user_name', '알 수 없음')}\\n\"\n",
                "            f\"관심사: {', '.join(memory_dict.get('interests', []))}\"\n",
                "        )\n",
                "    else:\n",
                "        formatted_memory = None\n",
                "\n",
                "    # 지침에서 기존 메모리 형식 지정\n",
                "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
                "\n",
                "    # 스키마와 일치하는 구조화된 출력을 생성하기 위해 모델 호출\n",
                "    new_memory = model_with_structure.invoke(\n",
                "        [SystemMessage(content=system_msg)] + state[\"messages\"]\n",
                "    )\n",
                "\n",
                "    # 기존 사용자 프로필 메모리를 덮어씁니다.\n",
                "    key = \"user_memory\"\n",
                "    store.put(namespace, key, new_memory)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<IPython.core.display.Image object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# 그래프 정의\n",
                "builder = StateGraph(MessagesState)\n",
                "builder.add_node(\"call_model\", call_model)\n",
                "builder.add_node(\"write_memory\", write_memory)\n",
                "\n",
                "builder.set_entry_point(\"call_model\")\n",
                "builder.add_edge(\"call_model\", \"write_memory\")\n",
                "builder.set_finish_point(\"write_memory\")\n",
                "\n",
                "# 장기(스레드 간) 메모리를 위한 저장소\n",
                "across_thread_memory = InMemoryStore()\n",
                "\n",
                "# 단기(스레드 내) 메모리를 위한 체크포인터\n",
                "within_thread_memory = MemorySaver()\n",
                "\n",
                "# 체크포인터와 저장소를 사용하여 그래프 컴파일\n",
                "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
                "\n",
                "# 보기\n",
                "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "안녕하세요, 제 이름은 Lance이고 샌프란시스코 주변에서 자전거 타는 것과 빵집에서 먹는 것을 좋아합니다.\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "안녕하세요, Lance! 샌프란시스코는 자전거 타기에 정말 멋진 장소죠. 특히 경치가 아름다운 곳이 많아서 더욱 즐거울 것 같아요. 그리고 빵집에서 맛있는 빵을 먹는 것도 큰 즐거움이죠. 혹시 샌프란시스코에서 추천할 만한 자전거 경로나 빵집이 있나요?\n"
                    ]
                }
            ],
            "source": [
                "# 단기(스레드 내) 메모리를 위해 스레드 ID를 제공합니다.\n",
                "# 장기(스레드 간) 메모리를 위해 사용자 ID를 제공합니다.\n",
                "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
                "\n",
                "# 사용자 입력\n",
                "input_messages = [\n",
                "    HumanMessage(\n",
                "        content=\"안녕하세요, 제 이름은 Lance이고 샌프란시스코 주변에서 자전거 타는 것과 빵집에서 먹는 것을 좋아합니다.\"\n",
                "    )\n",
                "]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream(\n",
                "    {\"messages\": input_messages},\n",
                "    config,\n",
                "    stream_mode=\"values\",\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "저장소의 메모리를 확인해 봅시다.\n",
                "\n",
                "메모리가 우리 스키마와 일치하는 딕셔너리임을 알 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'user_name': 'Lance',\n",
                            " 'interests': ['cycling around San Francisco', 'eating at bakeries']}"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 저장할 메모리의 네임스페이스\n",
                "user_id = \"1\"\n",
                "namespace = (\"memory\", user_id)\n",
                "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
                "existing_memory.value"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 어떤 경우에 실패할 수 있을까요?\n",
                "\n",
                "[`with_structured_output`](https://www.google.com/search?q=%5Bhttps://python.langchain.com/docs/concepts/structured_outputs/%23recommended-usage)은 매우 유용하지만, 더 복잡한 스키마로 작업하는 경우에는 어떻게 될까요?\n",
                "\n",
                "더 복잡한 스키마의 예시가 [여기](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema)에 있으며, 아래에서 테스트해 보겠습니다.\n",
                "\n",
                "이것은 사용자의 커뮤니케이션 및 트러스트 폴(trust fall)에 대한 선호도를 설명하는 [Pydantic](https://docs.pydantic.dev/latest/) 모델입니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List, Optional\n",
                "\n",
                "\n",
                "class OutputFormat(BaseModel):\n",
                "    preference: str\n",
                "    sentence_preference_revealed: str\n",
                "\n",
                "\n",
                "class TelegramPreferences(BaseModel):\n",
                "    preferred_encoding: Optional[List[OutputFormat]] = None\n",
                "    favorite_telegram_operators: Optional[List[OutputFormat]] = None\n",
                "    preferred_telegram_paper: Optional[List[OutputFormat]] = None\n",
                "\n",
                "\n",
                "class MorseCode(BaseModel):\n",
                "    preferred_key_type: Optional[List[OutputFormat]] = None\n",
                "    favorite_morse_abbreviations: Optional[List[OutputFormat]] = None\n",
                "\n",
                "\n",
                "class Semaphore(BaseModel):\n",
                "    preferred_flag_color: Optional[List[OutputFormat]] = None\n",
                "    semaphore_skill_level: Optional[List[OutputFormat]] = None\n",
                "\n",
                "\n",
                "class TrustFallPreferences(BaseModel):\n",
                "    preferred_fall_height: Optional[List[OutputFormat]] = None\n",
                "    trust_level: Optional[List[OutputFormat]] = None\n",
                "    preferred_catching_technique: Optional[List[OutputFormat]] = None\n",
                "\n",
                "\n",
                "class CommunicationPreferences(BaseModel):\n",
                "    telegram: TelegramPreferences\n",
                "    morse_code: MorseCode\n",
                "    semaphore: Semaphore\n",
                "\n",
                "\n",
                "class UserPreferences(BaseModel):\n",
                "    communication_preferences: CommunicationPreferences\n",
                "    trust_fall_preferences: TrustFallPreferences\n",
                "\n",
                "\n",
                "class TelegramAndTrustFallPreferences(BaseModel):\n",
                "    pertinent_user_preferences: UserPreferences"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이제 `with_structured_output` 메서드를 사용하여 이 스키마의 추출을 시도해 보겠습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pydantic import ValidationError\n",
                "\n",
                "# 스키마를 모델에 바인딩\n",
                "model_with_structure = model.with_structured_output(TelegramAndTrustFallPreferences)\n",
                "\n",
                "# 대화\n",
                "conversation = \"\"\"교환원: 전보를 어떻게 도와드릴까요, 손님?\n",
                "고객: 신뢰 낙하 운동에 대한 메시지를 보내야 합니다.\n",
                "교환원: 알겠습니다. 모스 부호인가요, 아니면 표준 인코딩인가요?\n",
                "고객: 모스 부호로 부탁합니다. 스트레이트 키를 사용하는 것을 좋아하거든요.\n",
                "교환원: 훌륭합니다. 메시지가 무엇인가요?\n",
                "고객: 더 높은 낙하에 준비되었고, 잡는 데는 다이아몬드 포메이션을 선호한다고 전해주세요.\n",
                "교환원: 완료되었습니다. 이 대담한 메시지에 저희 \\\"데어데블\\\" 용지를 사용할까요?\n",
                "고객: 완벽해요! 가장 빠른 비둘기 전송으로 보내주세요.\n",
                "교환원: 한 시간 안에 도착할 겁니다, 손님.\"\"\"\n",
                "\n",
                "# 모델 호출\n",
                "try:\n",
                "    model_with_structure.invoke(f\"\"\"다음 대화에서 선호도를 추출하세요:\n",
                "    <convo>\n",
                "    {conversation}\n",
                "    </convo>\"\"\")\n",
                "except ValidationError as e:\n",
                "    print(e)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`gpt-4o`와 같은 고성능 모델을 사용하더라도, 더 복잡한 스키마를 단순하게 추출하려고 하면 실패하기 쉽습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 프로필 스키마 생성 및 업데이트를 위한 Trustcall\n",
                "\n",
                "보시다시피, 스키마 작업은 까다로울 수 있습니다.\n",
                "\n",
                "복잡한 스키마는 추출하기 어려울 수 있습니다.\n",
                "\n",
                "또한, 간단한 스키마를 업데이트하는 것조차 어려울 수 있습니다.\n",
                "\n",
                "위에서 만든 챗봇을 생각해 봅시다.\n",
                "\n",
                "새로운 메모리를 저장하기로 할 때마다 프로필 스키마를 *처음부터* 다시 생성했습니다.\n",
                "\n",
                "이는 스키마에 매번 다시 생성해야 할 정보가 많이 포함되어 있는 경우 모델 토큰을 낭비할 수 있으므로 비효율적입니다.\n",
                "\n",
                "더 나쁜 것은, 프로필을 처음부터 다시 생성할 때 정보가 손실될 수 있다는 점입니다.\n",
                "\n",
                "이러한 문제를 해결하는 것이 바로 [TrustCall](https://github.com/hinthornw/trustcall)의 동기입니다!\n",
                "\n",
                "이것은 LangChain 팀의 [Will Fu-Hinthorn](https://github.com/hinthornw)이 개발한 JSON 스키마 업데이트를 위한 오픈 소스 라이브러리입니다.\n",
                "\n",
                "이 라이브러리는 바로 메모리 작업 중에 겪는 이러한 어려움에서 영감을 얻었습니다.\n",
                "\n",
                "먼저, 이 [메시지](https://python.langchain.com/docs/concepts/messages/) 목록에서 TrustCall을 사용하여 간단하게 추출하는 방법을 보여드리겠습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 대화\n",
                "conversation = [\n",
                "    HumanMessage(content=\"안녕하세요, 저는 Lance입니다.\"),\n",
                "    AIMessage(content=\"만나서 반가워요, Lance.\"),\n",
                "    HumanMessage(content=\"저는 샌프란시스코 주변에서 자전거 타는 것을 정말 좋아해요.\"),\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`create_extractor`를 사용할 때, 모델과 함께 우리의 스키마를 [tool(도구)](https://python.langchain.com/docs/concepts/tools/)로 전달합니다.\n",
                "\n",
                "TrustCall에서는 다양한 방법으로 스키마를 제공할 수 있습니다.\n",
                "\n",
                "예를 들어, JSON 객체/파이썬 딕셔너리 또는 Pydantic 모델을 전달할 수 있습니다.\n",
                "\n",
                "내부적으로, TrustCall은 입력된 [메시지](https://python.langchain.com/docs/concepts/messages/) 목록으로부터 [구조화된 출력](https://python.langchain.com/docs/concepts/structured_outputs/)을 생성하기 위해 [tool calling(도구 호출)](https://python.langchain.com/docs/concepts/tool_calling/)을 사용합니다.\n",
                "\n",
                "Trustcall이 [구조화된 출력](https://python.langchain.com/docs/concepts/structured_outputs/)을 생성하도록 강제하려면, `tool_choice` 인자에 스키마 이름을 포함시키면 됩니다.\n",
                "\n",
                "위 대화를 사용하여 추출기를 호출할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from trustcall import create_extractor\n",
                "\n",
                "\n",
                "# 스키마\n",
                "class UserProfile(BaseModel):\n",
                "    \"\"\"타입이 지정된 필드를 가진 사용자 프로필 스키마\"\"\"\n",
                "\n",
                "    user_name: str = Field(description=\"사용자가 선호하는 이름\")\n",
                "    interests: List[str] = Field(description=\"사용자의 관심사 목록\")\n",
                "\n",
                "\n",
                "# 모델 초기화\n",
                "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
                "\n",
                "# 추출기 생성\n",
                "trustcall_extractor = create_extractor(\n",
                "    model,\n",
                "    tools=[UserProfile],\n",
                "    tool_choice=\"UserProfile\",  # UserProfile 도구 사용을 강제합니다.\n",
                ")\n",
                "\n",
                "# 지침\n",
                "system_msg = \"다음 대화에서 사용자 프로필을 추출하세요.\"\n",
                "\n",
                "# 추출기 호출\n",
                "result = trustcall_extractor.invoke(\n",
                "    {\"messages\": [SystemMessage(content=system_msg)] + conversation}\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "추출기를 호출하면 몇 가지를 얻게 됩니다:\n",
                "\n",
                "* `messages`: 도구 호출을 포함하는 `AIMessages` 목록.\n",
                "\n",
                "* `responses`: 스키마와 일치하는 결과로 파싱된 도구 호출.\n",
                "\n",
                "* `response_metadata`: 기존 도구 호출을 업데이트할 때 적용됩니다. 어떤 응답이 어떤 기존 객체에 해당하는지를 나타냅니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "Tool Calls:\n",
                        "  UserProfile (call_mYEyeID6cZ5P6gG7hblGtKap)\n",
                        " Call ID: call_mYEyeID6cZ5P6gG7hblGtKap\n",
                        "  Args:\n",
                        "    user_name: Lance\n",
                        "    interests: ['자전거 타기', '샌프란시스코']\n"
                    ]
                }
            ],
            "source": [
                "for m in result[\"messages\"]:\n",
                "    m.pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[UserProfile(user_name='Lance', interests=['자전거 타기', '샌프란시스코'])]"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "schema = result[\"responses\"]\n",
                "schema"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'user_name': 'Lance', 'interests': ['자전거 타기', '샌프란시스코']}"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "schema[0].model_dump()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'id': 'call_uAEgIKFoah7yFoMC6LUVv4cs'}]"
                        ]
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "result[\"response_metadata\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이제 이것을 사용하여 프로필을 _수정(update)_ 하는 방법을 살펴보겠습니다.\n",
                "\n",
                "수정 작업을 위해, TrustCall은 메시지 집합과 기존 스키마를 함께 입력으로 받습니다.\n",
                "\n",
                "핵심 아이디어는 모델이 스키마의 관련 부분만 업데이트하도록 [JSON Patch](https://jsonpatch.com/)를 생성하게 하는 것입니다.\n",
                "\n",
                "이 방법은 전체 스키마를 단순히 덮어쓰는 것보다 오류가 발생할 가능성이 적습니다.\n",
                "\n",
                "또한 모델이 변경된 부분의 스키마만 생성하면 되므로 더 효율적입니다.\n",
                "\n",
                "기존 스키마를 딕셔너리(dict)로 저장할 수 있습니다.\n",
                "\n",
                "Pydantic 모델 인스턴스는 `model_dump()`를 사용하여 딕셔너리로 직렬화할 수 있습니다.\n",
                "\n",
                "이것을 스키마 이름인 `UserProfile`과 함께 `\"existing\"` 인자에 전달합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 대화 업데이트\n",
                "updated_conversation = [\n",
                "    HumanMessage(content=\"안녕하세요, 저는 Lance입니다.\"),\n",
                "    AIMessage(content=\"만나서 반가워요, Lance.\"),\n",
                "    HumanMessage(content=\"저는 샌프란시스코 주변에서 자전거 타는 것을 정말 좋아해요.\"),\n",
                "    AIMessage(content=\"샌프란시스코는 멋진 도시죠! 자전거 탄 후에는 어디로 가시나요?\"),\n",
                "    HumanMessage(content=\"자전거 탄 후에 빵집에 가는 것을 정말 좋아해요.\"),\n",
                "]\n",
                "\n",
                "# 지침 업데이트\n",
                "system_msg = \"다음 대화에서 새로운 정보를 통합하도록 메모리(JSON 문서)를 업데이트하세요\"\n",
                "\n",
                "# 업데이트된 지침과 해당 도구 이름(UserProfile)이 있는 기존 프로필로 추출기 호출\n",
                "result = trustcall_extractor.invoke(\n",
                "    {\"messages\": [SystemMessage(content=system_msg)] + updated_conversation},\n",
                "    {\"existing\": {\"UserProfile\": schema[0].model_dump()}},\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "Tool Calls:\n",
                        "  UserProfile (call_RpJ3qNa8xD2Vvu7dkcJcw9r7)\n",
                        " Call ID: call_RpJ3qNa8xD2Vvu7dkcJcw9r7\n",
                        "  Args:\n",
                        "    user_name: Lance\n",
                        "    interests: ['cycling around San Francisco', 'visiting bakeries']\n"
                    ]
                }
            ],
            "source": [
                "for m in result[\"messages\"]:\n",
                "    m.pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'id': 'call_RpJ3qNa8xD2Vvu7dkcJcw9r7'}]"
                        ]
                    },
                    "execution_count": 40,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "result[\"response_metadata\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'user_name': 'Lance',\n",
                            " 'interests': ['cycling around San Francisco', 'visiting bakeries']}"
                        ]
                    },
                    "execution_count": 41,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "updated_schema = result[\"responses\"][0]\n",
                "updated_schema.model_dump()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LangSmith 트레이스:\n",
                "\n",
                "https://smith.langchain.com/public/229eae22-1edb-44c6-93e6-489124a43968/r\n",
                "\n",
                "이제, 이전에 보았던 [까다로운 스키마](https://github.com/hinthornw/trustcall?tab=readme-ov-file#complex-schema)에 대해서도 Trustcall을 테스트해 봅시다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "bound = create_extractor(\n",
                "    model,\n",
                "    tools=[TelegramAndTrustFallPreferences],\n",
                "    tool_choice=\"TelegramAndTrustFallPreferences\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "TelegramAndTrustFallPreferences(pertinent_user_preferences=UserPreferences(communication_preferences=CommunicationPreferences(telegram=TelegramPreferences(preferred_encoding=[OutputFormat(preference='standard encoding', sentence_preference_revealed='표준 인코딩')], favorite_telegram_operators=None, preferred_telegram_paper=[OutputFormat(preference='데어데블 용지', sentence_preference_revealed='데어데블 용지 사용')]), morse_code=MorseCode(preferred_key_type=[OutputFormat(preference='straight key', sentence_preference_revealed='스트레이트 키 사용')], favorite_morse_abbreviations=None), semaphore=Semaphore(preferred_flag_color=None, semaphore_skill_level=None)), trust_fall_preferences=TrustFallPreferences(preferred_fall_height=[OutputFormat(preference='higher', sentence_preference_revealed='더 높은 낙하')], trust_level=None, preferred_catching_technique=[OutputFormat(preference='diamond formation', sentence_preference_revealed='다이아몬드 포메이션')])))"
                        ]
                    },
                    "execution_count": 43,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 대화\n",
                "conversation = \"\"\"교환원: 전보를 어떻게 도와드릴까요, 손님?\n",
                "고객: 신뢰 낙하 운동에 대한 메시지를 보내야 합니다.\n",
                "교환원: 알겠습니다. 모스 부호인가요, 아니면 표준 인코딩인가요?\n",
                "고객: 모스 부호로 부탁합니다. 스트레이트 키를 사용하는 것을 좋아하거든요.\n",
                "교환원: 훌륭합니다. 메시지가 무엇인가요?\n",
                "고객: 더 높은 낙하에 준비되었고, 잡는 데는 다이아몬드 포메이션을 선호한다고 전해주세요.\n",
                "교환원: 완료되었습니다. 이 대담한 메시지에 저희 \\\"데어데블\\\" 용지를 사용할까요?\n",
                "고객: 완벽해요! 가장 빠른 비둘기 전송으로 보내주세요.\n",
                "교환원: 한 시간 안에 도착할 겁니다, 손님.\"\"\"\n",
                "\n",
                "result = bound.invoke(\n",
                "    f\"\"\"다음 대화에서 선호도를 추출하세요:\n",
                "    <convo>\n",
                "    {conversation}\n",
                "    </convo>\"\"\"\n",
                ")\n",
                "\n",
                "# 선호도 추출\n",
                "result[\"responses\"][0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "트레이스:\n",
                "\n",
                "https://smith.langchain.com/public/5cd23009-3e05-4b00-99f0-c66ee3edd06e/r\n",
                "\n",
                "더 많은 예제는 [여기](https://www.youtube.com/watch?v=-H4s0jQi-QY)에서 개요 비디오를 볼 수 있습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 프로필 스키마 업데이트 기능이 있는 챗봇\n",
                "\n",
                "이제 Trustcall을 챗봇에 도입하여 메모리 프로필을 *생성하고 업데이트*해 봅시다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image, display\n",
                "from langchain_core.messages import HumanMessage, SystemMessage\n",
                "from langgraph.graph import StateGraph, MessagesState, START, END\n",
                "from langchain_core.runnables.config import RunnableConfig\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langgraph.store.base import BaseStore\n",
                "\n",
                "# 모델 초기화\n",
                "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
                "\n",
                "\n",
                "# 스키마\n",
                "class UserProfile(BaseModel):\n",
                "    \"\"\"사용자 프로필\"\"\"\n",
                "\n",
                "    user_name: str = Field(description=\"사용자가 선호하는 이름\")\n",
                "    user_location: str = Field(description=\"사용자의 위치\")\n",
                "    interests: list = Field(description=\"사용자의 관심사 목록\")\n",
                "\n",
                "\n",
                "# 추출기 생성\n",
                "trustcall_extractor = create_extractor(\n",
                "    model,\n",
                "    tools=[UserProfile],\n",
                "    tool_choice=\"UserProfile\",  # UserProfile 도구 사용을 강제합니다.\n",
                ")\n",
                "\n",
                "# 챗봇 지침\n",
                "MODEL_SYSTEM_MESSAGE = \"\"\"당신은 사용자에 대한 정보를 제공하는 기억력을 가진 유용한 어시스턴트입니다.\n",
                "이 사용자에 대한 기억이 있다면, 그것을 사용하여 응답을 개인화하세요.\n",
                "여기 기억이 있습니다 (비어 있을 수 있습니다): {memory}\"\"\"\n",
                "\n",
                "# 추출 지침\n",
                "TRUSTCALL_INSTRUCTION = (\n",
                "    \"\"\"다음 대화의 정보를 통합하여 메모리(JSON 문서)를 생성하거나 업데이트하세요:\"\"\"\n",
                ")\n",
                "\n",
                "\n",
                "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
                "    \"\"\"저장소에서 메모리를 로드하고 이를 사용하여 챗봇의 응답을 개인화합니다.\"\"\"\n",
                "\n",
                "    # 설정에서 사용자 ID 가져오기\n",
                "    user_id = config[\"configurable\"][\"user_id\"]\n",
                "\n",
                "    # 저장소에서 메모리 검색\n",
                "    namespace = (\"memory\", user_id)\n",
                "    existing_memory = store.get(namespace, \"user_memory\")\n",
                "\n",
                "    # 시스템 프롬프트를 위한 메모리 형식 지정\n",
                "    if existing_memory and existing_memory.value:\n",
                "        memory_dict = existing_memory.value\n",
                "        formatted_memory = (\n",
                "            f\"이름: {memory_dict.get('user_name', '알 수 없음')}\\n\"\n",
                "            f\"위치: {memory_dict.get('user_location', '알 수 없음')}\\n\"\n",
                "            f\"관심사: {', '.join(memory_dict.get('interests', []))}\"\n",
                "        )\n",
                "    else:\n",
                "        formatted_memory = None\n",
                "\n",
                "    # 시스템 프롬프트에서 메모리 형식 지정\n",
                "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
                "\n",
                "    # 메모리와 채팅 기록을 사용하여 응답\n",
                "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
                "    return {\"messages\": response}\n",
                "\n",
                "\n",
                "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
                "    \"\"\"채팅 기록을 검토하고 저장소에 메모리를 저장합니다.\"\"\"\n",
                "\n",
                "    # 설정에서 사용자 ID 가져오기\n",
                "    user_id = config[\"configurable\"][\"user_id\"]\n",
                "\n",
                "    # 저장소에서 기존 메모리 검색\n",
                "    namespace = (\"memory\", user_id)\n",
                "    existing_memory = store.get(namespace, \"user_memory\")\n",
                "\n",
                "    # 목록에서 값을 프로필로 가져와 JSON 문서로 변환\n",
                "    existing_profile = (\n",
                "        {\"UserProfile\": existing_memory.value} if existing_memory else None\n",
                "    )\n",
                "\n",
                "    # 추출기 호출\n",
                "    result = trustcall_extractor.invoke(\n",
                "        {\n",
                "            \"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]\n",
                "            + state[\"messages\"],\n",
                "            \"existing\": existing_profile,\n",
                "        }\n",
                "    )\n",
                "    # 업데이트된 프로필을 JSON 객체로 가져오기\n",
                "    updated_profile = result[\"responses\"][0].model_dump()\n",
                "\n",
                "    # 업데이트된 프로필 저장\n",
                "    key = \"user_memory\"\n",
                "    store.put(namespace, key, updated_profile)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<IPython.core.display.Image object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# 그래프 정의\n",
                "builder = StateGraph(MessagesState)\n",
                "builder.add_node(\"call_model\", call_model)\n",
                "builder.add_node(\"write_memory\", write_memory)\n",
                "\n",
                "builder.set_entry_point(\"call_model\")\n",
                "builder.add_edge(\"call_model\", \"write_memory\")\n",
                "builder.set_finish_point(\"write_memory\")\n",
                "\n",
                "# 장기(스레드 간) 메모리를 위한 저장소\n",
                "across_thread_memory = InMemoryStore()\n",
                "\n",
                "# 단기(스레드 내) 메모리를 위한 체크포인터\n",
                "within_thread_memory = MemorySaver()\n",
                "\n",
                "# 체크포인터와 저장소를 사용하여 그래프 컴파일\n",
                "graph = builder.compile(\n",
                "    checkpointer=within_thread_memory,\n",
                "    store=across_thread_memory,\n",
                ")\n",
                "\n",
                "# 보기\n",
                "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "안녕하세요, 제 이름은 Lance입니다\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "안녕하세요, Lance님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?\n"
                    ]
                }
            ],
            "source": [
                "# 단기(스레드 내) 메모리를 위해 스레드 ID를 제공합니다.\n",
                "# 장기(스레드 간) 메모리를 위해 사용자 ID를 제공합니다.\n",
                "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
                "\n",
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"안녕하세요, 제 이름은 Lance입니다\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream(\n",
                "    {\"messages\": input_messages},\n",
                "    config,\n",
                "    stream_mode=\"values\",\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "저는 샌프란시스코 주변에서 자전거 타는 것을 좋아해요\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "샌프란시스코는 자전거 타기에 정말 멋진 장소죠! 금문교를 건너거나 골든 게이트 파크를 탐험하는 것도 좋을 것 같아요. Lance님이 가장 좋아하는 자전거 경로가 있나요?\n"
                    ]
                }
            ],
            "source": [
                "# 사용자 입력\n",
                "input_messages = [\n",
                "    HumanMessage(content=\"저는 샌프란시스코 주변에서 자전거 타는 것을 좋아해요\")\n",
                "]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in (\n",
                "    graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"),\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'namespace': ['memory', '1'],\n",
                            " 'key': 'user_memory',\n",
                            " 'value': {'user_name': 'Lance',\n",
                            "  'user_location': 'San Francisco',\n",
                            "  'interests': ['cycling']},\n",
                            " 'created_at': '2025-10-02T08:12:48.675908+00:00',\n",
                            " 'updated_at': '2025-10-02T08:12:48.675909+00:00'}"
                        ]
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 저장할 메모리의 네임스페이스\n",
                "user_id = \"1\"\n",
                "namespace = (\"memory\", user_id)\n",
                "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
                "existing_memory.dict()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'user_name': 'Lance',\n",
                            " 'user_location': 'San Francisco',\n",
                            " 'interests': ['cycling']}"
                        ]
                    },
                    "execution_count": 49,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# JSON 객체로 저장된 사용자 프로필\n",
                "existing_memory.value"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "빵집에 가는 것도 즐겨요\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "자전거를 타고 샌프란시스코의 멋진 빵집을 탐험하는 것은 정말 좋은 아이디어네요! Tartine Bakery나 Boudin Bakery 같은 곳은 어떠세요? Lance님이 추천하는 빵집이 있나요?\n"
                    ]
                }
            ],
            "source": [
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"빵집에 가는 것도 즐겨요\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream(\n",
                "    {\"messages\": input_messages},\n",
                "    config,\n",
                "    stream_mode=\"values\",\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "새 스레드에서 대화를 계속합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "저에게 추천할 만한 빵집이 있나요?\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "샌프란시스코에는 훌륭한 빵집들이 많이 있습니다. 사이클링을 좋아하신다고 하셨으니, 자전거로 방문하기 좋은 몇 곳을 추천드릴게요.\n",
                        "\n",
                        "1. **Tartine Bakery**: 미션 지구에 위치한 이 빵집은 신선한 빵과 페이스트리로 유명합니다. 자전거를 타고 가기에 좋은 위치에 있으며, 항상 많은 사람들이 찾는 곳입니다.\n",
                        "\n",
                        "2. **B. Patisserie**: 퍼시픽 하이츠에 있는 이곳은 프랑스 스타일의 페이스트리와 크루아상으로 유명합니다. 자전거를 타고 가면 주변 경치도 즐길 수 있습니다.\n",
                        "\n",
                        "3. **Arizmendi Bakery**: 이곳은 협동조합으로 운영되며, 다양한 빵과 피자, 페이스트리를 제공합니다. 자전거로 방문하기에 좋은 위치에 있습니다.\n",
                        "\n",
                        "이 빵집들은 모두 독특한 매력을 가지고 있으니, 방문해 보시면 좋을 것 같습니다!\n"
                    ]
                }
            ],
            "source": [
                "# 단기(스레드 내) 메모리를 위해 스레드 ID를 제공합니다.\n",
                "# 장기(스레드 간) 메모리를 위해 사용자 ID를 제공합니다.\n",
                "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
                "\n",
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"저에게 추천할 만한 빵집이 있나요?\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream(\n",
                "    {\"messages\": input_messages},\n",
                "    config,\n",
                "    stream_mode=\"values\",\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## LangSmith\n",
                "\n",
                "트레이스:\n",
                "\n",
                "https://smith.langchain.com/public/f45bdaf0-6963-4c19-8ec9-f4b7fe0f68ad/r"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 스튜디오\n",
                "\n",
                "![Screenshot 2024-10-30 at 11.26.31 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732d0437060f1754ea79908_Screenshot%202024-11-11%20at%207.48.53%E2%80%AFPM.png)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
