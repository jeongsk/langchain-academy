{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 컬렉션 스키마를 사용하는 챗봇"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 복습"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "우리는 단일 [사용자 프로필](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)에 시맨틱 메모리를 저장하도록 챗봇을 확장했습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "또한, 이 스키마에 새로운 정보를 업데이트하기 위해 [Trustcall](https://github.com/hinthornw/trustcall) 라이브러리를 도입했습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 목표"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "때로는 단일 프로필이 아닌 [컬렉션](https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_200)에 메모리를 저장하고 싶을 때가 있습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "여기서는 [메모리를 컬렉션에 저장](https://langchain-ai.github.io/langgraph/concepts/memory/#collection)하도록 챗봇을 업데이트할 것입니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "또한 [Trustcall](https://github.com/hinthornw/trustcall)을 사용하여 이 컬렉션을 업데이트하는 방법도 보여줄 것입니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture --no-stderr\n",
                "%pip install -U langchain_openai langgraph trustcall langchain_core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, getpass\n",
                "\n",
                "def _set_env(var: str):\n",
                "    # OS 환경에 변수가 설정되어 있는지 확인합니다\n",
                "    env_value = os.environ.get(var)\n",
                "    if not env_value:\n",
                "        # 설정되어 있지 않다면, 사용자에게 입력을 요청합니다\n",
                "        env_value = getpass.getpass(f\"{var}: \")\n",
                "\n",
                "    # 현재 프로세스의 환경 변수를 설정합니다\n",
                "    os.environ[var] = env_value\n",
                "\n",
                "_set_env(\"LANGSMITH_API_KEY\")\n",
                "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
                "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 컬렉션 스키마 정의하기"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "고정된 프로필 구조에 사용자 정보를 저장하는 대신, 사용자 상호작용에 대한 메모리를 저장하기 위해 유연한 컬렉션 스키마를 생성할 것입니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "각 메모리는 우리가 기억하고 싶은 주요 정보를 위한 단일 `content` 필드를 가진 별도의 항목으로 저장될 것입니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이 접근 방식을 통해 사용자에 대해 더 많이 알게 됨에 따라 성장하고 변경될 수 있는 개방형 메모리 컬렉션을 구축할 수 있습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "컬렉션 스키마는 [Pydantic](https://docs.pydantic.dev/latest/) 객체로 정의할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pydantic import BaseModel, Field\n",
                "\n",
                "class Memory(BaseModel):\n",
                "    content: str = Field(\n",
                "        description=\"메모리의 주요 내용입니다. 예: 사용자가 프랑스어 학습에 관심을 보였습니다.\"\n",
                "    )\n",
                "\n",
                "class MemoryCollection(BaseModel):\n",
                "    memories: list[Memory] = Field(description=\"사용자에 대한 메모리 목록입니다.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_set_env(\"OPENAI_API_KEY\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LangChain의 [채팅 모델](https://python.langchain.com/docs/concepts/chat_models/) 인터페이스의 [`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) 메서드를 사용하여 구조화된 출력을 강제할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.messages import HumanMessage\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "# 모델 초기화\n",
                "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
                "\n",
                "# 모델에 스키마 바인딩\n",
                "model_with_structure = model.with_structured_output(MemoryCollection)\n",
                "\n",
                "# 스키마와 일치하는 구조화된 출력을 생성하기 위해 모델 호출\n",
                "memory_collection = model_with_structure.invoke(\n",
                "    [HumanMessage(\"제 이름은 Lance입니다. 저는 자전거 타는 것을 좋아합니다.\")]\n",
                ")\n",
                "memory_collection.memories"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`model_dump()`를 사용하여 Pydantic 모델 인스턴스를 파이썬 딕셔너리로 직렬화할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "memory_collection.memories[0].model_dump()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "각 메모리의 딕셔너리 표현을 저장소에 저장합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import uuid\n",
                "from langgraph.store.memory import InMemoryStore\n",
                "\n",
                "# 인메모리 저장소 초기화\n",
                "in_memory_store = InMemoryStore()\n",
                "\n",
                "# 저장할 메모리의 네임스페이스\n",
                "user_id = \"1\"\n",
                "namespace_for_memory = (user_id, \"memories\")\n",
                "\n",
                "# 네임스페이스에 메모리를 키와 값으로 저장\n",
                "key = str(uuid.uuid4())\n",
                "value = memory_collection.memories[0].model_dump()\n",
                "in_memory_store.put(namespace_for_memory, key, value)\n",
                "\n",
                "key = str(uuid.uuid4())\n",
                "value = memory_collection.memories[1].model_dump()\n",
                "in_memory_store.put(namespace_for_memory, key, value)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "저장소에서 메모리를 검색합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 검색\n",
                "for m in in_memory_store.search(namespace_for_memory):\n",
                "    print(m.dict())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 컬렉션 스키마 업데이트하기"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "지난 강의에서 프로필 스키마 업데이트의 어려움에 대해 논의했습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "컬렉션에도 동일하게 적용됩니다!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "우리는 컬렉션에 새로운 메모리를 추가하고 기존 메모리를 업데이트하는 기능을 원합니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이제 [Trustcall](https://github.com/hinthornw/trustcall)을 사용하여 컬렉션을 업데이트할 수 있음을 보여드리겠습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이를 통해 새로운 메모리를 추가하고 [컬렉션의 기존 메모리를 업데이트](https://github.com/hinthornw/trustcall?tab=readme-ov-file#simultanous-updates--insertions)할 수 있습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Trustcall로 새로운 추출기를 정의해 보겠습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이전과 마찬가지로 각 메모리에 대한 스키마인 `Memory`를 제공합니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "하지만, `enable_inserts=True`를 제공하여 추출기가 컬렉션에 새로운 메모리를 삽입할 수 있도록 허용할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from trustcall import create_extractor\n",
                "\n",
                "# 추출기 생성\n",
                "trustcall_extractor = create_extractor(\n",
                "    model,\n",
                "    tools=[Memory],\n",
                "    tool_choice=\"Memory\",\n",
                "    enable_inserts=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
                "\n",
                "# 지시사항\n",
                "instruction = \"\"\"다음 대화에서 메모리를 추출하세요:\"\"\"\n",
                "\n",
                "# 대화\n",
                "conversation = [\n",
                "    HumanMessage(content=\"안녕하세요, 저는 Lance입니다.\"),\n",
                "    AIMessage(content=\"만나서 반갑습니다, Lance.\"),\n",
                "    HumanMessage(content=\"오늘 아침 샌프란시스코에서 즐겁게 자전거를 탔습니다.\"),\n",
                "]\n",
                "\n",
                "# 추출기 호출\n",
                "result = trustcall_extractor.invoke(\n",
                "    {\"messages\": [SystemMessage(content=instruction)] + conversation}\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 메시지에는 도구 호출이 포함됩니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for m in result[\"messages\"]:\n",
                "    m.pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 응답에는 스키마를 따르는 메모리가 포함됩니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for m in result[\"responses\"]:\n",
                "    print(m)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 메타데이터에는 도구 호출이 포함됩니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for m in result[\"response_metadata\"]:\n",
                "    print(m)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 대화 업데이트\n",
                "updated_conversation = [\n",
                "    AIMessage(content=\"좋네요, 그 후에는 무엇을 하셨나요?\"),\n",
                "    HumanMessage(content=\"Tartine에 가서 크루아상을 먹었어요.\"),\n",
                "    AIMessage(content=\"또 무슨 생각하고 계신가요?\"),\n",
                "    HumanMessage(content=\"일본에 대해 생각하고 있었는데, 이번 겨울에 다시 가고 싶어요!\"),\n",
                "]\n",
                "\n",
                "# 지시사항 업데이트\n",
                "system_msg = \"\"\"다음 대화를 기반으로 기존 메모리를 업데이트하고 새로운 메모리를 생성하세요:\"\"\"\n",
                "\n",
                "# 기존 메모리를 저장하고, ID, 키(도구 이름), 값을 부여합니다\n",
                "tool_name = \"Memory\"\n",
                "existing_memories = (\n",
                "    [\n",
                "        (str(i), tool_name, memory.model_dump())\n",
                "        for i, memory in enumerate(result[\"responses\"])\n",
                "    ]\n",
                "    if result[\"responses\"]\n",
                "    else None\n",
                ")\n",
                "existing_memories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 업데이트된 대화와 기존 메모리로 추출기 호출\n",
                "result = trustcall_extractor.invoke(\n",
                "    {\"messages\": updated_conversation, \"existing\": existing_memories}\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 모델의 메시지는 두 개의 도구 호출이 이루어졌음을 나타냅니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for m in result[\"messages\"]:\n",
                "    m.pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 응답에는 스키마를 따르는 메모리가 포함됩니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for m in result[\"responses\"]:\n",
                "    print(m)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이것은 `json_doc_id`를 지정하여 컬렉션의 첫 번째 메모리를 업데이트했음을 알려줍니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 메타데이터에는 도구 호출이 포함됩니다"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for m in result[\"response_metadata\"]:\n",
                "    print(m)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LangSmith 추적: \n",
                "\n",
                "https://smith.langchain.com/public/ebc1cb01-f021-4794-80c0-c75d6ea90446/r"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 컬렉션 스키마 업데이트를 포함한 챗봇"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이제 Trustcall을 챗봇에 통합하여 메모리 컬렉션을 생성하고 업데이트해 보겠습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image, display\n",
                "import uuid\n",
                "from langgraph.graph import StateGraph, MessagesState, START, END\n",
                "from langgraph.store.memory import InMemoryStore\n",
                "from langchain_core.messages import merge_message_runs\n",
                "from langchain_core.messages import HumanMessage, SystemMessage\n",
                "from langchain_core.runnables.config import RunnableConfig\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langgraph.store.base import BaseStore\n",
                "\n",
                "# 모델 초기화\n",
                "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
                "\n",
                "# 메모리 스키마\n",
                "class Memory(BaseModel):\n",
                "    content: str = Field(\n",
                "        description=\"메모리의 주요 내용입니다. 예: 사용자가 프랑스어 학습에 관심을 보였습니다.\"\n",
                "    )\n",
                "\n",
                "# Trustcall 추출기 생성\n",
                "trustcall_extractor = create_extractor(\n",
                "    model,\n",
                "    tools=[Memory],\n",
                "    tool_choice=\"Memory\",\n",
                "    # 이를 통해 추출기가 새로운 메모리를 삽입할 수 있습니다\n",
                "    enable_inserts=True,\n",
                ")\n",
                "\n",
                "# 챗봇 지시사항\n",
                "MODEL_SYSTEM_MESSAGE = \"\"\"당신은 도움이 되는 챗봇입니다. 당신은 사용자의 동반자가 되도록 설계되었습니다.\\n\n",
                "당신은 시간이 지남에 따라 사용자에 대해 배우는 정보를 추적하는 장기 기억을 가지고 있습니다.\\n\n",
                "현재 메모리 (이 대화에서 업데이트된 메모리를 포함할 수 있음):\\n\n",
                "{memory}\"\"\"\n",
                "\n",
                "# Trustcall 지시사항\n",
                "TRUSTCALL_INSTRUCTION = \"\"\"다음 상호작용을 되돌아보세요.\\n\n",
                "제공된 도구를 사용하여 사용자에 대한 필요한 메모리를 유지하세요.\\n\n",
                "병렬 도구 호출을 사용하여 업데이트와 삽입을 동시에 처리하세요:\"\"\"\n",
                "\n",
                "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
                "    \"\"\"저장소에서 메모리를 로드하고 이를 사용하여 챗봇의 응답을 개인화합니다.\"\"\"\n",
                "\n",
                "    # config에서 사용자 ID 가져오기\n",
                "    user_id = config[\"configurable\"][\"user_id\"]\n",
                "\n",
                "    # 저장소에서 메모리 검색\n",
                "    namespace = (\"memories\", user_id)\n",
                "    memories = store.search(namespace)\n",
                "\n",
                "    # 시스템 프롬프트를 위해 메모리 형식 지정\n",
                "    info = \"\\n\".join(f\"- {mem.value['content']}\" for mem in memories)\n",
                "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=info)\n",
                "\n",
                "    # 메모리와 채팅 기록을 사용하여 응답\n",
                "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
                "\n",
                "    return {\"messages\": response}\n",
                "\n",
                "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
                "    \"\"\"채팅 기록을 되돌아보고 메모리 컬렉션을 업데이트합니다.\"\"\"\n",
                "\n",
                "    # config에서 사용자 ID 가져오기\n",
                "    user_id = config[\"configurable\"][\"user_id\"]\n",
                "\n",
                "    # 메모리의 네임스페이스 정의\n",
                "    namespace = (\"memories\", user_id)\n",
                "\n",
                "    # 컨텍스트를 위해 가장 최근 메모리 검색\n",
                "    existing_items = store.search(namespace)\n",
                "\n",
                "    # Trustcall 추출기를 위해 기존 메모리 형식 지정\n",
                "    tool_name = \"Memory\"\n",
                "    existing_memories = (\n",
                "        [\n",
                "            (existing_item.key, tool_name, existing_item.value)\n",
                "            for existing_item in existing_items\n",
                "        ]\n",
                "        if existing_items\n",
                "        else None\n",
                "    )\n",
                "\n",
                "    # 채팅 기록과 지시사항 병합\n",
                "    updated_messages = list(\n",
                "        merge_message_runs(\n",
                "            messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"]\n",
                "        )\n",
                "    )\n",
                "\n",
                "    # 추출기 호출\n",
                "    result = trustcall_extractor.invoke(\n",
                "        {\"messages\": updated_messages, \"existing\": existing_memories}\n",
                "    )\n",
                "\n",
                "    # Trustcall의 메모리를 저장소에 저장\n",
                "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
                "        store.put(\n",
                "            namespace,\n",
                "            rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
                "            r.model_dump(mode=\"json\"),\n",
                "        )\n",
                "\n",
                "# 그래프 정의\n",
                "builder = StateGraph(MessagesState)\n",
                "builder.add_node(\"call_model\", call_model)\n",
                "builder.add_node(\"write_memory\", write_memory)\n",
                "builder.add_edge(START, \"call_model\")\n",
                "builder.add_edge(\"call_model\", \"write_memory\")\n",
                "builder.add_edge(\"write_memory\", END)\n",
                "\n",
                "# 장기(스레드 간) 메모리를 위한 저장소\n",
                "across_thread_memory = InMemoryStore()\n",
                "\n",
                "# 단기(스레드 내) 메모리를 위한 체크포인터\n",
                "within_thread_memory = MemorySaver()\n",
                "\n",
                "# 체크포인터와 저장소로 그래프 컴파일\n",
                "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
                "\n",
                "# 보기\n",
                "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 단기(스레드 내) 메모리를 위해 스레드 ID를 제공합니다\n",
                "# 장기(스레드 간) 메모리를 위해 사용자 ID를 제공합니다\n",
                "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
                "\n",
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"안녕하세요, 제 이름은 Lance입니다\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"저는 샌프란시스코 주변에서 자전거 타는 것을 좋아합니다\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 저장할 메모리의 네임스페이스\n",
                "user_id = \"1\"\n",
                "namespace = (\"memories\", user_id)\n",
                "memories = across_thread_memory.search(namespace)\n",
                "for m in memories:\n",
                "    print(m.dict())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"저는 빵집 가는 것도 즐깁니다\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "새로운 스레드에서 대화를 계속합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 단기(스레드 내) 메모리를 위해 스레드 ID를 제공합니다\n",
                "# 장기(스레드 간) 메모리를 위해 사용자 ID를 제공합니다\n",
                "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
                "\n",
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"저에게 추천할 만한 빵집이 있나요?\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### LangSmith \n",
                "\n",
                "https://smith.langchain.com/public/c87543ec-b426-4a82-a3ab-94d01c01d9f4/r"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 스튜디오\n",
                "\n",
                "![Screenshot 2024-10-30 at 11.29.25 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732d0876d3daa19fef993ba_Screenshot%202024-11-11%20at%207.50.21%E2%80%AFPM.png)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}