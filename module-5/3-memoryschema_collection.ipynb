{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-5/memoryschema_collection.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/59971006-lesson-4-memory-schema-collection)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 컬렉션 스키마를 사용하는 챗봇\n",
                "\n",
                "## 복습\n",
                "\n",
                "우리는 챗봇을 확장하여 의미 기억을 단일 [사용자 프로필](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)에 저장하도록 만들었습니다.\n",
                "\n",
                "또한, 새로운 정보로 이 스키마를 업데이트하기 위한 [Trustcall](https://github.com/hinthornw/trustcall) 라이브러리를 소개했습니다.\n",
                "\n",
                "## 목표\n",
                "\n",
                "때로는 단일 프로필이 아닌 [컬렉션](https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_200)에 메모리를 저장하고 싶을 때가 있습니다.\n",
                "\n",
                "여기서는 챗봇을 업데이트하여 [메모리를 컬렉션에 저장](https://langchain-ai.github.io/langgraph/concepts/memory/#collection)하도록 만들 것입니다.\n",
                "\n",
                "또한 [Trustcall](https://github.com/hinthornw/trustcall)을 사용하여 이 컬렉션을 업데이트하는 방법도 보여드리겠습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%capture --no-stderr\n",
                "%pip install -U langchain_openai langgraph trustcall langchain_core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv(\"../.env\", override=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import getpass\n",
                "\n",
                "\n",
                "def _set_env(var: str):\n",
                "    env_value = os.environ.get(var)\n",
                "    if not env_value:\n",
                "        env_value = getpass.getpass(f\"{var}: \")\n",
                "\n",
                "    os.environ[var] = env_value\n",
                "\n",
                "\n",
                "_set_env(\"LANGSMITH_API_KEY\")\n",
                "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
                "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 컬렉션 스키마 정의하기"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "고정된 프로필 구조에 사용자 정보를 저장하는 대신, 사용자 상호작용에 대한 메모리를 저장하기 위해 유연한 컬렉션 스키마를 생성할 것입니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "각 메모리는 우리가 기억하고 싶은 주요 정보를 위한 단일 `content` 필드를 가진 별도의 항목으로 저장될 것입니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이 접근 방식을 통해 사용자에 대해 더 많이 알게 됨에 따라 성장하고 변경될 수 있는 개방형 메모리 컬렉션을 구축할 수 있습니다."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "컬렉션 스키마는 [Pydantic](https://docs.pydantic.dev/latest/) 객체로 정의할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pydantic import BaseModel, Field\n",
                "\n",
                "\n",
                "class Memory(BaseModel):\n",
                "    content: str = Field(\n",
                "        description=\"메모리의 주요 내용입니다. 예: 사용자가 프랑스어 학습에 관심을 보였습니다.\"\n",
                "    )\n",
                "\n",
                "\n",
                "class MemoryCollection(BaseModel):\n",
                "    memories: list[Memory] = Field(description=\"사용자에 대한 메모리 목록입니다.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "_set_env(\"OPENAI_API_KEY\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LangChain의 [채팅 모델](https://python.langchain.com/docs/concepts/chat_models/) 인터페이스의 [`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) 메서드를 사용하여 구조화된 출력을 강제할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[Memory(content='사용자 이름은 Lance입니다.'),\n",
                            " Memory(content='Lance는 자전거 타는 것을 좋아합니다.')]"
                        ]
                    },
                    "execution_count": 55,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_core.messages import HumanMessage\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "# 모델 초기화\n",
                "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
                "\n",
                "# 모델에 스키마 바인딩\n",
                "model_with_structure = model.with_structured_output(MemoryCollection)\n",
                "\n",
                "# 스키마와 일치하는 구조화된 출력을 생성하기 위해 모델 호출\n",
                "memory_collection = model_with_structure.invoke(\n",
                "    [HumanMessage(\"제 이름은 Lance입니다. 그리고 저는 자전거 타는 것을 좋아합니다.\")]\n",
                ")\n",
                "memory_collection.memories"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "`model_dump()`를 사용하여 Pydantic 모델 인스턴스를 파이썬 딕셔너리로 직렬화할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'content': '사용자의 이름은 Lance이다.'}"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "memory_collection.memories[0].model_dump()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "각 메모리의 딕셔너리 표현을 저장소에 저장합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "import uuid\n",
                "from langgraph.store.memory import InMemoryStore\n",
                "\n",
                "# 인메모리 저장소 초기화\n",
                "in_memory_store = InMemoryStore()\n",
                "\n",
                "# 저장할 메모리의 네임스페이스\n",
                "user_id = \"1\"\n",
                "namespace_for_memory = (user_id, \"memories\")\n",
                "\n",
                "# 네임스페이스에 메모리를 키와 값으로 저장\n",
                "key = str(uuid.uuid4())\n",
                "value = memory_collection.memories[0].model_dump()\n",
                "in_memory_store.put(namespace_for_memory, key, value)\n",
                "\n",
                "key = str(uuid.uuid4())\n",
                "value = memory_collection.memories[1].model_dump()\n",
                "in_memory_store.put(namespace_for_memory, key, value)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "저장소에서 메모리를 검색합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'namespace': ['1', 'memories'], 'key': '722c5de4-8d39-47f4-a330-2747961b087b', 'value': {'content': '사용자의 이름은 Lance이다.'}, 'created_at': '2025-10-02T08:33:54.899283+00:00', 'updated_at': '2025-10-02T08:33:54.899284+00:00', 'score': None}\n",
                        "{'namespace': ['1', 'memories'], 'key': '471c0f0b-6f69-4cd0-99d2-61bda01cc747', 'value': {'content': '사용자는 자전거 타는 것을 좋아한다.'}, 'created_at': '2025-10-02T08:33:54.899328+00:00', 'updated_at': '2025-10-02T08:33:54.899329+00:00', 'score': None}\n"
                    ]
                }
            ],
            "source": [
                "# 검색\n",
                "for m in in_memory_store.search(namespace_for_memory):\n",
                "    print(m.dict())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 컬렉션 스키마 업데이트하기\n",
                "\n",
                "지난 강의에서 프로필 스키마를 업데이트할 때의 어려움에 대해 논의했습니다.\n",
                "\n",
                "이는 컬렉션의 경우에도 마찬가지입니다!\n",
                "\n",
                "우리는 컬렉션에 새로운 메모리를 추가하고, 기존 메모리를 수정하는 기능이 모두 필요합니다.\n",
                "\n",
                "이제 [Trustcall](https://github.com/hinthornw/trustcall)이 컬렉션 업데이트에도 사용될 수 있음을 보여드리겠습니다.\n",
                "\n",
                "이를 통해 새로운 메모리를 추가하는 것과 [컬렉션 내의 기존 메모리를 업데이트하는 것](https://github.com/hinthornw/trustcall?tab=readme-ov-file#simultanous-updates--insertions)이 모두 가능해집니다.\n",
                "\n",
                "Trustcall을 사용하여 새로운 추출기를 정의해 보겠습니다.\n",
                "\n",
                "이전과 마찬가지로, 각 메모리에 대한 스키마인 `Memory`를 제공합니다.\n",
                "\n",
                "그리고 추출기가 컬렉션에 새로운 메모리를 삽입할 수 있도록 `enable_inserts=True`를 설정할 수 있습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from trustcall import create_extractor\n",
                "\n",
                "# 추출기 생성\n",
                "trustcall_extractor = create_extractor(\n",
                "    model,\n",
                "    tools=[Memory],\n",
                "    tool_choice=\"Memory\",\n",
                "    enable_inserts=True,  # 컬렉션에 새로운 메모리 삽입 가능\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
                "\n",
                "# 지시사항\n",
                "instruction = \"\"\"다음 대화에서 메모리를 추출하세요:\"\"\"\n",
                "\n",
                "# 대화\n",
                "conversation = [\n",
                "    HumanMessage(content=\"안녕하세요, 저는 Lance입니다.\"),\n",
                "    AIMessage(content=\"만나서 반갑습니다, Lance.\"),\n",
                "    HumanMessage(content=\"오늘 아침 샌프란시스코에서 즐겁게 자전거를 탔습니다.\"),\n",
                "]\n",
                "\n",
                "# 추출기 호출\n",
                "result = trustcall_extractor.invoke(\n",
                "    {\n",
                "        \"messages\": [SystemMessage(content=instruction)] + conversation,\n",
                "    }\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5P9dVOAl75I4dw15WwyVfNxi', 'function': {'arguments': '{\"content\":\"사용자 이름은 Lance입니다. 오늘 아침 샌프란시스코에서 자전거를 타며 즐거운 시간을 보냈습니다.\"}', 'name': 'Memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 141, 'total_tokens': 177, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_9f0c66f9ae', 'id': 'chatcmpl-CM935AkSUVhkZ76MzzJdYS7XtKHxe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c9f42f11-1985-43fc-b2f1-0c1ee12fa17f-0', tool_calls=[{'name': 'Memory', 'args': {'content': '사용자 이름은 Lance입니다. 오늘 아침 샌프란시스코에서 자전거를 타며 즐거운 시간을 보냈습니다.'}, 'id': 'call_5P9dVOAl75I4dw15WwyVfNxi', 'type': 'tool_call'}], usage_metadata={'input_tokens': 141, 'output_tokens': 36, 'total_tokens': 177, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
                            " 'responses': [Memory(content='사용자 이름은 Lance입니다. 오늘 아침 샌프란시스코에서 자전거를 타며 즐거운 시간을 보냈습니다.')],\n",
                            " 'response_metadata': [{'id': 'call_5P9dVOAl75I4dw15WwyVfNxi'}],\n",
                            " 'attempts': 1}"
                        ]
                    },
                    "execution_count": 38,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "Tool Calls:\n",
                        "  Memory (call_5P9dVOAl75I4dw15WwyVfNxi)\n",
                        " Call ID: call_5P9dVOAl75I4dw15WwyVfNxi\n",
                        "  Args:\n",
                        "    content: 사용자 이름은 Lance입니다. 오늘 아침 샌프란시스코에서 자전거를 타며 즐거운 시간을 보냈습니다.\n"
                    ]
                }
            ],
            "source": [
                "# 메시지에는 도구 호출이 포함됩니다\n",
                "for m in result[\"messages\"]:\n",
                "    m.pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "content='사용자 이름은 Lance입니다. 오늘 아침 샌프란시스코에서 자전거를 타며 즐거운 시간을 보냈습니다.'\n"
                    ]
                }
            ],
            "source": [
                "# 응답(Responses)에는 스키마를 준수하는 메모리가 포함되어 있습니다.\n",
                "for m in result[\"responses\"]:\n",
                "    print(m)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'id': 'call_5P9dVOAl75I4dw15WwyVfNxi'}\n"
                    ]
                }
            ],
            "source": [
                "# 메타데이터에는 도구 호출(tool call)이 포함됩니다.\n",
                "for m in result[\"response_metadata\"]:\n",
                "    print(m)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[('0',\n",
                            "  'Memory',\n",
                            "  {'content': '사용자 이름은 Lance입니다. 오늘 아침 샌프란시스코에서 자전거를 타며 즐거운 시간을 보냈습니다.'})]"
                        ]
                    },
                    "execution_count": 44,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 대화 업데이트\n",
                "updated_conversation = [\n",
                "    AIMessage(content=\"좋네요, 그 후에는 무엇을 하셨나요?\"),\n",
                "    HumanMessage(content=\"Tartine에 가서 크루아상을 먹었어요.\"),\n",
                "    AIMessage(content=\"또 무슨 생각하고 계신가요?\"),\n",
                "    HumanMessage(\n",
                "        content=\"일본에 대해 생각하고 있었는데, 이번 겨울에 다시 가고 싶어요!\"\n",
                "    ),\n",
                "]\n",
                "\n",
                "# 지시사항 업데이트\n",
                "system_msg = (\n",
                "    \"\"\"다음 대화를 기반으로 기존 메모리를 업데이트하고 새로운 메모리를 생성하세요:\"\"\"\n",
                ")\n",
                "\n",
                "# 기존 메모리를 저장하고, ID, 키(도구 이름), 값을 부여합니다\n",
                "tool_name = \"Memory\"\n",
                "existing_memories = (\n",
                "    [\n",
                "        (str(i), tool_name, memory.model_dump())\n",
                "        for i, memory in enumerate(result[\"responses\"])\n",
                "    ]\n",
                "    if result[\"responses\"]\n",
                "    else None\n",
                ")\n",
                "existing_memories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 업데이트된 대화와 기존 메모리를 사용하여 추출기를 호출합니다.\n",
                "result = trustcall_extractor.invoke(\n",
                "    {\n",
                "        \"messages\": updated_conversation,\n",
                "        \"existing\": existing_memories,\n",
                "    }\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "Tool Calls:\n",
                        "  Memory (call_sBu9ROfPwdeCOalZ53P4Flzi)\n",
                        " Call ID: call_sBu9ROfPwdeCOalZ53P4Flzi\n",
                        "  Args:\n",
                        "    content: 사용자 이름은 Lance입니다. 오늘 아침 샌프란시스코에서 자전거를 타며 즐거운 시간을 보냈습니다. 그 후 Tartine에 가서 크루아상을 먹었습니다. 그리고 일본에 대해 생각하고 있었는데, 이번 겨울에 다시 가고 싶어요!\n"
                    ]
                }
            ],
            "source": [
                "# 모델의 메시지는 두 개의 도구 호출(tool call)이 이루어졌음을 나타냅니다.\n",
                "for m in result[\"messages\"]:\n",
                "    m.pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "content='사용자 이름은 Lance입니다. 오늘 아침 샌프란시스코에서 자전거를 타며 즐거운 시간을 보냈습니다. 그 후 Tartine에 가서 크루아상을 먹었습니다. 그리고 일본에 대해 생각하고 있었는데, 이번 겨울에 다시 가고 싶어요!'\n"
                    ]
                }
            ],
            "source": [
                "# 응답에는 스키마를 준수하는 메모리가 포함되어 있습니다.\n",
                "for m in result[\"responses\"]:\n",
                "    print(m)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이는 `json_doc_id`를 지정하여 컬렉션의 첫 번째 메모리를 업데이트했음을 알려줍니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'id': 'call_sBu9ROfPwdeCOalZ53P4Flzi', 'json_doc_id': '0'}\n"
                    ]
                }
            ],
            "source": [
                "# Metadata contains the tool call\n",
                "for m in result[\"response_metadata\"]:\n",
                "    print(m)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LangSmith 추적: \n",
                "\n",
                "https://smith.langchain.com/public/ebc1cb01-f021-4794-80c0-c75d6ea90446/r"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 컬렉션 스키마 업데이트를 포함한 챗봇"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "이제 Trustcall을 챗봇에 통합하여 메모리 컬렉션을 생성하고 업데이트해 보겠습니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAAFNCAIAAABkBqGXAAAQAElEQVR4nOydB1wTZx/Hn8sihEBYIltkKCIC4h5VXDiqrRT3HrXWLqu1rat11L511Lbaat0LR921dlnrrKhV6wRFRRFQEMMmEEJI7v2H0xggQUhyCXc+31o+l+d57rnxu+d5/s/mkSSJMEyDhzAMBMvGSLBsjATLxkiwbIwEy8ZIrClb2u3C25dK8rKUyjI1qSJVakQQiKqPcDlITSLNYcVPQoPmgCS1FRaCw9F4kuqngSCExo+oiERd9VoEqflP10FzOpyhQhyCUOvUgghNDIRaTbkQT+/gGQIBh8tHInuOR4CoVXdnZCUIy9fbbl7Iv3Q0rzBHBe8E5OHbcAS28A6RWkUgDonUGn0IDqUfSFchF4ckCA6lGfHsfT4T8tmLpd5wFdkqwoA7CMOhTnjqQHK4mmtoQnIIpNZ5CRWykZSL5nqE7s3zbJBKRcJ3pihRq8sRX0h4BQpfneCFLItFZUv6r/D0fml5Genszm/xiqR5O0fEZOTystP7ctJvlyjkpKe/Tcy7PshSWE627YsfFEjLA8Ls+oz1QOwi9Y7s+E6pQq7uN6Ghb1Mxoh8Lybbqo2R7R+6Yzxoj9nLhaM6lI3lNWol7DndHNGMJ2dZ8ei+olW2PIZ7oJWDNp8k9R7oFhjkgOqFdttUzktv0dmzTyxW9NKyddc+nqW2/cTR+phxEJ2tnJ4e0t3+pNAMmfxWQdkt+5WQOog0aZdv9TarIjhc1qCF6+Rjwlse5w3mINuiSLTVJJn2oHD3HD72UeAWIXLwF275MQfRAl2x/xWV5BwrRS8zQab6F2arMByWIBmiR7XG6XFFCDnzHG73cQKvC0e1ZiAZoke3kbqnEhYteeqIGNyjMVSEaoEW2vKyyoEh7ZFlmzpx56NAhVEfu3bvXv39/RA+e/iIen4j/9QkyN+aXraSoTKVC7ftZ2ui/efMmqjvGnVV7oG0IKgPI3Ji/un3xr+xLf+dPWRqI6CE+Pn7btm2JiYmurq7h4eHvv/8+HLRu3ZryFYvFJ0+elMvlK1euTEhIgMTk7+8/cODAQYMGUQF69uw5adKkR48eHThwYPDgwXFxcZT7tGnTRo4ciczN75syMu6XvrnIH5kV86e27Iwy6ItB9JCUlDR16tQ2bdrs27cPcsX09PT58+ejCi3h72effQaawcG33377zz//9OvXb+nSpVFRUUuWLKECAHw+/+DBg6Dr8uXL33333TFjxri7u1+6dIkOzQAXL4FKqUbmxvzdpNCLwaXNHLl69aqNjc348eO5XC687uDg4OTk5OrBQI+xY8d6eWm6wTp37gxanj17tlOnTpQvj8ebM2cOsgh2Er5aTSBzY37ZCE1nJV2pDTJDpVI5ceLE3r17Q5oLDAzUZo+6SKXSDRs2QCb5+PFjysXH53lnWGhoKLIUPE1/vflbfc3/fnl8Dh3ZAgXotGPHjqCgoBUrVgwbNgwKrRs3blQJU1pa+sEHH+Tk5CxevPjMmTOQAYaFhekGsLe3nJUrKywnzJ/YaJDNyZ1XrqSxVwE0gyzu+PHjy5Ytc3BwmD59ukKh0A0A2eaTJ08gn4RUJRRqWmoyMjKQlZBmKDg0FBnmly040p4+2S5fvgylFByIRKJu3bqBeZKXlwdZom4YmUwGfx0dn454OH/+fHZ2NrISuY/KRGLzv2Tzx+jsaQvZwpWTuYgGQLaPP/4YbHdQC7JHKMAaNWrk7e0NdoqbmxsoBFki/ASjAyx7UOvIkSOrVq165ZVXMjMz9Ubo6+sLwcBmSU1NRTSQl13uGWiLzA0ttoPYiZt4thDRANiQMTExYNb36tVr9uzZYCuuXr2a8powYcLFixdnzJghkUgWLVoEog4ZMgSqAXA8YsQI0EZbddMF7MyIiAg46+jRo8jcyOXlYJ/1GGb+sTO09G4n/ltwco/03eV01biZwt4V6QVPyt78MgCZG1pSW/N2Esgn/9yWiV5ush4o2r9KSyMfXaOS2/V1OvdbHhqj3xdsP6h46fUqKyuDhgxCn9UMzVSbNm1C9LClAr1e0GBGmTnVadu2LeTYer1+/jGdy0ehHSWIBmgcArRlYYpYwhs0Vf+gz6KiIr3uoCjYF3q9QEt4g4ge4Lrwxej1AneBQKDXCxprwKbV6/XDtOSJX/rYivQ/i4nQO3JrzSf3ug9zbRJJyxdXn1k3+55vU9s+Y+kavEXvyK2RM72O7pCil4wtC++JHbn0aYYsME6yVK7aMCdlyHQvN2/zV1/qIRvnJgeE20cNpne8miVGJcsKlFvmpzZqbjvgTUvPTLEkxfmKHUseOrjwhs1ohGjGclM31s26B3+7vOEa3IaFRd2+FemP0xTNO9h3s8i4UItOlDoSl3nvWjFPQPi3sLPA/AYLcOdS/n/HC3KzlGIJd+znlpuYYoVpiX9sznx4V64oVXN5SCji2kl4dvYcnoCr0untqTrDU/NfpTuFeh2Hw1GpqvYQcbiaGYXakNrpqRzNVMWqdcEqjtrAmkqjmoSboGYl6l6Xx1GXykl5sbK4QAUdwnC+xJXXc0TDhr4WLbmtIBtFaYni3K/5mSmlJUUqtVpNqgm1ztA0glNlIi9BVO5vhN8cAqnUVW+ey9HoTQWEaDmcp6ayRnZUNXCVqzydRkwBenKfzirWPY/L5/B4JM8GObrxA8MdQtpaJ8O3mmwWYNSoUdAz16xZM8Q62LxSQnl5OfTgIDaCZWMkWDZGwmbZlEoldCYgNoJTGyPBsjESLBsjwbIxEiwbI2GzbCqVCsvGMCCpcbmsnYjMZtnYmtQQi2VjcV0b4dTGULBsjATLxkhw2cZIcGpjJFg2RoJlYyRYNkaCTRJGglMbI2HtgxEE4exstT1o6Ia1snE4nCrrlbAJ9mYjPB7kk4ilYNkYCZaNkWDZGAmWjZFg2RgJlo2RYNkYCZaNkWDZGAmWjZFg2RgJm2VTqWjZzak+QO8Kd9aFy+WyNcGxWTYW55NsnijFYtlYuApQeHg4ZI/UasvU+k3wd9SoUR999BFiCyzMJIODg0EqogJKPx8fn+HDhyMWwULZhgwZYmtbab25Dh06eHrSuASu5WGhbLGxsY0bP1/a0c3NbejQoYhdsNOSHDFihHad95YtW/r7m3mPSavDTtn69Onj5+cHBy4uLmCMINZhHksy7U7x3ctFilK9V6i0jGalxVB1vHSXayUIkuBUXhW08hKq2uU7dddbrfIcT6RZNxNvOTk5RUSE1/yI1AYfL3wNNVxLJ56a3ieXQ0oa8Nv3NcP2KWaQbePnyYoSxLchlM92v9N9sErHFf/r9QLTT63WyoYqZNNdq9WAbNUOdMJADOqKqDikNmaEqj8tnAuuL5BWc4sEFU/1a2mvCLepNrxRJN8GqVQkfI4h7e2jYk1aCdvU6vaaT5Mb+PCjRzdCmNqRkVJ4bOcTexd+qyjjB02blNrWz072bWbb8TU2r+5PEzu/Sm7ZXdI2ugEyCuNNkjOHsyBDwJoZh1eQ8NrpAmQsxsv28E6pyIHNTZq0EtrRRVmKjMZ42cpKqNXWMcZg72RrSm+g8ckFjCKCru212Y+mC9cEEx7ncowEy8ZIjJdNs5sMLtushPGyQSsGgVUzFs0OPSaAM0krYVqbogmZJHwvOLkZi4ktwSakNhKZ2giNMRYTZMOJzXoYL5smmePkZiwmfvHGN26RWDcTIEiTxhVgS9I6qJFJDYPGa64ZgcihvXAb+EbPbXEb4GD/gZ96RrdDFufEyaPderTOz8+rOZj2Pi2DCdVtNcKNJNbCFJOExKpZC5MqAEawZevaI0d+LSjMDwuLnDB+SpOgYHCUy+Xr1q+8dSsh5cE9v0b+/foNfP21QcgoYmJ7jRwxHqK6cOGsu7vnwIFD2rTusGTp/FtJCQ0aNBw3dnK3qF5UyPj4U1u3rUtNS5FIHMPDIqe8Pc3Z2YXyWrN2xV9HfxPZinr06OPj46cb/85dW37/45BUmtWwocfgQSMH9H8DGQVhWk5lgj1TdysSnnn3nrj+/d+YPesLR0enadPfysh8BO4/rvn23Pl/evXst2De0k6dolasXHL+33hkFDweb8/e7eHhrbZvP9S2bcevly+at+CTAQNid8QdCm0evnTZgpKSEgh28dL5uZ9/FBXVa9/eI/PnLb2RcHXW7KlUDId+2Qc3OXnSB2t+3O7k5LJx4ypt5Hv37di4afXokRP37vlz+LCx3/+w7NjxI8goSGtVADSzI+pikpSVlcHrGDVyIqSGzp2iZkyf2yqyXbb0CXhNnPjuN8vXxsYOb9++85jRbwYFNr1w8SwyFm8v39cGxEocJEMGawa2hoS0iOra08nJOWbg0NLSUkhe4Lhp848tI1qPGD7OXmwf0ix08ltT79xNupWUiDS2z66OHbv07t1fLBYPfH1wkybNtPe/Y+dmiBm8HOwd+vZ5rUf3Pjt3bUbGYbU2yTp23KSnpxYWFsAn//TCPN7CBcuo45xsadz2DZCPZWU9ply8vHyQsQQENKEOIPdDFSpSP+3tHeBvQYVNmJKSPHzYOO0pYS1awt+01JTgpiGZmY8g3T/3Cos8/c9x6v4LCvI7d+6m9YoIb/XnkcNWWSbW+OuVK9VEXer60mxNwqLenS6QAmbO/sDDw+vzzxb7Nw4UCoXvfTABmYCNjY3uz+orJkM+qVAoxGJ7rYuDgwT+5uXnFhcXgwwikd1zr2c3TN3/jI/fqRJb1pPHXp7eyLJY7jOhvv2iosIq7vdTkqXSJ5/N+R9kVpTL48cZbg1MGrRbMyKRCD4OmaxI6wLZAPx1cnS2s7ODpFNSUvzc69kNUwbL9Gmzvb19dWODs5ARECY1b1muKRnyPS6Xe/3GlfDwSFRRf5g564OePfo6OmkemxIVVRgLOTnZiGb8/AISEq5qf165eglV5K7wMt3c3JNuJ2q9rl+//PT+PX0gHQtthFAoUi55ebnwFNqpPXUCXp4phZsJrSR17G+D3GbUyAnbd2zcsnXdf5cvrPx+6eUrF/39g3x9/OADB2sF1ALDDCy3Dh1eeZyViegE6h5wD2BzQmL65fD+FSsXR7ZsExioKRShhnD27OkNG1dBSQZWZeLN69QpkBCh/rB2/UqoOchkslOnj8345B24bWQUJGlS45YJ1W1UZ+CxfX0b//bbwT1745qHhH29dHVAQBC4z5m9CKpQ4ycOade2IxxDKQKW+tjxg7Zu3ofooU3r9uvX7ty1e2tc3AY7sbhrl56T3nyP8gJbF5qyoHIGdmOLFhFvT/7wy//NVVfMyBg2dAykyIM/7168dB7U5zp17ApPhKyB8XMANs9PgSwl9kM/hKk7cplq97KU978LREZh2qAE3ChpLCa2kpjSlGyFkVs3blydPedDQ77b437Wmjb1HKvJxuVbIbVBYbNu3U5DvkzRDJnc32aCSaKyTh7p4c6qpSqMw7TqNh6TYCwV5Yvxr49hZRt7IE0qYkwc3oowRkJYqQegIrVh3YzEaqOSobONWddU7gAAEABJREFUg5OblTDBklSTaqyasZg46s0USxK3kpiC2pRs0hSTBKtmPFYr23AFwIoYL5vAFioAXIQxDi7imPDyjO8mtXPgKorLEMYo0hKLCBMGOxp/archrvJi3LplJLcuFDo3FCBjMV42iYutu59gx1fJCFNH/v0jU5ZXNmyGLzIWU9eTPPe79NqpAo8AkVeQrVBY0+dDGjY8qy/zqBNY/3kVC0wS1f1ITWMfYSAqg2jego59pYmaqHotvRFWjvz5L20MlaJSl+dklaXelJUWq976ysh+7ec3jEzj4l/SG/EyhVylUtYUjLRMfaEWl6miisWuzOEhHh85uvGHfGjq8pss3L5By+jRo2fNmhUSEoJYB5tnk1plmLdlwLIxEiwbI2GzbEqlsvq8DXaAUxsjwbIxEiwbI8FlGyPBqY2RsFk2lUqFZWMYkNS4XNb24rJZNrYmNYRlYyhYNkaCZWMkWDZGwtoHY3FdG+HUxlCwbIwEy8ZIsGyMBJskjASnNkbC5h4AHx/jl4Ct57BWNoIg0tLSEEthbzbC40E+iVgKlo2RYNkYCZaNkWDZGAmWjZFg2RgJlo2RYNkYCZaNkWDZGAmWjZFg2RiJSZt212egB4DD4ahUKsRGWCsbYnWCw7IxEhauAhQREcHhVPoc1Wp1r169li1bhtgCC1Obv78/pzLu7u4TJ05ELIKFskVHR1eZkBgaGhocHIxYBAtlGzVqlLf38615JRLJmDFjELtgoWxisTgmJkab4Jo2bRoWFobYBTstyREjRnh6avYLE4lE7EtqqJatJCm3CtXK6tPXa7uwp6FwVRZt1RuMfLZLRO3sXRI9W+EzJvrtw4cPe/v4uIpa3LteXP2KdYz5+em1uW30zJGsRYSVHoAsd/cRiJ1tUc0n1lwB+GlZSm6WCt6Eyqz1n7qun0oQlfc7qNNKsGYJbMTas3X6IrQncTVLCfOFqM84D58gO4PBapBt+9L7ZcXkKzFu7o3tEcaCxP+SmXylePQcX4mL/uWnDcq2ZcF9rgANfMcfYazEtoXJQ2d4uXroyTD1mySJ5/JKi9VYM+vS0E/46/rHer30y3brQqFQzObmSkYQ3M6uuFB/D4Z+bRSlBJe9s4yYgpuvgyGjRr825WV4T716gAqpDXQX4iTFSLBs9Zcaqrb6yzYOh8C7/Fod0nANX39qU6tZvIcKczCsAU5tjASntvoLYTiTNJTaUMXmaBhrQhpuijaU2pBm+zqMVeEYLqhwBaD+UkNJhWWrxxB1rABw+QRZjjNJa1PXCgCp0hiTiGZej+mxLW4DwhhAY0kaEEG/bJapAAwdMjqsRUvqOCa2V0bmI4TRgTTcTmLNsm3E8HHUwePHmfn5eQhTBcNlG3f+/PnVXa+dzocKQEh7R1Q73hgUXVpaGhHeCo4LCvL7vto5NfV+VNeelG/s4N5qtfru3dtzPpse0qzFnM+mpaY9aNe2I2SSSqUSuojemjwSgh048FPyvdvdu/WG4527tixZtmDtupVH//6dx+M3bdKs5ht48OA+pNfgpiFLv1648vulV65c9PTwzsx8NPfzj1b/+O35f+ObBDVzdnahAhuKHGLg8Xj7D+z6+usvTpz4i8vlOkqcPp/38YqVS/46+rujo1NjvwAqZHz8qUVfzvlh9fLDv+6/c+dWaPNwW1sRuM9f8Onpf47LimWz53xYUlIy7aPJrVu1c3Nzp866d+8uvIpxY99CtQO6zxLP5rfr41zdS38myeVzuNw6mCStWrW7eesGdXz5ykVX1wY3Eq5SP9PTU3Nzc1q3bi8QCEpL5Rs3rx4yaFTM60O057aMaP3Vl9/BwY7thxYtXA4He/ft2Lhp9eiRE/fu+XP4sLHf/7Ds2PEjNd8AtXTkps0/jhk9acumfTw+HwTbvHXNR9Pnblj/k6q8fNXq5VTIGiKHSPbs3R4e3mr79kNt23b8evmieQs+GTAgdkfcIRBm6bIFoAQEu3jpPEQeFdVr394j8+cthSedNXsqFQOfz7+fknzs2J/Tps4a+Prghg3d/z72h/Ym/zlzXCKpbUqoGQNlm0pTuqFa0yqybULCVao8vHHjSnSvVyHNPcp4CD+vXb8M32lQYFM4lsvlg2NHRke/6u3tayiqsrKyHTs3vzYgtnfv/g72Dn37vNaje5+duzbX4i5Qx45d4euGlwVnFRYWxL4xvFlwc28vn549+ibdTqxN5N5evuArcZAMGTwKfoaEtIA8w8nJOWbgUMhOUtNSUMXHAZ8a5PD2YvuQZqGT35p6527SraREKoZHj9LnzVvSqVNXeOoB/WOPHz+inRr5z5kTvaP7o1pT58YtUq35V3vatO4AX2JKyj1UoVNYWGSzZqGgH/y8eu2/yJZttCGbN3/BuG5InSB5587dtC6Q996/n1ybmWqBAU2oA+qj9vF+upm8WGwPL12hULww8oDKMYCK1E97ewf4W1BRAKekJIdXFAcUlFWVlppC/YQvElSnjl/tNxAyzH//jYfjzMcZcKF+fV9HtaaGdirzmCQuLq6+vn6JN6/DAdwcPMn10IiEhGt9eg+4du2/8ePe1oaEN1hzVNLsJ/B3xsfvVHHPevLYy9O75nNthELdn9XXSn5h5DY2NjXHAF8nyK/7FA4VIuXl51I/db0gwXXq2PXY8T87duxy8uTRJkHBjRo1RrWmhlZhs1mSkKRANshPoIS3tbVt0aLlmrXfQT6ZnS1t365z7eOhDIfp02ZXyUidHJ2RyZgeuUgkEgqFMlmR1gVy4xpigAS34IuZUDqciT8ZXZccEhnRlMzlcdTldau4RUa2Xb/hBwd7CeSQqCLrSEt7cO7caUiFWhOuNnh5+sAnL7QRQvlBueTl5UKpCe8LmYxZIvfzC0h4ZnABV65eQjq5axXatesEyfHgz7tv3775v0XfIjNhyCSpc3W7ZUSbhw/T4uNPhoVp8np4EWCG7N+/C4zMF57r4+sHfyEbuXkrwc7ObtzYyWvXrwQjWyaTnTp9bMYn7+zeE4fMgVkinzB+yn+XL4DNWVhU+Mvh/StWLoacJjBQv2zQiA+Gz+Ytazp26FJXM5IwbJPoT22khrq1SYrF4qZNQ5KSEluERlAuYH0c/HmPrj1iCChXoBSEZ4Nzv1m+ZtjQMfDxwhe6eOk8Hx8/KB7gXSMzYXrkbVq3X792567dW+PiNtiJxV279Jz05ns1hAf7duu29WBdozpCGs4l9c8B2PrFA1JNxH7YCGFMZs3aFVCv37v7jyoLAbwQuUy1e1nK+98FVvfCHTc0AsXe3btJ+/bvnPrBp3XVDNU44I4xskGL1K5dW/R6NfLz/2HlJlT/+HTm+5CZQcPNgP5voLpD1rUCwOESdaltWwJoZOrWLVqvF49bTz++v/48h0yAQHUclKCxJOvZHABoSbIXv3SzI/GgBOZRQ3W7huGtCFNvsWbvNuYF1HUIEE5q9RwDrSTaPxgrQtaxKRnKNrK+1QAwOhiuAODB5PUYXAFgJFg2RqJfNgGfKMcrJVgbLtegSa+/3mYjJtTl7FyKnUFkPJAZam3VL1t4F/uSIiyblbl5Ll8k0Z/c9MsWEOYkduLtX3EfYayH9KFy+Cf6tw6vaWHCg6se5mSUhke5BLd1QhhLISuQ//trdsZ9xZtfNBbYcvWGecEyoAdXp2ellqnKSTUTa99GrN1pFIT5mpQ4XE1sQjExfIanrdjgGq612r5BnieXySvJXmU5VeLZcrdVItO463El9DXbVHp2Koj+CPW9Jk1IVDX0FwsXjh49yq+xf7UrEdX7RLTX0vWtfKw9p+r1CcQhkZ7vutpb0omNesDqd6JSNfB5wYq7qJb1NlsnW1sGZpPZhfcdXIkGngLEOthc3S4vL+exdHlFLBsjwbIxEiwbI2GzbEqlsvpMJ3aAUxsjwbIxEiwbI8FlGyNhrWwqlYrD3lG6rJWNxTkkwrIxFNY+GIsLNoRTG0PBsjESLBsjYbNsuGxjHji1MRIsGyPBsjESqLdh2ZgHTm1MpVEj1q4ZxlrZSJJMS0tDLIW92QiPV5vllRkKlo2RYNkYCZaNkWDZGAmWjZFg2RgJlo2RYNkYCZaNkWDZGAmWjZFg2RhJnbeCYArULhdqRq6n8mJYKxuq2DQP+rgRG2GzbCzOJwn2rRzfp08fVJE95uTk2NjYwEFZWVlERMSmTfVxHxzjYKFJQhCEVCqlDkAwOHBycpoyZQpiESzMJDt16lQlCwkKCmrT5sW7/zEIFso2fvx4Ly8v7U87O7sRI0YgdsFC2UCz7t27a3/6+fl16dIFsQt2WpJjxozx9dVs0SwSiYYNG4ZYBztlc3Z2jo6Ohho3iNe3b1/EOqxcAYj/9UnKjRJZnkqzh1VFg4a6+u1QC4I+4+lKoCTSsy1IteVa9Qar7qjZY6TKmgrVo4J/HGh8QSJ7rrOHoNMAV2d3G2QlrCbbloX3ZXlqeBl8IU/oILBzFgrt+Fwu78XL5JLE0xdPkM8cCKIWT/FcCJ1zKx3rQKgRWTknghelkCvkhUp5vkIpV6qUaoEN0byDQ8cBDZDFsYJsu79Lk6aWcQSEV0gDiZsdYixp17Nk2XIeH/Ud7+4TZNEHsahsMlnZtvlpPAG3ySu+iC08TJDmZ8q8g4QDp3gjS2E52XIyFbuWpbs2cnBv4oJYR9KpVDt7zug5fsgiWEi2rDT5vu8eNe/VGLGXmyceePgJY97xQvRjCdlysuS7Fj8KjWazZhR34lNthGjsXH9EM5aot+1a8sgzxBm9BDTp1EiWrz6yLQPRDO2ybVv0QGjPd/aWoJeD4Cjfu1dKEM3QK1vy9cKivPLA9pYzsawOl8sVSgSb56cgOqFXtlP7skWOQvSSEdjOq7hAlfmAxjRHo2z5uQq5TN24tQeqryz7fvj+w0sRDQjseMd2SRFt0CjbiZ+kfAGbx6rUgIuvQ0E2jaOPaHyt0nSFUPLS5ZAULj4SaBm/818Bogcax5KUlZJuwSJEG8dPb71w+XB+QZaTo0eXjsM7tIkBx8dP7n/9/fC3xn5/4sy29Ee3bASiVhF9+/acQjXwg+9P+xdmSVMC/Vv17DqBQ9D41RJcdPu/oiataDGh6ZItX6oZe+PoZo/o4VT8zj/+XjM0Zm5I01cSkk7t/2WJ0MauZVg0l6N5ol/++K5Xt4ljhy25efvMzn2f+3o3D23WtbxcuWHbh6Dxp1P3ykuLDh5eVliUjWiDx+fmSeka7kfX55aZIke0oSwvg6TWoc0brVu+KhI5tI0cEBnWG1y0AUKadg4P7QFdQZHhvV2cvB6k3QDH6zePQ9J8vd80R4mbR8OAmAEfF5fkI9rg2XAVxXRty0uXbMWFNG4kLM1OhTfeIiRK6+LfODIzK1mlevp1Q/LSegmF9pQ8ObkP4a+3ZzDlDsqJRDQ2AnB4PJKk6/XSlUnybTj0tXUWFGps67Vb3qvinpf/+OnV+XpMoZKSwio6iWwdEG2okZpH2zKkdMnm6nuROwsAAAMqSURBVCGgb+MEe7GmhTP2tZkNXHyruNdQXEF2KpcX6rqUVP5pXkiFSiCk6x3QJZtXoAgRSC5T2IrNP+DC1dmHz7cR8IVgEFIuRbJc6MqwsRGhIoNnOUk8IMzDjCQqn8zMuldSQpeBDqjK1WJHupIbjRYwj0/kPSxCNAC2RnS3Sb/99UPCrdPyUtn1hOPrtrx/Kn5HzWc1b9aFxxPs3DsvNf0GaLb35//RWrapylRegXRVW2mst0lcebJcutrlur0y2tOjSfz5PT8dWODm6tc8uEt090k1n2IrFE8c9Q2IvWrDZEipr0a/d/n6EURPd2NJkUKtRm17uyJ6oLGbNPF8/qm92SE92d87Wp2USxlkefmEBXQ9O42ZZPP2jhwekXmbxiptvaWkQNG8A11NDYjuiVJNIsXQwOPR1GBeMffLHnrd1WoVQRjcxmvmh/vFdo7ITGyMm56Sdk2vF9QQDFmbi+YcQwZ4eFPK5aF2fejKIZEFxpKsnXXPzsXOu7n+MaC5ecb03zs7eSLzUViYXa4q0+ulUMhtbGxRHe8h8VhK5wFO4V1pHKBGu2xPHpbs+SYjlNVjtnS5e+6hUEiOnu2H6IT2/jA3b1FQS7tbJx6glwAoyFWKcro1Q5YZudV7tEdDX5uEo/QOr7A66YlZuelFby8JQPRjuVHJZ3/NuXoqL6Q7O3PL1KtZRU9K3vs2EFkEi84B+G3To5QbckdPkXdoQ8Qikk494HKJSV/SPqpVi6Vn3GSkFh9YkQkHro0l7oHMHvOqUqlSLmaUFpV7BQhi3rXoZBTrzG/7Y+vDB4kKlZLkCjmOHnYNGjsyaGOTgieyvEcyeYFCrVRLXLlDZngJBAJkWaw5m/Ty8dzLJ/JKi0nNjEEONV2TIHW7V4lnkwlJfZM7q9041M6fPw1ReUYoqXOKoQPdODkVxzqOaoIkKua7EhwkEHI8Gtv0f9MSszT0Ul9WAbp1Kb8wW1kmR2Sltc20L1LPNF2kZ6aurrM+YZ+H0Ehc+af6mVbaWceVYxAQEnuOR4Ctm48tsjYsXLzpZYDNO0qxGCwbI8GyMRIsGyPBsjESLBsj+T8AAAD//3VOYbIAAAAGSURBVAMA3U5pTNMNd7UAAAAASUVORK5CYII=",
                        "text/plain": [
                            "<IPython.core.display.Image object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from IPython.display import Image, display\n",
                "import uuid\n",
                "from langgraph.graph import StateGraph, MessagesState, START, END\n",
                "from langgraph.store.memory import InMemoryStore\n",
                "from langchain_core.messages import merge_message_runs\n",
                "from langchain_core.messages import HumanMessage, SystemMessage\n",
                "from langchain_core.runnables.config import RunnableConfig\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langgraph.store.base import BaseStore\n",
                "\n",
                "# 모델 초기화\n",
                "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
                "\n",
                "\n",
                "# 메모리 스키마\n",
                "class Memory(BaseModel):\n",
                "    content: str = Field(\n",
                "        description=\"메모리의 주요 내용입니다. 예: 사용자가 프랑스어 학습에 관심을 보였습니다.\"\n",
                "    )\n",
                "\n",
                "\n",
                "# Trustcall 추출기 생성\n",
                "trustcall_extractor = create_extractor(\n",
                "    model,\n",
                "    tools=[Memory],\n",
                "    tool_choice=\"Memory\",\n",
                "    # 이를 통해 추출기가 새로운 메모리를 삽입할 수 있습니다\n",
                "    enable_inserts=True,\n",
                ")\n",
                "\n",
                "# 챗봇 지시사항\n",
                "MODEL_SYSTEM_MESSAGE = \"\"\"당신은 도움이 되는 챗봇입니다. 당신은 사용자의 동반자가 되도록 설계되었습니다.\\n\n",
                "당신은 시간이 지남에 따라 사용자에 대해 배우는 정보를 추적하는 장기 기억을 가지고 있습니다.\\n\n",
                "현재 메모리 (이 대화에서 업데이트된 메모리를 포함할 수 있음):\\n\n",
                "{memory}\"\"\"\n",
                "\n",
                "# Trustcall 지시사항\n",
                "TRUSTCALL_INSTRUCTION = \"\"\"다음 상호작용을 되돌아보세요.\\n\n",
                "제공된 도구를 사용하여 사용자에 대한 필요한 메모리를 유지하세요.\\n\n",
                "병렬 도구 호출을 사용하여 업데이트와 삽입을 동시에 처리하세요:\"\"\"\n",
                "\n",
                "\n",
                "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
                "    \"\"\"저장소에서 메모리를 로드하고 이를 사용하여 챗봇의 응답을 개인화합니다.\"\"\"\n",
                "\n",
                "    # config에서 사용자 ID 가져오기\n",
                "    user_id = config[\"configurable\"][\"user_id\"]\n",
                "\n",
                "    # 저장소에서 메모리 검색\n",
                "    namespace = (\"memories\", user_id)\n",
                "    memories = store.search(namespace)\n",
                "\n",
                "    # 시스템 프롬프트를 위해 메모리 형식 지정\n",
                "    info = \"\\n\".join(f\"- {mem.value['content']}\" for mem in memories)\n",
                "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=info)\n",
                "\n",
                "    # 메모리와 채팅 기록을 사용하여 응답\n",
                "    response = model.invoke([SystemMessage(content=system_msg)] + state[\"messages\"])\n",
                "\n",
                "    return {\"messages\": response}\n",
                "\n",
                "\n",
                "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
                "    \"\"\"채팅 기록을 되돌아보고 메모리 컬렉션을 업데이트합니다.\"\"\"\n",
                "\n",
                "    # config에서 사용자 ID 가져오기\n",
                "    user_id = config[\"configurable\"][\"user_id\"]\n",
                "\n",
                "    # 메모리의 네임스페이스 정의\n",
                "    namespace = (\"memories\", user_id)\n",
                "\n",
                "    # 컨텍스트를 위해 가장 최근 메모리 검색\n",
                "    existing_items = store.search(namespace)\n",
                "\n",
                "    # Trustcall 추출기를 위해 기존 메모리 형식 지정\n",
                "    tool_name = \"Memory\"\n",
                "    existing_memories = (\n",
                "        [\n",
                "            (existing_item.key, tool_name, existing_item.value)\n",
                "            for existing_item in existing_items\n",
                "        ]\n",
                "        if existing_items\n",
                "        else None\n",
                "    )\n",
                "\n",
                "    # 채팅 기록과 지시사항 병합\n",
                "    updated_messages = list(\n",
                "        merge_message_runs(\n",
                "            messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"]\n",
                "        )\n",
                "    )\n",
                "\n",
                "    # 추출기 호출\n",
                "    result = trustcall_extractor.invoke(\n",
                "        {\"messages\": updated_messages, \"existing\": existing_memories}\n",
                "    )\n",
                "\n",
                "    # Trustcall의 메모리를 저장소에 저장\n",
                "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
                "        store.put(\n",
                "            namespace,\n",
                "            rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
                "            r.model_dump(mode=\"json\"),\n",
                "        )\n",
                "\n",
                "\n",
                "# 그래프 정의\n",
                "builder = StateGraph(MessagesState)\n",
                "builder.add_node(\"call_model\", call_model)\n",
                "builder.add_node(\"write_memory\", write_memory)\n",
                "\n",
                "builder.set_entry_point(\"call_model\")\n",
                "builder.add_edge(\"call_model\", \"write_memory\")\n",
                "builder.set_finish_point(\"write_memory\")\n",
                "\n",
                "# 장기(스레드 간) 메모리를 위한 저장소\n",
                "across_thread_memory = InMemoryStore()\n",
                "\n",
                "# 단기(스레드 내) 메모리를 위한 체크포인터\n",
                "within_thread_memory = MemorySaver()\n",
                "\n",
                "# 체크포인터와 저장소로 그래프 컴파일\n",
                "graph = builder.compile(\n",
                "    checkpointer=within_thread_memory,\n",
                "    store=across_thread_memory,\n",
                ")\n",
                "\n",
                "# 보기\n",
                "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "안녕하세요, 제 이름은 Lance입니다\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "안녕하세요, Lance! 만나서 반가워요. 오늘 어떻게 도와드릴까요?\n"
                    ]
                }
            ],
            "source": [
                "# 단기(스레드 내) 메모리를 위해 스레드 ID를 제공합니다\n",
                "# 장기(스레드 간) 메모리를 위해 사용자 ID를 제공합니다\n",
                "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
                "\n",
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"안녕하세요, 제 이름은 Lance입니다\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream(\n",
                "    {\"messages\": input_messages},\n",
                "    config,\n",
                "    stream_mode=\"values\",\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "저는 샌프란시스코 주변에서 자전거 타는 것을 좋아합니다\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "샌프란시스코는 자전거 타기에 정말 멋진 장소죠! 특히 좋아하는 경로나 장소가 있나요?\n"
                    ]
                }
            ],
            "source": [
                "# 사용자 입력\n",
                "input_messages = [\n",
                "    HumanMessage(content=\"저는 샌프란시스코 주변에서 자전거 타는 것을 좋아합니다\")\n",
                "]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream(\n",
                "    {\"messages\": input_messages},\n",
                "    config,\n",
                "    stream_mode=\"values\",\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'namespace': ['memories', '1'], 'key': '62ef507d-28d5-4eb1-9a31-79e0bdc0ff78', 'value': {'content': '사용자의 이름은 Lance입니다.'}, 'created_at': '2025-10-02T08:34:10.073993+00:00', 'updated_at': '2025-10-02T08:34:10.073993+00:00', 'score': None}\n",
                        "{'namespace': ['memories', '1'], 'key': 'cc5ad87b-59d0-45fb-95a5-126db0d9c539', 'value': {'content': '사용자는 샌프란시스코 주변에서 자전거 타는 것을 좋아합니다.'}, 'created_at': '2025-10-02T08:34:10.074010+00:00', 'updated_at': '2025-10-02T08:34:10.074010+00:00', 'score': None}\n"
                    ]
                }
            ],
            "source": [
                "# 저장할 메모리의 네임스페이스\n",
                "user_id = \"1\"\n",
                "namespace = (\"memories\", user_id)\n",
                "memories = across_thread_memory.search(namespace)\n",
                "for m in memories:\n",
                "    print(m.dict())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "저는 빵집 가는 것도 즐깁니다\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "자전거를 타고 빵집에 가는 건 정말 좋은 조합이네요! 샌프란시스코에는 맛있는 빵집이 많죠. 특별히 좋아하는 빵집이 있나요?\n"
                    ]
                }
            ],
            "source": [
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"저는 빵집 가는 것도 즐깁니다\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream(\n",
                "    {\"messages\": input_messages},\n",
                "    config,\n",
                "    stream_mode=\"values\",\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "새로운 스레드에서 대화를 계속합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================\u001b[1m Human Message \u001b[0m=================================\n",
                        "\n",
                        "저에게 추천할 만한 빵집이 있나요?\n",
                        "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
                        "\n",
                        "샌프란시스코에는 훌륭한 빵집이 많이 있습니다! 몇 가지 추천을 드리자면:\n",
                        "\n",
                        "1. **타르틴 베이커리 (Tartine Bakery)** - 미션 지구에 위치한 이곳은 크루아상과 사워도우 빵으로 유명합니다.\n",
                        "\n",
                        "2. **비 파티세리 (b. Patisserie)** - 이곳은 특히 크로캉트 아망드와 같은 페이스트리로 인기가 많습니다.\n",
                        "\n",
                        "3. **아르스 타르틴 (Arsicault Bakery)** - 리치몬드 지구에 있으며, 버터리한 크루아상으로 많은 사랑을 받고 있습니다.\n",
                        "\n",
                        "4. **파니에 (Le Marais Bakery)** - 프랑스 스타일의 빵과 페이스트리를 즐길 수 있는 곳입니다.\n",
                        "\n",
                        "이 중에서 가보지 않은 곳이 있다면 한 번 방문해 보세요! 자전거로 가기에도 좋은 경로가 있을 것 같네요.\n"
                    ]
                }
            ],
            "source": [
                "# 단기(스레드 내) 메모리를 위해 스레드 ID를 제공합니다\n",
                "# 장기(스레드 간) 메모리를 위해 사용자 ID를 제공합니다\n",
                "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
                "\n",
                "# 사용자 입력\n",
                "input_messages = [HumanMessage(content=\"저에게 추천할 만한 빵집이 있나요?\")]\n",
                "\n",
                "# 그래프 실행\n",
                "for chunk in graph.stream(\n",
                "    {\"messages\": input_messages},\n",
                "    config,\n",
                "    stream_mode=\"values\",\n",
                "):\n",
                "    chunk[\"messages\"][-1].pretty_print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### LangSmith \n",
                "\n",
                "https://smith.langchain.com/public/c87543ec-b426-4a82-a3ab-94d01c01d9f4/r"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 스튜디오\n",
                "\n",
                "![Screenshot 2024-10-30 at 11.29.25 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6732d0876d3daa19fef993ba_Screenshot%202024-11-11%20at%207.50.21%E2%80%AFPM.png)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
