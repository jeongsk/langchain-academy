"""
Perplexity Clone - Streamlit UI (Remote Graph)
LangGraph Studio ì„œë²„ì™€ í†µì‹ í•˜ëŠ” ë²„ì „
"""

import asyncio
import os
import uuid

import streamlit as st
from dotenv import load_dotenv
from langgraph_sdk import get_client

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from concurrent.futures import ThreadPoolExecutor

import nest_asyncio

# nest_asyncio ì ìš© - Jupyter/Streamlit í™˜ê²½ì—ì„œ asyncio ì¤‘ì²© í—ˆìš©
nest_asyncio.apply()


class AsyncRunner:
    """
    Streamlit í™˜ê²½ì—ì„œ async í•¨ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í—¬í¼ í´ë˜ìŠ¤
    ê¸°ì¡´ event loopë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ event loop ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """

    def __init__(self):
        self.loop = None
        self.executor = ThreadPoolExecutor(max_workers=1)

    def _get_or_create_loop(self):
        """ê¸°ì¡´ event loopë¥¼ ì¬ì‚¬ìš©í•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±"""
        if self.loop is None or self.loop.is_closed():
            self.loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self.loop)
        return self.loop

    def run(self, async_func, *args, **kwargs):
        """
        async í•¨ìˆ˜ë¥¼ ê¸°ì¡´ event loopì—ì„œ ì‹¤í–‰

        Args:
            async_func: ì‹¤í–‰í•  async í•¨ìˆ˜
            *args, **kwargs: async í•¨ìˆ˜ì— ì „ë‹¬í•  ì¸ì

        Returns:
            async í•¨ìˆ˜ì˜ ì‹¤í–‰ ê²°ê³¼
        """

        def _run():
            loop = self._get_or_create_loop()
            return loop.run_until_complete(async_func(*args, **kwargs))

        future = self.executor.submit(_run)
        return future.result()

    def run_generator(self, async_gen_func, *args, **kwargs):
        """
        async generatorë¥¼ ë™ê¸° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            async_gen_func: ì‹¤í–‰í•  async generator í•¨ìˆ˜
            *args, **kwargs: async generator í•¨ìˆ˜ì— ì „ë‹¬í•  ì¸ì

        Returns:
            generatorì—ì„œ yieldëœ ëª¨ë“  í•­ëª©ì˜ ë¦¬ìŠ¤íŠ¸
        """

        def _run():
            loop = self._get_or_create_loop()

            async def collect():
                results = []
                async for item in async_gen_func(*args, **kwargs):
                    results.append(item)
                return results

            return loop.run_until_complete(collect())

        future = self.executor.submit(_run)
        return future.result()


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Perplexity Clone (Remote)",
    page_icon="ğŸ”",
    layout="wide",
)

# ì œëª© ë° ì„¤ëª…
st.title("ğŸ” Perplexity Clone (Remote)")
st.markdown(
    """
    LangGraph Studio ì„œë²„ì™€ í†µì‹ í•˜ëŠ” **ì›¹ ê²€ìƒ‰ Agent**ì…ë‹ˆë‹¤.
    ì§ˆë¬¸í•˜ì‹œë©´ ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ **ì¶œì²˜ì™€ í•¨ê»˜** ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

if "client" not in st.session_state:
    st.session_state.client = None

if "server_url" not in st.session_state:
    st.session_state.server_url = os.getenv(
        "LANGGRAPH_API_URL", "http://127.0.0.1:2024"
    )

if "async_runner" not in st.session_state:
    st.session_state.async_runner = AsyncRunner()

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # ì„œë²„ URL ì„¤ì •
    st.subheader("ğŸŒ ì„œë²„ ì—°ê²°")
    server_url = st.text_input(
        "LangGraph Studio URL",
        value=st.session_state.server_url,
        help="LangGraph Studio ì„œë²„ ì£¼ì†Œ (ì˜ˆ: http://127.0.0.1:2024)",
    )

    if st.button("ğŸ”Œ ì—°ê²°", use_container_width=True):
        try:
            with st.spinner("ì„œë²„ ì—°ê²° ì¤‘..."):
                st.session_state.client = get_client(url=server_url)
                st.session_state.server_url = server_url
                st.success("âœ… ì„œë²„ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")

                # ì‚¬ìš© ê°€ëŠ¥í•œ ê·¸ë˜í”„ ëª©ë¡ ì¡°íšŒ (ë™ê¸° ë°©ì‹)
                try:
                    assistants = st.session_state.async_runner.run(
                        st.session_state.client.assistants.search
                    )
                    if assistants:
                        st.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ê·¸ë˜í”„: {len(assistants)}ê°œ")
                except Exception:
                    # ê²€ìƒ‰ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ (ì—°ê²°ì€ ì„±ê³µ)
                    pass
        except Exception as e:
            st.error(f"âŒ ì—°ê²° ì‹¤íŒ¨: {str(e)}")

    st.divider()

    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.session_state.thread_id = str(uuid.uuid4())
        st.rerun()

    st.divider()

    # í˜„ì¬ ìŠ¤ë ˆë“œ ì •ë³´
    st.caption(f"Thread ID: `{st.session_state.thread_id[:8]}...`")

    st.divider()
    st.caption("Made with LangGraph ğŸ¦œğŸ”—")


# ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸
if st.session_state.client is None:
    st.warning("âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ LangGraph Studio ì„œë²„ì— ì—°ê²°í•´ì£¼ì„¸ìš”.")
    st.info("""
    **ì—°ê²° ë°©ë²•:**
    1. í„°ë¯¸ë„ì—ì„œ `cd tutorial/12-Perplexity-Clone/studio` ì‹¤í–‰
    2. `langgraph dev` ëª…ë ¹ìœ¼ë¡œ ì„œë²„ ì‹œì‘
    3. ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ”Œ ì—°ê²°' ë²„íŠ¼ í´ë¦­
    """)
    st.stop()


# ì´ì „ ëŒ€í™” í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


# ì‚¬ìš©ì ì…ë ¥
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_input)

    # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})

    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ğŸ” ê²€ìƒ‰ ì¤‘..."):
            # ì‘ë‹µ ì»¨í…Œì´ë„ˆ
            response_container = st.empty()
            search_status_container = st.container()

            try:
                # ì…ë ¥ ë©”ì‹œì§€
                input_data = {"messages": [{"role": "user", "content": user_input}]}

                # ê·¸ë˜í”„ ì´ë¦„ (langgraph.jsonì— ì •ì˜ëœ ì´ë¦„)
                graph_name = "perplexity_agent"

                # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (AsyncRunner ì‚¬ìš©)
                full_response = ""
                tool_calls_made = []

                # async generatorë¥¼ ë™ê¸° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                chunks = st.session_state.async_runner.run_generator(
                    st.session_state.client.runs.stream,
                    st.session_state.thread_id,
                    graph_name,
                    input=input_data,
                    stream_mode="values",
                )

                # ìˆ˜ì§‘ëœ chunkë“¤ì„ ìˆœíšŒí•˜ë©° ì²˜ë¦¬
                for chunk in chunks:
                    # ë©”ì‹œì§€ ì´ë²¤íŠ¸ ì²˜ë¦¬
                    if "messages" in chunk:
                        last_message = chunk["messages"][-1]

                        # AI ë©”ì‹œì§€ì¸ ê²½ìš°
                        if last_message.get("type") == "ai":
                            # ë„êµ¬ í˜¸ì¶œ í™•ì¸
                            if (
                                "tool_calls" in last_message
                                and last_message["tool_calls"]
                            ):
                                for tool_call in last_message["tool_calls"]:
                                    tool_id = tool_call.get("id")
                                    if tool_id not in tool_calls_made:
                                        tool_calls_made.append(tool_id)
                                        with search_status_container:
                                            st.info(
                                                f"ğŸ” ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘: `{tool_call.get('name')}`"
                                            )

                            # ìµœì¢… ì‘ë‹µ
                            if last_message.get("content"):
                                full_response = last_message["content"]
                                response_container.markdown(full_response)

                # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
                st.session_state.messages.append(
                    {"role": "assistant", "content": full_response}
                )

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                st.exception(e)


# í•˜ë‹¨ ì •ë³´
st.divider()
with st.expander("â„¹ï¸ ì‚¬ìš© ë°©ë²•"):
    st.markdown("""
    ### ì‚¬ìš© ë°©ë²• (Remote ëª¨ë“œ)

    1. **ì„œë²„ ì‹œì‘**: í„°ë¯¸ë„ì—ì„œ `langgraph dev` ì‹¤í–‰
    2. **ì—°ê²°**: ì‚¬ì´ë“œë°”ì—ì„œ ì„œë²„ URL í™•ì¸ í›„ 'ğŸ”Œ ì—°ê²°' í´ë¦­
    3. **ì§ˆë¬¸ ì…ë ¥**: í•˜ë‹¨ ì…ë ¥ì°½ì— ì§ˆë¬¸ ì…ë ¥
    4. **ì‘ë‹µ í™•ì¸**: AIê°€ ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¶œì²˜ì™€ í•¨ê»˜ ë‹µë³€ ì œê³µ

    ### ì¥ì 

    - **ê°œë°œ/í”„ë¡œë•ì…˜ ë¶„ë¦¬**: UIì™€ ê·¸ë˜í”„ ë¡œì§ ë¶„ë¦¬
    - **ìŠ¤ì¼€ì¼ë§**: ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ê°€ ë™ì¼í•œ ê·¸ë˜í”„ ì„œë²„ ì‚¬ìš© ê°€ëŠ¥
    - **ë””ë²„ê¹…**: LangGraph Studio UIì—ì„œ ì‹¤ì‹œê°„ ë””ë²„ê¹…
    - **ë°°í¬**: ê·¸ë˜í”„ ì„œë²„ë¥¼ ë³„ë„ë¡œ ë°°í¬ ê°€ëŠ¥

    ### ë¡œì»¬ ëª¨ë“œ vs Remote ëª¨ë“œ

    - **app.py**: ê·¸ë˜í”„ë¥¼ ì§ì ‘ ë¡œë“œí•˜ì—¬ ì‹¤í–‰ (ê°„ë‹¨, ì˜¬ì¸ì›)
    - **app_remote.py**: LangGraph Studio ì„œë²„ì™€ í†µì‹  (í”„ë¡œë•ì…˜ í™˜ê²½)
    """)

with st.expander("ğŸ”§ ì„œë²„ ì •ë³´"):
    if st.session_state.client:
        st.write(f"**ì„œë²„ URL**: `{st.session_state.server_url}`")
        st.write(f"**Thread ID**: `{st.session_state.thread_id}`")

        if st.button("ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ê·¸ë˜í”„ ì¡°íšŒ"):
            try:
                assistants = st.session_state.async_runner.run(
                    st.session_state.client.assistants.search
                )
                st.json(
                    [{"name": a["name"], "graph_id": a["graph_id"]} for a in assistants]
                )
            except Exception as e:
                st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
