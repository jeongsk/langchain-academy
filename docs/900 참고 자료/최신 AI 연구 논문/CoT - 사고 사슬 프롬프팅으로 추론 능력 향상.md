---
title: "CoT: 사고 사슬 프롬프팅으로 대규모 언어 모델의 추론 능력 향상"
created: 2025-10-25 00:00:00
updated: 2025-10-25 18:09:19
tags: [연구논문, 추론, 프롬프트엔지니어링, CoT, LLM기초]
---
## 기본 정보

- **제목**: Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
- **저자**: Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou (Google Research)
- **발표일**: 2022년 1월 28일 (arXiv), 2023년 4월 15일 (NeurIPS 2022)
- **arXiv**: <https://arxiv.org/abs/2201.11903>
- **분야**: Computation and Language, Artificial Intelligence
- **학회**: NeurIPS 2022 (Neural Information Processing Systems)

## 연구 개요

Chain-of-Thought (CoT) 프롬프팅은 대규모 언어 모델이 복잡한 추론 문제를 해결할 때 중간 추론 단계를 생성하도록 유도하는 프롬프팅 기법입니다. 모델의 가중치를 수정하지 않고도 몇 가지 예시만으로 수학, 상식 추론, 기호 추론 등 다양한 영역에서 획기적인 성능 향상을 달성했습니다.

## 핵심 개념

### 1. CoT 프롬프팅이란?

#### 기본 원리

**표준 프롬프팅 (Standard Prompting)**

- 입력 → 출력 직접 매핑
- 예: "Q: 로저는 테니스공 5개를 가지고 있었다. 그는 테니스공 캔 2개를 더 샀다. 각 캔에는 3개씩 들어있다. 이제 몇 개를 가지고 있는가? A: 11"

**CoT 프롬프팅 (Chain-of-Thought Prompting)**

- 입력 → 중간 추론 단계 → 출력
- 예: "Q: 로저는 테니스공 5개를 가지고 있었다. 그는 테니스공 캔 2개를 더 샀다. 각 캔에는 3개씩 들어있다. 이제 몇 개를 가지고 있는가? A: 로저는 처음에 5개를 가지고 있었다. 2캔을 샀는데 각각 3개씩이므로 2 × 3 = 6개다. 5 + 6 = 11개다. 답은 11이다."

#### 핵심 특징

1. **Few-Shot Learning**
   - 8개 내외의 예시만으로 작동
   - 모델 재학습이나 파인튜닝 불필요
   - 프롬프트만 변경하여 즉시 적용 가능

2. **중간 추론 단계 생성**
   - 문제를 작은 단계로 분해
   - 각 단계의 논리적 연결 표시
   - 최종 답변으로 수렴

3. **해석 가능성**
   - 모델의 사고 과정이 투명하게 드러남
   - 오류 발생 지점 추적 가능
   - 디버깅 및 개선 용이

### 2. 창발적 능력 (Emergent Property)

#### 모델 크기와 성능 관계

**소형 모델 (< 100B 파라미터)**

- CoT 프롬프팅이 효과 없음
- 일관성 없는 추론 체인 생성
- 표준 프롬프팅과 유사한 성능

**대형 모델 (≥ 100B 파라미터)**

- CoT 프롬프팅으로 극적인 성능 향상
- 체계적이고 논리적인 추론 생성
- 모델 크기 증가에 따라 성능 지속 향상

#### 스케일링 특성

- **표준 프롬프팅**: 모델 크기 증가에도 성능 정체 (Flat scaling curve)
- **CoT 프롬프팅**: 모델 크기에 따라 선형적 성능 향상
- **임계점**: 약 100B 파라미터에서 CoT 효과 발현

### 3. 적용 가능한 추론 유형

#### 산술 추론 (Arithmetic Reasoning)

**작업 유형**

- 수학 단어 문제 (Math Word Problems)
- 다단계 계산 (Multi-step Calculations)
- 수치 추론 (Numerical Reasoning)

**예시**

```
Q: 카페테리아에는 사과 23개가 있었다. 점심에 20개를 사용했고
오후에 6개를 더 샀다면, 사과는 몇 개인가?

A: 카페테리아는 처음에 23개를 가지고 있었다.
   점심에 20개를 사용했으므로 23 - 20 = 3개가 남았다.
   오후에 6개를 더 샀으므로 3 + 6 = 9개다.
   답은 9이다.
```

#### 상식 추론 (Commonsense Reasoning)

**작업 유형**

- 일상 상황 이해
- 암묵적 지식 활용
- 인과 관계 추론

**예시**

```
Q: Q와 A가 친구일 때, Q가 A를 방문하면 어떻게 될까?

A: Q가 A를 방문하면, A는 Q를 반길 것이다.
   친구 사이이므로 함께 시간을 보낼 것이다.
   대화하거나 활동을 같이 할 것이다.
   답은: A가 Q를 환영할 것이다.
```

#### 기호 추론 (Symbolic Reasoning)

**작업 유형**

- 패턴 인식
- 규칙 적용
- 논리적 변환

## 주요 실험 결과

### 1. 산술 추론 벤치마크

#### GSM8K (Grade School Math 8K)

**데이터셋 특성**

- 초등학교 수준 수학 문제 8,000개
- 2-8단계의 다단계 추론 필요
- 자연어 해법 제공

**성능 결과**

- **PaLM 540B + CoT**: 58% 정확도 (새로운 SOTA)
- **이전 SOTA** (GPT-3 finetuned + verifier): 55%
- **PaLM 540B 표준**: 18%
- **개선률**: 표준 대비 +40% 포인트

#### SVAMP (Simple Variations on Arithmetic Math word Problems)

- **PaLM 540B + CoT**: 79% 정확도
- **표준 프롬프팅**: 60%
- **개선률**: +19% 포인트

#### MAWPS (Math Word Problem Solving)

- **PaLM 540B + CoT**: 93% 정확도
- **표준 프롬프팅**: 88%
- **개선률**: +5% 포인트

### 2. 상식 추론 벤치마크

#### CommonsenseQA

**데이터셋 특성**

- 다중 선택 질문
- 일상적 상식 지식 요구
- 복잡한 추론 필요

**성능 결과**

- **PaLM 540B + CoT**: 답변 정확도 향상
- 특히 복잡한 질문에서 큰 개선

#### StrategyQA

**데이터셋 특성**

- Yes/No 질문
- 암묵적 다단계 추론 필요
- 전략적 사고 요구

**성능 결과**

- **PaLM 540B + CoT**: 75.6% 정확도
- **이전 SOTA**: 69.4%
- **개선률**: +6.2% 포인트

#### Sports Understanding

**성능 결과**

- **PaLM 540B + CoT**: 95.4% 정확도
- **인간 (스포츠 애호가)**: 84%
- **초과 성능**: +11.4% 포인트

#### Date Understanding

- 날짜 계산 및 추론 작업
- CoT를 통한 단계별 계산으로 정확도 향상

### 3. 기호 추론 벤치마크

#### Last Letter Concatenation

**작업 내용**

- 단어 목록의 마지막 글자들을 연결
- 예: "Amy Brown" → "yn"

**성능 결과**

- **PaLM 540B + CoT**: 큰 성능 향상
- 표준 프롬프팅으로는 거의 불가능한 작업

#### Coin Flip

**작업 내용**

- 일련의 동전 뒤집기 후 최종 상태 추론
- 다단계 상태 변화 추적

**성능 결과**

- CoT가 없으면 성능 저조
- CoT로 논리적 단계 추적 가능

### 4. 모델별 성능 비교

#### PaLM (Pathways Language Model)

- **540B 파라미터**: CoT로 최고 성능
- **62B 파라미터**: 일부 작업에서 CoT 효과
- **8B 파라미터**: CoT 효과 미미

#### LaMDA (Language Model for Dialogue Applications)

- **137B 파라미터**: CoT로 성능 향상
- 대화 모델에서도 추론 능력 발현

#### GPT-3

- **175B 파라미터**: CoT로 성능 향상
- 다양한 작업에서 일관된 개선

## 주요 발견 및 통찰

### 1. 언어 기반 추론의 범용성

#### 적용 범위

- **수학**: 계산, 대수, 기하
- **상식**: 일상 지식, 인과 관계
- **기호**: 패턴, 규칙, 논리
- **전략**: 계획, 의사결정

#### 언어의 힘

> "Language-based nature makes it applicable to any task that a person could solve via language"

- 인간이 언어로 해결할 수 있는 모든 작업에 적용 가능
- 언어가 추론의 매개체 역할
- 도메인 지식을 언어로 표현 가능

### 2. 계산 자원 할당

#### 적응적 계산 (Adaptive Computation)

**문제 난이도에 따른 계산량 조절**

- 단순 문제: 짧은 추론 체인
- 복잡한 문제: 긴 추론 체인
- 필요한 만큼만 계산 자원 사용

**효율성 향상**

- 불필요한 계산 최소화
- 문제별 맞춤형 추론 깊이
- 전체 시스템 효율성 개선

### 3. 프롬프트 설계의 중요성

#### 예시 품질의 영향

**고품질 예시 특성**

1. **논리적 일관성**: 각 단계가 자연스럽게 연결
2. **적절한 세분화**: 너무 간단하지도, 복잡하지도 않게
3. **명확한 표현**: 모호함 없는 언어 사용
4. **다양성**: 다양한 문제 유형 커버

**저품질 예시의 문제**

- 불일치하는 추론 체인 생성
- 성능 저하
- 잘못된 패턴 학습

#### 예시 개수

- **권장**: 8개 내외
- **최소**: 3-4개 (일부 효과)
- **최대**: 15개 이상도 가능하나 수익 체감

### 4. 한계점 및 도전 과제

#### 기술적 한계

1. **모델 크기 의존성**
   - 100B 파라미터 이상 필요
   - 소형 모델에서는 효과 없음
   - 컴퓨팅 자원 요구사항 높음

2. **정확성 보장 불가**
   - 올바른 추론이 항상 생성되지 않음
   - 논리적으로 보이지만 틀린 추론 가능
   - 환각(hallucination) 문제 여전히 존재

3. **프롬프트 엔지니어링 필요**
   - 효과적인 예시 작성 필요
   - 도메인 지식 요구
   - 시행착오 과정 필요

#### 실무적 고려사항

1. **추론 비용**
   - 더 긴 출력 생성 → 토큰 비용 증가
   - 추론 시간 증가
   - 대규모 배포 시 비용 고려 필요

2. **작업 적합성**
   - 모든 작업에 CoT가 필요하지 않음
   - 단순한 작업에는 오버헤드
   - 작업 특성 분석 필요

3. **품질 관리**
   - 생성된 추론 검증 필요
   - 오류 탐지 메커니즘 필요
   - 지속적인 모니터링 요구

## 실무적 함의

### 장점

#### 1. 즉시 적용 가능

- **Zero Deployment Cost**: 모델 재학습 불필요
- **Rapid Prototyping**: 프롬프트만 수정하면 즉시 테스트
- **Version Control**: 프롬프트 버전 관리 용이
- **A/B Testing**: 다양한 프롬프트 전략 실험 가능

#### 2. 비용 효율성

- **파인튜닝 대비**: 학습 데이터, 컴퓨팅 자원 불필요
- **유지보수**: 프롬프트만 업데이트하면 됨
- **확장성**: 동일한 프롬프트로 다양한 문제 해결

#### 3. 투명성 및 디버깅

- **추론 과정 가시화**: 각 단계 확인 가능
- **오류 진단**: 문제 발생 지점 파악 용이
- **개선 방향**: 어떤 부분을 수정할지 명확
- **신뢰성**: 사용자가 결과 검증 가능

#### 4. 범용성

- **다중 도메인**: 수학, 상식, 기호 추론 등
- **작업 전이**: 한 도메인의 CoT를 다른 도메인에 적용 가능
- **언어 독립적**: 다양한 언어로 적용 가능

### 적용 분야

#### 교육 (Education)

**활용 예시**

- 문제 풀이 과정 설명
- 학생 이해도 향상
- 자동 튜터링 시스템
- 오개념 진단 및 교정

**이점**

- 학습자가 사고 과정 이해 가능
- 맞춤형 설명 생성
- 즉각적인 피드백 제공

#### 비즈니스 분석 (Business Analytics)

**활용 예시**

- 재무 분석 및 예측
- 시장 동향 추론
- 전략적 의사결정 지원
- 리스크 평가

**이점**

- 분석 근거 투명화
- 다단계 추론 자동화
- 의사결정 과정 문서화

#### 소프트웨어 개발 (Software Development)

**활용 예시**

- 코드 디버깅 설명
- 알고리즘 설계 과정
- 복잡한 로직 분해
- 테스트 케이스 생성

**이점**

- 버그 원인 추적
- 코드 리뷰 품질 향상
- 개발자 생산성 증대

#### 의료 (Healthcare)

**활용 예시**

- 진단 추론 과정
- 치료 계획 수립
- 의료 문헌 분석
- 환자 상담 지원

**이점**

- 의학적 판단 근거 제시
- 복잡한 증상 분석
- 의료진 의사결정 지원

#### 법률 (Legal)

**활용 예시**

- 판례 분석
- 법적 논리 구성
- 계약서 검토
- 규정 준수 확인

**이점**

- 법적 추론 과정 문서화
- 복잡한 법률 관계 분석
- 논거 체계적 구성

#### 과학 연구 (Scientific Research)

**활용 예시**

- 실험 설계
- 가설 생성 및 검증
- 데이터 해석
- 문헌 리뷰

**이점**

- 과학적 추론 명확화
- 연구 방법론 개선
- 결과 해석 체계화

## 후속 연구 및 발전

### 1. Zero-Shot CoT

**개념**

- Few-shot 예시 없이 "Let's think step by step" 같은 프롬프트만으로 CoT 유도
- 더 간단한 프롬프팅 전략

**장점**

- 예시 작성 불필요
- 범용성 증가
- 적용 편의성 향상

### 2. Self-Consistency

**개념**

- 동일한 문제에 대해 여러 추론 경로 생성
- 가장 일관된 답변 선택
- 앙상블 효과

**성능**

- CoT 단독보다 높은 정확도
- 로버스트성 증가
- 오류 감소

### 3. Least-to-Most Prompting

**개념**

- 문제를 작은 하위 문제로 분해
- 각 하위 문제를 순차적으로 해결
- 이전 답변을 다음 문제에 활용

**특징**

- 더 구조화된 추론
- 복잡한 문제 처리 능력 향상
- 일반화 성능 개선

### 4. Tree of Thoughts

**개념**

- 여러 가능한 추론 경로를 트리 구조로 탐색
- 각 경로를 평가하고 최선의 경로 선택
- 백트래킹 가능

**장점**

- 더 깊은 탐색
- 막다른 길에서 복귀 가능
- 최적 해 발견 확률 증가

### 5. Automatic CoT

**개념**

- CoT 예시를 자동으로 생성
- 인간 개입 최소화
- 데이터 기반 예시 선택

**이점**

- 프롬프트 엔지니어링 자동화
- 확장성 증가
- 도메인 적응 용이

### 6. 멀티모달 CoT

**개념**

- 텍스트뿐 아니라 이미지, 표 등 다양한 모달리티 통합
- 시각적 추론 단계 포함
- 복합적 정보 처리

**응용**

- 과학 문제 해결 (다이어그램 포함)
- 의료 영상 분석
- 멀티모달 질의응답

## 관련 개념

- [[워크플로우와 에이전트 패턴#추론 패턴|추론 패턴]]
- [[ACE - 진화하는 컨텍스트를 통한 자가 개선]] - 컨텍스트 엔지니어링
- [[초기 경험을 통한 에이전트 학습#자기 성찰|자기 성찰]]
- **Prompt Engineering**: 프롬프트 설계 및 최적화
- **Few-Shot Learning**: 소수 예시로 학습하는 기법
- **Emergent Abilities**: 모델 크기 증가로 나타나는 능력
- **In-Context Learning**: 컨텍스트 내 학습

## 참고 자료

- [[최신 AI 연구 논문]]
- [[C.R.A.F.T.E.D. 프롬프트 프레임워크 - AI로 소프트웨어 엔지니어링 작업하기]]
- [[학습 자료 모음]]
- Google Research Blog: <https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/>

## 실전 가이드

### CoT 프롬프트 작성 체크리스트

#### 예시 작성 시

- [ ] 각 단계가 논리적으로 연결되는가?
- [ ] 중간 단계가 명확하게 표현되었는가?
- [ ] 최종 답변이 추론 과정과 일치하는가?
- [ ] 다양한 문제 유형을 커버하는가?
- [ ] 예시가 너무 길거나 짧지 않은가?

#### 배포 전 검증

- [ ] 다양한 테스트 케이스로 검증했는가?
- [ ] 생성된 추론이 일관성 있는가?
- [ ] 오류 패턴을 분석했는가?
- [ ] 성능이 표준 프롬프팅 대비 향상되었는가?
- [ ] 추가 비용이 정당화되는가?

#### 운영 중 모니터링

- [ ] 추론 품질을 정기적으로 확인하는가?
- [ ] 사용자 피드백을 수집하는가?
- [ ] 실패 케이스를 분석하는가?
- [ ] 프롬프트를 지속적으로 개선하는가?

---

**마지막 업데이트**: 2025-10-25
