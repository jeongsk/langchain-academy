---
source: https://langchain-ai.github.io/langgraph/agents/overview/
---

## Agent development using prebuilt components

LangGraph provides both low-level primitives and high-level prebuilt components for building agent-based applications. This section focuses on the prebuilt, ready-to-use components designed to help you construct agentic systems quickly and reliably—without the need to implement orchestration, memory, or human feedback handling from scratch.

## What is an agent?

An *agent* consists of three components: a **large language model (LLM)**, a set of **tools** it can use, and a **prompt** that provides instructions.

The LLM operates in a loop. In each iteration, it selects a tool to invoke, provides input, receives the result (an observation), and uses that observation to inform the next action. The loop continues until a stopping condition is met — typically when the agent has gathered enough information to respond to the user.

![image](https://langchain-ai.github.io/langgraph/agents/assets/agent.png)

Agent loop: the LLM selects tools and uses their outputs to fulfill a user request.

## Key features

LangGraph includes several capabilities essential for building robust, production-ready agentic systems:

- [**Memory integration**](https://langchain-ai.github.io/langgraph/how-tos/memory/add-memory/): Native support for *short-term* (session-based) and *long-term* (persistent across sessions) memory, enabling stateful behaviors in chatbots and assistants.
- [**Human-in-the-loop control**](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/): Execution can pause *indefinitely* to await human feedback—unlike websocket-based solutions limited to real-time interaction. This enables asynchronous approval, correction, or intervention at any point in the workflow.
- [**Streaming support**](https://langchain-ai.github.io/langgraph/how-tos/streaming/): Real-time streaming of agent state, model tokens, tool outputs, or combined streams.
- [**Deployment tooling**](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/): Includes infrastructure-free deployment tools. [**LangGraph Platform**](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/) supports testing, debugging, and deployment.
- **[Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/)**: A visual IDE for inspecting and debugging workflows.
- Supports multiple [**deployment options**](https://langchain-ai.github.io/langgraph/concepts/deployment_options.md) for production.

## High-level building blocks

LangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.

Using LangGraph for agent development allows you to focus on your application's logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.

## Package ecosystem

The high-level components are organized into several packages, each with a specific focus.

| Package | Description | Installation |
| --- | --- | --- |
| `langgraph-prebuilt` (part of `langgraph`) | Prebuilt components to [**create agents**](https://langchain-ai.github.io/langgraph/agents/agents/) | `pip install -U langgraph langchain` |
| `langgraph-supervisor` | Tools for building [**supervisor**](https://langchain-ai.github.io/langgraph/agents/multi-agent/#supervisor) agents | `pip install -U langgraph-supervisor` |
| `langgraph-swarm` | Tools for building a [**swarm**](https://langchain-ai.github.io/langgraph/agents/multi-agent/#swarm) multi-agent system | `pip install -U langgraph-swarm` |
| `langchain-mcp-adapters` | Interfaces to [**MCP servers**](https://langchain-ai.github.io/langgraph/agents/mcp/) for tool and resource integration | `pip install -U langchain-mcp-adapters` |
| `langmem` | Agent memory management: [**short-term and long-term**](https://langchain-ai.github.io/langgraph/how-tos/memory/add-memory/) | `pip install -U langmem` |
| `agentevals` | Utilities to [**evaluate agent performance**](https://langchain-ai.github.io/langgraph/agents/evals/) | `pip install -U agentevals` |

## Visualize an agent graph

Use the following tool to visualize the graph generated by [`create_react_agent`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) and to view an outline of the corresponding code. It allows you to explore the infrastructure of the agent as defined by the presence of:

- [`tools`](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/): A list of tools (functions, APIs, or other callable objects) that the agent can use to perform tasks.
- [`pre_model_hook`](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-manage-message-history/): A function that is called before the model is invoked. It can be used to condense messages or perform other preprocessing tasks.
- `post_model_hook`: A function that is called after the model is invoked. It can be used to implement guardrails, human-in-the-loop flows, or other postprocessing tasks.
- [`response_format`](https://langchain-ai.github.io/langgraph/agents/agents/#6-configure-structured-output): A data structure used to constrain the type of the final output, e.g., a `pydantic` `BaseModel`.

### Features

### Graph

![graph image](https://langchain-ai.github.io/langgraph/agents/assets/react_agent_graphs/0001.svg)

The following code snippet shows how to create the above agent (and underlying graph) with [`create_react_agent`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent):

```python
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI

model = ChatOpenAI("o4-mini")

def tool() -> None:
    """Testing tool."""
    ...

agent = create_react_agent(
    model,
    tools=[tool],
)

# Visualize the graph
# For Jupyter or GUI environments:
agent.get_graph().draw_mermaid_png()

# To save PNG to file:
png_data = agent.get_graph().draw_mermaid_png()
with open("graph.png", "wb") as f:
    f.write(png_data)

# For terminal/ASCII output:
agent.get_graph().draw_ascii()
```