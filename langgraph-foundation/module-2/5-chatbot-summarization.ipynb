{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fcadf3",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-2/chatbot-summarization.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239436-lesson-5-chatbot-w-summarizing-messages-and-memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651ead9-5504-45ee-938d-f91ac78dddd1",
   "metadata": {},
   "source": [
    "# 메시지 요약 기능을 갖춘 챗봇\n",
    "\n",
    "## 복습\n",
    "\n",
    "그래프 상태 스키마와 리듀서를 커스터마이징하는 방법을 다뤘습니다.\n",
    "\n",
    "또한 그래프 상태에서 메시지를 트리밍하거나 필터링하는 여러 방법을 보여드렸습니다.\n",
    "\n",
    "## 목표\n",
    "\n",
    "이제 한 단계 더 나아가보겠습니다!\n",
    "\n",
    "메시지를 단순히 트리밍하거나 필터링하는 대신, LLM을 사용하여 대화의 실행 요약을 생성하는 방법을 보여드리겠습니다.\n",
    "\n",
    "이를 통해 트리밍이나 필터링으로 단순히 제거하는 것이 아니라, 전체 대화의 압축된 표현을 유지할 수 있습니다.\n",
    "\n",
    "이 요약 기능을 간단한 챗봇에 통합할 것입니다.\n",
    "\n",
    "그리고 해당 챗봇에 메모리를 장착하여 높은 토큰 비용/지연 시간을 발생시키지 않으면서 장기 실행 대화를 지원할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a8b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09201a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd",
   "metadata": {},
   "source": [
    "[tracing](https://docs.smith.langchain.com/concepts/tracing)을 위해 [LangSmith](https://docs.smith.langchain.com/)를 사용하겠습니다.\n",
    "\n",
    "`langchain-academy` 프로젝트에 로깅할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464856d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b",
   "metadata": {},
   "source": [
    "이전과 마찬가지로 `MessagesState`를 사용하겠습니다.\n",
    "\n",
    "내장된 `messages` 키 외에도 이제 커스텀 키(`summary`)를 포함할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "948e60f0-5c76-4235-b40e-cf523205d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855ea31-5cc1-4277-a189-0b72459f67ec",
   "metadata": {},
   "source": [
    "요약이 존재하는 경우 이를 프롬프트에 통합하는 LLM을 호출하는 노드를 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "\n",
    "# 모델 호출 로직 정의\n",
    "def call_model(state: State):\n",
    "    # 요약이 존재하면 가져오기\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # 요약이 있다면 추가합니다\n",
    "    if summary:\n",
    "        # 시스템 메시지에 요약 추가\n",
    "        system_message = f\"이전 대화 요약: {summary}\"\n",
    "\n",
    "        # 요약문을 최신 메시지에 추가하십시오\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450",
   "metadata": {},
   "source": [
    "요약을 생성하는 노드를 정의하겠습니다.\n",
    "\n",
    "여기서는 요약을 생성한 후 상태를 필터링하기 위해 `RemoveMessage`를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    # 먼저, 기존 요약문을 가져옵니다.\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # 요약 프롬프트 생성\n",
    "    if summary:\n",
    "        # 요약본이 이미 존재합니다\n",
    "        summary_message = (\n",
    "            f\"지금까지의 대화 요약은 다음과 같습니다: {summary}\\n\\n\"\n",
    "            \"위의 새로운 메시지를 고려하여 요약을 확장하십시오:\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        summary_message = \"위의 대화 내용을 요약하세요:\"\n",
    "\n",
    "    # 우리의 기록에 프롬프트를 추가하세요\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # 가장 최근의 2개 메시지를 제외한 모든 메시지를 삭제하세요\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    return {\n",
    "        \"summary\": response.content,\n",
    "        \"messages\": delete_messages,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982993e-f4be-4ff7-9a38-886f75398b3d",
   "metadata": {},
   "source": [
    "대화 길이를 기반으로 요약을 생성할지 여부를 결정하는 조건부 엣지를 추가하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b507665d-7f5d-442a-b498-218c94c5dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from typing_extensions import Literal\n",
    "\n",
    "\n",
    "# 대화를 종료할지 요약할지 결정하십시오\n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 메시지가 여섯 개 이상일 경우 대화를 요약합니다\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    # 그렇지 않으면 그냥 종료합니다.\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd",
   "metadata": {},
   "source": [
    "## 메모리 추가하기\n",
    "\n",
    "[상태는 단일 그래프 실행에 일시적](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220)이라는 것을 기억하세요.\n",
    "\n",
    "이는 중단이 있는 다회차 대화를 수행하는 능력을 제한합니다.\n",
    "\n",
    "모듈 1의 끝부분에서 소개했듯이, 이를 해결하기 위해 [지속성(persistence)](https://langchain-ai.github.io/langgraph/how-tos/persistence/)을 사용할 수 있습니다!\n",
    "\n",
    "LangGraph는 체크포인터를 사용하여 각 단계 후 그래프 상태를 자동으로 저장할 수 있습니다.\n",
    "\n",
    "이 내장된 지속성 레이어는 메모리를 제공하여 LangGraph가 마지막 상태 업데이트부터 다시 시작할 수 있도록 합니다.\n",
    "\n",
    "이전에 보여드렸듯이, 가장 사용하기 쉬운 것 중 하나는 그래프 상태를 위한 인메모리 키-값 저장소인 `MemorySaver`입니다.\n",
    "\n",
    "체크포인터로 그래프를 컴파일하기만 하면 그래프에 메모리가 생깁니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77de99",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/lRLhWcK.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9",
   "metadata": {},
   "source": [
    "## 스레드\n",
    "\n",
    "체크포인터는 각 단계의 상태를 체크포인트로 저장합니다.\n",
    "\n",
    "이렇게 저장된 체크포인트들은 대화의 `스레드`로 그룹화될 수 있습니다.\n",
    "\n",
    "Slack을 비유로 생각해보세요: 서로 다른 채널이 서로 다른 대화를 담습니다.\n",
    "\n",
    "스레드는 Slack 채널과 같아서, 그룹화된 상태 모음(예: 대화)을 포착합니다.\n",
    "\n",
    "아래에서는 `configurable`을 사용하여 스레드 ID를 설정합니다.\n",
    "\n",
    "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbadf3b379c2ee621adfd1_chatbot-summarization1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요, 랜스님! 만나서 반갑습니다. 어떻게 도와드릴까요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "당신의 이름은 랜스라고 하셨습니다. 다른 질문이나 도움이 필요하시면 말씀해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "샌프란시스코 49ers를 좋아하시는군요! 49ers는 NFL에서 매우 인기 있는 팀 중 하나로, 특히 그들의 역사적인 성공과 전설적인 선수들로 유명합니다. 팀이나 선수에 대해 더 이야기하고 싶으신 게 있나요?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"안녕하세요! 저는 랜스입니다.\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output[\"messages\"][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"내 이름이 뭐지?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output[\"messages\"][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"저는 49ers를 좋아해요!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output[\"messages\"][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2",
   "metadata": {},
   "source": [
    "이제 아직 상태의 요약이 없는데, 아직 6개 이하의 메시지를 가지고 있기 때문입니다.\n",
    "\n",
    "이는 `should_continue`에서 설정되었습니다.\n",
    "\n",
    "```\n",
    "    # 메시지가 6개를 초과하면 대화를 요약합니다\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "```\n",
    "\n",
    "스레드가 있기 때문에 대화를 이어갈 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a93e9-f716-4980-8edf-94115017d865",
   "metadata": {},
   "source": [
    "스레드 ID가 있는 `config`를 사용하면 이전에 기록된 상태에서 계속 진행할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, 닉 보사는 2023년 기준으로 NFL 수비수 중 최고 연봉을 받는 선수입니다. 그는 샌프란시스코 49ers와의 계약 연장을 통해 이 기록을 세웠습니다. 보사는 뛰어난 수비 능력과 경기력으로 팀에 큰 기여를 하고 있으며, 많은 팬들에게 사랑받고 있습니다. 그의 활약을 지켜보는 것은 정말 흥미진진하죠!\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(\n",
    "    content=\"닉 보사 좋아하는데, 그 선수 수비수 중 최고 연봉자 아니야?\"\n",
    ")\n",
    "\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "\n",
    "for m in output[\"messages\"][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사용자는 자신을 랜스라고 소개하며 샌프란시스코 49ers를 좋아한다고 말했습니다. 특히 닉 보사를 좋아하며, 그가 NFL 수비수 중 최고 연봉자라는 사실을 언급했습니다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "\n",
    "Let's review the trace!\n",
    "\n",
    "https://smith.langchain.com/public/f8468b91-a5cd-4573-b703-6afa9d374981/r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5205c4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
