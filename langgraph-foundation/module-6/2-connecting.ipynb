{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Platform 배포에 연결하기\n",
    "\n",
    "## 배포 생성 (복습)\n",
    "\n",
    "방금 모듈 5의 `task_maistro` 앱에 대한 [배포](https://langchain-ai.github.io/langgraph/how-tos/deploy-self-hosted/#how-to-do-a-self-hosted-deployment-of-langgraph)를 생성했습니다.\n",
    "\n",
    "  * [LangGraph CLI](https://langchain-ai.github.io/langgraph/concepts/langgraph_cli/#commands)를 사용하여 `task_maistro` 그래프가 포함된 LangGraph 서버용 Docker 이미지를 빌드했습니다.\n",
    "  * 제공된 `docker-compose.yml` 파일을 사용하여 정의된 서비스에 따라 세 개의 개별 컨테이너를 생성했습니다:\n",
    "      * `langgraph-redis`: 공식 Redis 이미지를 사용하는 새 컨테이너를 생성합니다.\n",
    "      * `langgraph-postgres`: 공식 Postgres 이미지를 사용하는 새 컨테이너를 생성합니다.\n",
    "      * `langgraph-api`: 미리 빌드한 `task_maistro` Docker 이미지를 사용하는 새 컨테이너를 생성합니다.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```shell\n",
    "$ cd module-6/deployment\n",
    "$ docker compose up\n",
    "```\n",
    "\n",
    "실행이 완료되면, 다음 주소를 통해 배포된 서비스에 접근할 수 있습니다:\n",
    "\n",
    "  * API: http://localhost:8123\n",
    "  * 문서(Docs): http://localhost:8123/docs\n",
    "  * LangGraph Studio: [https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:8123](https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:8123)\n",
    "\n",
    "## API 사용하기\n",
    "\n",
    "LangGraph 서버는 배포된 에이전트와 상호작용하기 위한 [다양한 API 엔드포인트](https://github.com/langchain-ai/agent-protocol)를 제공합니다.\n",
    "\n",
    "이 [엔드포인트들은 일반적인 에이전트의 몇 가지 요구사항에 따라 그룹화](https://github.com/langchain-ai/agent-protocol)할 수 있습니다:\n",
    "\n",
    "  * **실행(Runs)**: 단일 원자적(atomic) 에이전트 실행\n",
    "  * **스레드(Threads)**: 다중 턴(multi-turn) 상호작용 또는 사용자 개입(human-in-the-loop)\n",
    "  * **저장소(Store)**: 장기 기억(long-term memory)\n",
    "\n",
    "[API 문서](https://www.google.com/search?q=http://localhost:8123/docs%23tag/thread-runs)에서 직접 요청을 테스트해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDK\n",
    "\n",
    "[LangGraph SDK](https://langchain-ai.github.io/langgraph/concepts/sdk/) (Python 및 JS)는 위에서 소개한 LangGraph 서버 API와 상호작용하기 위한 개발자 친화적인 인터페이스를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# Connect via SDK\n",
    "url_for_cli_deployment = \"http://localhost:8123\"\n",
    "client = get_client(url=url_for_cli_deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원격 그래프 (Remote Graph)\n",
    "\n",
    "LangGraph 라이브러리 환경에서 작업하는 경우, [원격 그래프(Remote Graph)](https://langchain-ai.github.io/langgraph/how-tos/use-remote-graph/)는 배포된 그래프에 직접 연결할 수 있는 또 다른 유용한 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.pregel.remote import RemoteGraph\n",
    "from langchain_core.messages import convert_to_messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 원격 그래프를 통해 연결\n",
    "url = \"http://localhost:8123\"\n",
    "graph_name = \"task_maistro\"\n",
    "remote_graph = RemoteGraph(graph_name, url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행 (Runs)\n",
    "\n",
    "\"실행(run)\"은 그래프의 [단일 실행](https://github.com/langchain-ai/agent-protocol?tab=readme-ov-file#runs-atomic-agent-executions)을 의미합니다. 클라이언트가 요청을 보낼 때마다 다음 과정이 일어납니다:\n",
    "\n",
    "1. HTTP 워커(worker)가 고유한 실행 ID(run ID)를 생성합니다.\n",
    "2. 이 실행과 그 결과는 PostgreSQL에 저장됩니다.\n",
    "3. 이 실행 기록을 쿼리하여 다음을 수행할 수 있습니다:\n",
    "   - 상태 확인\n",
    "   - 결과 가져오기\n",
    "   - 실행 기록 추적\n",
    "\n",
    "다양한 유형의 실행에 대한 전체 How To 가이드는 [여기](https://langchain-ai.github.io/langgraph/how-tos/#runs)에서 확인할 수 있습니다.\n",
    "\n",
    "이제 실행(run)을 통해 할 수 있는 몇 가지 흥미로운 작업들을 살펴보겠습니다.\n",
    "\n",
    "### 백그라운드 실행 (Background Runs)\n",
    "\n",
    "LangGraph 서버는 두 가지 유형의 실행을 지원합니다:\n",
    "\n",
    "* **Fire and forget (실행 후 망각)** - 백그라운드에서 실행을 시작하고, 완료될 때까지 기다리지 않습니다.\n",
    "* **응답 대기 (블로킹 또는 폴링)** - 실행을 시작하고 그 출력을 기다리거나 스트리밍합니다.\n",
    "\n",
    "백그라운드 실행과 폴링은 오래 실행되는 에이전트와 작업할 때 매우 유용합니다.\n",
    "\n",
    "이것이 어떻게 작동하는지 [알아보겠습니다](https://langchain-ai.github.io/langgraph/cloud/how-tos/background_run/#check-runs-on-thread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thread_id': '7f71c0dd-768b-4e53-8349-42bdd10e7caf',\n",
       " 'created_at': '2024-11-14T19:36:08.459457+00:00',\n",
       " 'updated_at': '2024-11-14T19:36:08.459457+00:00',\n",
       " 'metadata': {},\n",
       " 'status': 'idle',\n",
       " 'config': {},\n",
       " 'values': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새 스레드 생성\n",
    "thread = await client.threads.create()\n",
    "thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 스레드에서 실행 중인 작업이 있는지 확인\n",
    "thread = await client.threads.create()\n",
    "runs = await client.runs.list(thread[\"thread_id\"])\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 몇 가지 To-Do(할 일)를 생성하여 특정 user_id에 저장합니다.\n",
    "user_input = \"다음 주 말까지 홍콩 여행 예약을 마치는 To-Do를 추가해줘. 그리고 추수감사절 계획에 대해 부모님께 다시 전화드리는 To-Do도 추가해줘.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Test\"}}\n",
    "graph_name = \"task_maistro\"\n",
    "\n",
    "run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\n",
    "        \"messages\": [HumanMessage(content=user_input)],\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 스레드와 실행(run)을 시작합니다.\n",
    "thread = await client.threads.create()\n",
    "user_input = \"모든 To-Do(할 일) 항목들을 요약해줘.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Test\"}}\n",
    "graph_name = \"task_maistro\"\n",
    "\n",
    "run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\n",
    "        \"messages\": [HumanMessage(content=user_input)],\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': '1efa2c00-63e4-6f4a-9c5b-ca3f5f9bff07', 'thread_id': '641c195a-9e31-4250-a729-6b742c089df8', 'assistant_id': 'ea4ebafa-a81d-5063-a5fa-67c755d98a21', 'created_at': '2024-11-14T19:38:29.394777+00:00', 'updated_at': '2024-11-14T19:38:29.394777+00:00', 'metadata': {}, 'status': 'pending', 'kwargs': {'input': {'messages': [{'id': None, 'name': None, 'type': 'human', 'content': 'Give me a summary of all ToDos.', 'example': False, 'additional_kwargs': {}, 'response_metadata': {}}]}, 'config': {'metadata': {'created_by': 'system'}, 'configurable': {'run_id': '1efa2c00-63e4-6f4a-9c5b-ca3f5f9bff07', 'user_id': 'Test', 'graph_id': 'task_maistro', 'thread_id': '641c195a-9e31-4250-a729-6b742c089df8', 'assistant_id': 'ea4ebafa-a81d-5063-a5fa-67c755d98a21'}}, 'webhook': None, 'subgraphs': False, 'temporary': False, 'stream_mode': ['values'], 'feedback_keys': None, 'interrupt_after': None, 'interrupt_before': None}, 'multitask_strategy': 'reject'}\n"
     ]
    }
   ],
   "source": [
    "# 실행 상태 확인\n",
    "print(await client.runs.get(thread[\"thread_id\"], run[\"run_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행이 아직 진행 중이므로 `'status': 'pending'` 상태인 것을 확인할 수 있습니다.\n",
    "\n",
    "만약 실행이 완료될 때까지 기다려서, 이를 **블로킹(blocking)** 실행으로 만들고 싶다면 어떻게 해야 할까요?\n",
    "\n",
    "`client.runs.join`을 사용하면 실행이 완료될 때까지 기다릴 수 있습니다.\n",
    "\n",
    "이렇게 하면 해당 스레드에서 현재 실행이 완료될 때까지 새로운 실행이 시작되지 않도록 보장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': '1efa2c00-63e4-6f4a-9c5b-ca3f5f9bff07', 'thread_id': '641c195a-9e31-4250-a729-6b742c089df8', 'assistant_id': 'ea4ebafa-a81d-5063-a5fa-67c755d98a21', 'created_at': '2024-11-14T19:38:29.394777+00:00', 'updated_at': '2024-11-14T19:38:29.394777+00:00', 'metadata': {}, 'status': 'success', 'kwargs': {'input': {'messages': [{'id': None, 'name': None, 'type': 'human', 'content': 'Give me a summary of all ToDos.', 'example': False, 'additional_kwargs': {}, 'response_metadata': {}}]}, 'config': {'metadata': {'created_by': 'system'}, 'configurable': {'run_id': '1efa2c00-63e4-6f4a-9c5b-ca3f5f9bff07', 'user_id': 'Test', 'graph_id': 'task_maistro', 'thread_id': '641c195a-9e31-4250-a729-6b742c089df8', 'assistant_id': 'ea4ebafa-a81d-5063-a5fa-67c755d98a21'}}, 'webhook': None, 'subgraphs': False, 'temporary': False, 'stream_mode': ['values'], 'feedback_keys': None, 'interrupt_after': None, 'interrupt_before': None}, 'multitask_strategy': 'reject'}\n"
     ]
    }
   ],
   "source": [
    "# 실행이 완료될 때까지 기다리십시오\n",
    "await client.runs.join(thread[\"thread_id\"], run[\"run_id\"])\n",
    "print(await client.runs.get(thread[\"thread_id\"], run[\"run_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 실행이 완료되었으므로 `'status': 'success'` 상태가 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스트리밍 실행 (Streaming Runs)\n",
    "\n",
    "클라이언트가 스트리밍 요청을 보낼 때마다 다음 과정이 일어납니다:\n",
    "\n",
    "1. HTTP 워커(worker)가 고유한 실행 ID(run ID)를 생성합니다.\n",
    "2. 큐(Queue) 워커가 해당 실행에 대한 작업을 시작합니다.\n",
    "3. 실행 중에 큐 워커는 Redis로 업데이트를 발행(publish)합니다.\n",
    "4. HTTP 워커는 해당 실행에 대한 Redis의 업데이트를 구독(subscribe)하고, 이를 클라이언트에게 반환합니다.\n",
    "\n",
    "이러한 방식으로 스트리밍이 가능해집니다!\n",
    "\n",
    "이전 모듈들에서 [스트리밍](https://langchain-ai.github.io/langgraph/how-tos/#streaming_1)에 대해 다루었지만, 여기서는 그중 한 가지 방법인 **토큰 스트리밍(streaming tokens)** 에 초점을 맞춰보겠습니다.\n",
    "\n",
    "클라이언트에게 토큰을 스트리밍으로 반환하는 것은, 완료되기까지 시간이 걸릴 수 있는 운영 환경의 에이전트와 작업할 때 특히 유용합니다.\n",
    "\n",
    "`stream_mode=\"messages-tuple\"`을 사용하여 [토큰을 스트리밍](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/#setup)할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You might want to focus on \"Call parents back about Thanksgiving plans\" first. It has a shorter estimated time to complete (15 minutes) and doesn't have a specific deadline, so it could be a quick task to check off your list. Once that's done, you can dedicate more time to \"Finish booking travel to Hong Kong,\" which is more time-consuming and has a deadline."
     ]
    }
   ],
   "source": [
    "user_input = \"어떤 To-Do(할 일)에 가장 먼저 집중해야 할까?\"\n",
    "\n",
    "# stream_mode=\"messages-tuple\"을 사용하여 응답을 스트리밍합니다.\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input)]},\n",
    "    config=config,\n",
    "    stream_mode=\"messages-tuple\",\n",
    "):\n",
    "    # 이벤트가 'messages'인 경우, 데이터 조각(chunk)의 내용을 실시간으로 출력합니다.\n",
    "    if chunk.event == \"messages\":\n",
    "        print(\n",
    "            \"\".join(\n",
    "                data_item[\"content\"]\n",
    "                for data_item in chunk.data\n",
    "                if \"content\" in data_item\n",
    "            ),\n",
    "            end=\"\",\n",
    "            flush=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스레드 (Threads)\n",
    "\n",
    "실행(run)이 그래프의 단일 실행인 반면, 스레드는 **다중 턴(multi-turn)** 상호작용을 지원합니다.\n",
    "\n",
    "클라이언트가 `thread_id`를 사용하여 그래프를 실행하면, 서버는 실행 중의 모든 [체크포인트](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints)(단계)를 해당 스레드의 정보로 Postgres 데이터베이스에 저장합니다.\n",
    "\n",
    "서버를 통해 [생성된 스레드의 상태를 확인](https://langchain-ai.github.io/langgraph/cloud/how-tos/check_thread_status/)할 수 있습니다.\n",
    "\n",
    "### 스레드 상태 확인\n",
    "\n",
    "또한, 특정 스레드에 저장된 상태 [체크포인트](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints)에 쉽게 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Give me a summary of all ToDos.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here's a summary of your current ToDo list:\n",
      "\n",
      "1. **Task:** Finish booking travel to Hong Kong\n",
      "   - **Status:** Not started\n",
      "   - **Deadline:** November 22, 2024\n",
      "   - **Solutions:** \n",
      "     - Check flight prices on Skyscanner\n",
      "     - Book hotel through Booking.com\n",
      "     - Arrange airport transfer\n",
      "   - **Estimated Time to Complete:** 120 minutes\n",
      "\n",
      "2. **Task:** Call parents back about Thanksgiving plans\n",
      "   - **Status:** Not started\n",
      "   - **Deadline:** None\n",
      "   - **Solutions:** \n",
      "     - Check calendar for availability\n",
      "     - Discuss travel arrangements\n",
      "     - Confirm dinner plans\n",
      "   - **Estimated Time to Complete:** 15 minutes\n",
      "\n",
      "Let me know if there's anything else you'd like to do with your ToDo list!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What ToDo should I focus on first.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You might want to focus on \"Call parents back about Thanksgiving plans\" first. It has a shorter estimated time to complete (15 minutes) and doesn't have a specific deadline, so it could be a quick task to check off your list. Once that's done, you can dedicate more time to \"Finish booking travel to Hong Kong,\" which is more time-consuming and has a deadline.\n"
     ]
    }
   ],
   "source": [
    "thread_state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "for m in convert_to_messages(thread_state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스레드 복사\n",
    "\n",
    "또한 기존 스레드를 [복사](https://langchain-ai.github.io/langgraph/cloud/how-tos/copy_threads/) (즉, \"포크(fork)\")할 수도 있습니다.\n",
    "\n",
    "이렇게 하면 기존 스레드의 기록은 그대로 유지하면서, 원본 스레드에는 영향을 주지 않는 독립적인 실행을 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스레드 복사하기\n",
    "copied_thread = await client.threads.copy(thread[\"thread_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Give me a summary of all ToDos.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here's a summary of your current ToDo list:\n",
      "\n",
      "1. **Task:** Finish booking travel to Hong Kong\n",
      "   - **Status:** Not started\n",
      "   - **Deadline:** November 22, 2024\n",
      "   - **Solutions:** \n",
      "     - Check flight prices on Skyscanner\n",
      "     - Book hotel through Booking.com\n",
      "     - Arrange airport transfer\n",
      "   - **Estimated Time to Complete:** 120 minutes\n",
      "\n",
      "2. **Task:** Call parents back about Thanksgiving plans\n",
      "   - **Status:** Not started\n",
      "   - **Deadline:** None\n",
      "   - **Solutions:** \n",
      "     - Check calendar for availability\n",
      "     - Discuss travel arrangements\n",
      "     - Confirm dinner plans\n",
      "   - **Estimated Time to Complete:** 15 minutes\n",
      "\n",
      "Let me know if there's anything else you'd like to do with your ToDo list!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What ToDo should I focus on first.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You might want to focus on \"Call parents back about Thanksgiving plans\" first. It has a shorter estimated time to complete (15 minutes) and doesn't have a specific deadline, so it could be a quick task to check off your list. Once that's done, you can dedicate more time to \"Finish booking travel to Hong Kong,\" which is more time-consuming and has a deadline.\n"
     ]
    }
   ],
   "source": [
    "# 복사된 스레드의 상태를 확인하십시오\n",
    "copied_thread_state = await client.threads.get_state(copied_thread[\"thread_id\"])\n",
    "for m in convert_to_messages(copied_thread_state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 휴먼-인-더-루프 (Human in the loop)\n",
    "\n",
    "모듈 3에서 [휴먼-인-더-루프](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)에 대해 다루었으며, 서버는 우리가 논의했던 모든 관련 기능을 지원합니다.\n",
    "\n",
    "예를 들어, 이전의 어떤 체크포인트에서든 [그래프 실행을 검색하고, 편집하며, 이어서 계속 진행할 수 있습니다](https://langchain-ai.github.io/langgraph/concepts/persistence/#capabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Give me a summary of all ToDos.',\n",
       "   'additional_kwargs': {'example': False,\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {}},\n",
       "   'response_metadata': {},\n",
       "   'type': 'human',\n",
       "   'name': None,\n",
       "   'id': '3680da45-e3a5-4a47-b5b1-4fd4d3e8baf9',\n",
       "   'example': False}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스레드의 기록을 가져오기\n",
    "states = await client.threads.get_history(thread[\"thread_id\"])\n",
    "\n",
    "# 포크할 상태 업데이트를 선택하세요\n",
    "to_fork = states[-2]\n",
    "to_fork[\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3680da45-e3a5-4a47-b5b1-4fd4d3e8baf9'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork[\"values\"][\"messages\"][0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_mAIstro']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork[\"next\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1efa2c00-6609-67ff-8000-491b1dcf8129'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork[\"checkpoint_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 상태(state)를 수정해 보겠습니다. `messages`에 적용된 리듀서(reducer)가 어떻게 작동하는지 기억해 보세요:\n",
    "\n",
    "* 메시지 ID를 제공하지 않으면, 메시지는 (기존 목록에) 추가(append)됩니다.\n",
    "* 상태에 추가하는 대신, 메시지 ID를 제공하여 기존 메시지를 덮어쓸 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_input = {\n",
    "    \"messages\": HumanMessage(\n",
    "        content=\"다음 주 내에 해야 할 모든 To-Do(할 일)들을 요약해줘.\",\n",
    "        # 기존 메시지를 덮어쓰기 위해 ID를 지정합니다.\n",
    "        id=to_fork[\"values\"][\"messages\"][0][\"id\"],\n",
    "    )\n",
    "}\n",
    "\n",
    "# 상태를 업데이트하여 스레드에 새로운 체크포인트를 생성합니다.\n",
    "forked_config = await client.threads.update_state(\n",
    "    thread[\"thread_id\"], forked_input, checkpoint_id=to_fork[\"checkpoint_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of your ToDos that need to be done in the next week:\n",
      "\n",
      "1. **Finish booking travel to Hong Kong**\n",
      "   - **Status:** Not started\n",
      "   - **Deadline:** November 22, 2024\n",
      "   - **Solutions:** \n",
      "     - Check flight prices on Skyscanner\n",
      "     - Book hotel through Booking.com\n",
      "     - Arrange airport transfer\n",
      "   - **Estimated Time to Complete:** 120 minutes\n",
      "\n",
      "It looks like this task is due soon, so you might want to prioritize it. Let me know if there's anything else you need help with!"
     ]
    }
   ],
   "source": [
    "# 스레드에 있는 새로운 체크포인트부터 그래프를 실행합니다.\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input=None,  # 입력은 이미 체크포인트의 상태에 포함되어 있습니다.\n",
    "    config=config,\n",
    "    checkpoint_id=forked_config[\"checkpoint_id\"],\n",
    "    stream_mode=\"messages-tuple\",\n",
    "):\n",
    "    # 이벤트가 'messages'인 경우, 데이터 조각(chunk)의 내용을 실시간으로 출력합니다.\n",
    "    if chunk.event == \"messages\":\n",
    "        print(\n",
    "            \"\".join(\n",
    "                data_item[\"content\"]\n",
    "                for data_item in chunk.data\n",
    "                if \"content\" in data_item\n",
    "            ),\n",
    "            end=\"\",\n",
    "            flush=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스레드 간 메모리 (Across-thread memory)\n",
    "\n",
    "모듈 5에서 [LangGraph 메모리 `스토어(store)`](https://www.google.com/search?q=%5Bhttps://langchain-ai.github.io/langgraph/concepts/persistence/%23memory-store)를 사용하여 여러 스레드에 걸쳐 정보를 저장하는 방법에 대해 다루었습니다.\n",
    "\n",
    "우리가 배포한 `task_maistro` 그래프는 `스토어(store)`를 사용하여, `user_id`를 네임스페이스(namespace)로 지정해 To-Do(할 일)와 같은 정보를 저장합니다.\n",
    "\n",
    "우리의 배포 환경에는 Postgres 데이터베이스가 포함되어 있으며, 이 데이터베이스가 이러한 장기(스레드 간) 메모리를 저장합니다.\n",
    "\n",
    "LangGraph SDK를 사용하면 우리의 배포 환경에서 [스토어(store)와 상호작용하기 위한](https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/#langgraph_sdk.client.StoreClient) 여러 메서드를 사용할 수 있습니다.\n",
    "\n",
    "### 항목 검색하기\n",
    "\n",
    "`task_maistro` 그래프는 `스토어(store)`를 사용하여 To-Do 항목들을 저장하며, 이때 기본적으로 (`todo`, `todo_category`, `user_id`) 튜플로 네임스페이스를 지정합니다.\n",
    "\n",
    "`todo_category`는 (`deployment/configuration.py` 파일에서 확인할 수 있듯이) 기본적으로 `general`로 설정됩니다.\n",
    "\n",
    "모든 To-Do 항목을 검색하려면 이 튜플을 제공하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': {'task': 'Finish booking travel to Hong Kong',\n",
       "   'status': 'not started',\n",
       "   'deadline': '2024-11-22T23:59:59',\n",
       "   'solutions': ['Check flight prices on Skyscanner',\n",
       "    'Book hotel through Booking.com',\n",
       "    'Arrange airport transfer'],\n",
       "   'time_to_complete': 120},\n",
       "  'key': '18524803-c182-49de-9b10-08ccb0a06843',\n",
       "  'namespace': ['todo', 'general', 'Test'],\n",
       "  'created_at': '2024-11-14T19:37:41.664827+00:00',\n",
       "  'updated_at': '2024-11-14T19:37:41.664827+00:00'},\n",
       " {'value': {'task': 'Call parents back about Thanksgiving plans',\n",
       "   'status': 'not started',\n",
       "   'deadline': None,\n",
       "   'solutions': ['Check calendar for availability',\n",
       "    'Discuss travel arrangements',\n",
       "    'Confirm dinner plans'],\n",
       "   'time_to_complete': 15},\n",
       "  'key': '375d9596-edf8-4de2-985b-bacdc623d6ef',\n",
       "  'namespace': ['todo', 'general', 'Test'],\n",
       "  'created_at': '2024-11-14T19:37:41.664827+00:00',\n",
       "  'updated_at': '2024-11-14T19:37:41.664827+00:00'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = await client.store.search_items(\n",
    "    (\"todo\", \"general\", \"Test\"),\n",
    "    limit=5,\n",
    "    offset=0,\n",
    ")\n",
    "items[\"items\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 항목 추가하기\n",
    "\n",
    "우리가 만든 그래프에서는 `put`을 호출하여 스토어(store)에 항목을 추가합니다.\n",
    "\n",
    "만약 그래프 외부에서 스토어에 직접 항목을 추가하고 싶다면, SDK의 [put](https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/#langgraph_sdk.client.StoreClient.put_item) 메서드를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "await client.store.put_item(\n",
    "    (\"testing\", \"Test\"),\n",
    "    key=str(uuid4()),\n",
    "    value={\"todo\": \"SDK 테스트 put_item\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': {'todo': 'Test SDK put_item'},\n",
       "  'key': '3de441ba-8c79-4beb-8f52-00e4dcba68d4',\n",
       "  'namespace': ['testing', 'Test'],\n",
       "  'created_at': '2024-11-14T19:56:30.452808+00:00',\n",
       "  'updated_at': '2024-11-14T19:56:30.452808+00:00'},\n",
       " {'value': {'todo': 'Test SDK put_item'},\n",
       "  'key': '09b9a869-4406-47c5-a635-4716bd79a8b3',\n",
       "  'namespace': ['testing', 'Test'],\n",
       "  'created_at': '2024-11-14T19:53:24.812558+00:00',\n",
       "  'updated_at': '2024-11-14T19:53:24.812558+00:00'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = await client.store.search_items(\n",
    "    (\"testing\", \"Test\"),\n",
    "    limit=5,\n",
    "    offset=0,\n",
    ")\n",
    "items[\"items\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 항목 삭제하기\n",
    "\n",
    "SDK를 사용하여 키(key)를 이용해 스토어(store)에서 [항목을 삭제](https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/#langgraph_sdk.client.StoreClient.delete_item)할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3de441ba-8c79-4beb-8f52-00e4dcba68d4',\n",
       " '09b9a869-4406-47c5-a635-4716bd79a8b3']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item[\"key\"] for item in items[\"items\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.store.delete_item(\n",
    "    (\"testing\", \"Test\"),\n",
    "    key=\"3de441ba-8c79-4beb-8f52-00e4dcba68d4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'value': {'todo': 'Test SDK put_item'},\n",
       "  'key': '09b9a869-4406-47c5-a635-4716bd79a8b3',\n",
       "  'namespace': ['testing', 'Test'],\n",
       "  'created_at': '2024-11-14T19:53:24.812558+00:00',\n",
       "  'updated_at': '2024-11-14T19:53:24.812558+00:00'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = await client.store.search_items(\n",
    "    (\"testing\", \"Test\"),\n",
    "    limit=5,\n",
    "    offset=0,\n",
    ")\n",
    "items[\"items\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
