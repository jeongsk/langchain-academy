{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 더블 텍스팅 (Double Texting)\n",
    "\n",
    "특히 채팅 애플리케이션에서 [더블 텍스팅](https://langchain-ai.github.io/langgraph/concepts/double_texting/)(사용자가 AI의 응답을 기다리지 않고 연속으로 메시지를 보내는 행위)을 원활하게 처리하는 것은 실제 사용 시나리오를 다루는 데 중요합니다.\n",
    "\n",
    "사용자는 이전 실행이 완료되기 전에 여러 메시지를 연속으로 보낼 수 있으며, 우리는 이 상황을 자연스럽게 처리해야 합니다.\n",
    "\n",
    "## 거부 (Reject)\n",
    "\n",
    "간단한 접근 방식은 현재 실행이 완료될 때까지 새로운 모든 실행을 [거부](https://langchain-ai.github.io/langgraph/cloud/how-tos/reject_concurrent/)하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "url_for_cli_deployment = \"http://localhost:8123\"\n",
    "client = get_client(url=url_for_cli_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to start concurrent run Client error '409 Conflict' for url 'http://localhost:8123/threads/2b58630e-00fd-4c35-afad-a6b59e9b9104/runs'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 스레드를 생성합니다.\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# To-Do(할 일)들을 정의합니다.\n",
    "user_input_1 = \"DI 수리 업체에 후속 조치하는 To-Do를 추가해줘.\"\n",
    "user_input_2 = \"서랍장을 벽에 고정하는 To-Do를 추가해줘.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Test-Double-Texting\"}}\n",
    "graph_name = \"task_maistro\"\n",
    "\n",
    "# 첫 번째 실행을 시작합니다.\n",
    "run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_1)]},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# 첫 번째 실행이 끝나기 전에 두 번째 실행을 시도합니다 (더블 텍스팅).\n",
    "# multitask_strategy=\"reject\"는 동시 실행을 거부합니다.\n",
    "try:\n",
    "    await client.runs.create(\n",
    "        thread[\"thread_id\"],\n",
    "        graph_name,\n",
    "        input={\"messages\": [HumanMessage(content=user_input_2)]},\n",
    "        config=config,\n",
    "        multitask_strategy=\"reject\",  # 동시 실행 거부\n",
    "    )\n",
    "except httpx.HTTPStatusError as e:\n",
    "    # 예상대로 HTTPStatusError가 발생하여 동시 실행이 거부됩니다.\n",
    "    print(\"동시 실행 시작 실패:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add a ToDo to follow-up with DI Repairs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_6xqHubCPNufS0bg4tbUxC0FU)\n",
      " Call ID: call_6xqHubCPNufS0bg4tbUxC0FU\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Follow-up with DI Repairs', 'time_to_complete': 30, 'deadline': None, 'solutions': ['Call DI Repairs customer service', 'Email DI Repairs support', 'Check DI Repairs website for updates'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added a task to follow-up with DI Repairs to your ToDo list. If there's anything else you need, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "# 첫 번째 실행이 완료될 때까지 기다립니다.\n",
    "await client.runs.join(thread[\"thread_id\"], run[\"run_id\"])\n",
    "\n",
    "# 스레드의 최종 상태를 가져옵니다.\n",
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "\n",
    "# 최종 상태에 있는 메시지들을 보기 좋게 출력합니다.\n",
    "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 큐에 추가 (Enqueue)\n",
    "\n",
    "현재 실행이 완료될 때까지 들어오는 새로운 모든 실행을 [대기열(큐)에 추가](https://langchain-ai.github.io/langgraph/cloud/how-tos/enqueue_concurrent/)할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Send Erik his t-shirt gift this weekend.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_svTeXPmWGTLY8aQ8EifjwHAa)\n",
      " Call ID: call_svTeXPmWGTLY8aQ8EifjwHAa\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Send Erik his t-shirt gift', 'time_to_complete': 30, 'deadline': '2024-11-19T23:59:00', 'solutions': ['Wrap the t-shirt', \"Get Erik's address\", 'Visit the post office', 'Choose a delivery service'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've updated your ToDo list to send Erik his t-shirt gift this weekend. If there's anything else you need, feel free to let me know!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Get cash and pay nanny for 2 weeks. Do this by Friday.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_Cq0Tfn6yqccHH8n0DOucz5OQ)\n",
      " Call ID: call_Cq0Tfn6yqccHH8n0DOucz5OQ\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Get cash and pay nanny for 2 weeks', 'time_to_complete': 15, 'deadline': '2024-11-17T23:59:00', 'solutions': ['Visit the ATM', 'Calculate the total amount for 2 weeks', 'Hand over the cash to the nanny'], 'status': 'not started'}\n",
      "\n",
      "Document af1fe011-f3c5-4c1c-b98b-181869bc2944 updated:\n",
      "Plan: Update the deadline for sending Erik his t-shirt gift to this weekend, which is by 2024-11-17.\n",
      "Added content: 2024-11-17T23:59:00\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've updated your ToDo list to ensure you get cash and pay the nanny for 2 weeks by Friday. Let me know if there's anything else you need!\n"
     ]
    }
   ],
   "source": [
    "# 새 스레드를 생성합니다.\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# 새로운 To-Do(할 일)들을 생성합니다.\n",
    "user_input_1 = \"이번 주말에 Erik에게 티셔츠 선물을 보내는 To-Do를 추가해줘.\"\n",
    "user_input_2 = \"금요일까지 현금 찾아서 보모님께 2주치 급여를 드리는 To-Do를 추가해줘.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Test-Double-Texting\"}}\n",
    "graph_name = \"task_maistro\"\n",
    "\n",
    "# 첫 번째 실행을 시작합니다.\n",
    "first_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_1)]},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# 첫 번째 실행이 끝나기 전에 두 번째 실행을 시도합니다.\n",
    "# multitask_strategy=\"enqueue\"는 이 요청을 대기열(큐)에 추가하여 순차적으로 처리되도록 합니다.\n",
    "second_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_2)]},\n",
    "    config=config,\n",
    "    multitask_strategy=\"enqueue\",  # 대기열(큐)에 추가\n",
    ")\n",
    "\n",
    "# Wait until the second run completes\n",
    "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
    "\n",
    "# Get the state of the thread\n",
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중단 (Interrupt)\n",
    "\n",
    "[중단(interrupt)](https://langchain-ai.github.io/langgraph/cloud/how-tos/interrupt_concurrent/) 전략을 사용하면, 현재 실행을 중단시키면서도 그 시점까지 수행된 모든 작업 내용은 저장할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Give me a summary of my ToDos due tomrrow.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Never mind, create a ToDo to Order Ham for Thanksgiving by next Friday.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_Rk80tTSJzik2oY44tyUWk8FM)\n",
      " Call ID: call_Rk80tTSJzik2oY44tyUWk8FM\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Order Ham for Thanksgiving', 'time_to_complete': 30, 'deadline': '2024-11-22T23:59:59', 'solutions': ['Check local grocery stores for availability', 'Order online from a specialty meat provider', 'Visit a local butcher shop'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added the task \"Order Ham for Thanksgiving\" to your ToDo list with a deadline of next Friday. If you need any more help, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# 새 스레드를 생성합니다.\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# 새로운 요청들을 정의합니다.\n",
    "user_input_1 = \"내일까지 해야 할 내 To-Do(할 일)들을 요약해줘.\"\n",
    "user_input_2 = (\n",
    "    \"아니야, 그냥 다음 주 금요일까지 추수감사절에 쓸 햄을 주문하는 To-Do를 생성해줘.\"\n",
    ")\n",
    "config = {\"configurable\": {\"user_id\": \"Test-Double-Texting\"}}\n",
    "graph_name = \"task_maistro\"\n",
    "\n",
    "# 첫 번째 실행(요약 요청)을 시작합니다.\n",
    "interrupted_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_1)]},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# 첫 번째 실행이 스레드에 일부 기록될 수 있도록 잠시 기다립니다.\n",
    "await asyncio.sleep(1)\n",
    "\n",
    "# 첫 번째 실행을 중단(interrupt)하고 두 번째 실행(새 To-Do 생성)을 시작합니다.\n",
    "second_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_2)]},\n",
    "    config=config,\n",
    "    multitask_strategy=\"interrupt\",  # 중단\n",
    ")\n",
    "\n",
    "# 두 번째 실행이 완료될 때까지 기다립니다.\n",
    "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
    "\n",
    "# 스레드의 최종 상태를 가져옵니다.\n",
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기 실행이 저장되었으며, 상태가 `interrupted`인 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interrupted\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 실행이 중단(interrupted)되었는지 확인합니다.\n",
    "print((await client.runs.get(thread[\"thread_id\"], interrupted_run[\"run_id\"]))[\"status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 롤백 (Rollback)\n",
    "\n",
    "[롤백(rollback)](https://langchain-ai.github.io/langgraph/cloud/how-tos/rollback_concurrent/) 전략을 사용하면 이전 그래프 실행을 중단하고 삭제한 후, 연속으로 입력된(double-texted) 메시지를 사용하여 새로운 실행을 시작할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Actually, add a ToDo to drop by Yoga in person on Sunday.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It looks like the task \"Drop by Yoga in person\" is already on your ToDo list with a deadline of November 19, 2024. Would you like me to update the deadline to the upcoming Sunday instead?\n"
     ]
    }
   ],
   "source": [
    "# 새 스레드를 생성합니다.\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# 새로운 요청들을 정의합니다.\n",
    "user_input_1 = \"요가 학원에 전화해서 예약 잡는 To-Do를 추가해줘.\"\n",
    "user_input_2 = \"아니, 그냥 일요일에 요가 학원에 직접 들르는 To-Do를 추가해줘.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Test-Double-Texting\"}}\n",
    "graph_name = \"task_maistro\"\n",
    "\n",
    "# 첫 번째 실행을 시작합니다.\n",
    "rolled_back_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_1)]},\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "# 첫 번째 실행을 롤백(삭제)하고 두 번째 실행을 시작합니다.\n",
    "# multitask_strategy=\"rollback\"은 이전 실행을 취소하고 현재 요청으로 대체합니다.\n",
    "second_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_2)]},\n",
    "    config=config,\n",
    "    multitask_strategy=\"rollback\",\n",
    ")\n",
    "\n",
    "# 두 번째 실행이 완료될 때까지 기다립니다.\n",
    "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
    "\n",
    "# 스레드의 최종 상태를 가져옵니다.\n",
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 실행이 삭제되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original run was correctly deleted\n"
     ]
    }
   ],
   "source": [
    "# 원본 실행이 삭제되었는지 확인합니다.\n",
    "try:\n",
    "    # 이 호출은 롤백되었으므로 실패해야 합니다.\n",
    "    await client.runs.get(thread[\"thread_id\"], rolled_back_run[\"run_id\"])\n",
    "except httpx.HTTPStatusError as _:\n",
    "    # 예상대로 오류가 발생하면, 정상적으로 삭제된 것입니다.\n",
    "    print(\"원본 실행이 정상적으로 삭제되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 요약\n",
    "\n",
    "지금까지 다룬 모든 (더블 텍스팅 처리) 방법들을 [다음과 같이 요약](https://langchain-ai.github.io/langgraph/concepts/double_texting/)할 수 있습니다:\n",
    "\n",
    "![](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/langgraph-platform/images/double-texting.png?fit=max&auto=format&n=Xbr8HuVd9jPi6qTU&q=85&s=684d38e90d294df897a7a6a779784047)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
